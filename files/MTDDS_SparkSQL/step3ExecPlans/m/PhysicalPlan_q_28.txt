AdaptiveSparkPlan isFinalPlan=false
+- BroadcastNestedLoopJoin BuildRight, Inner
   :- BroadcastNestedLoopJoin BuildRight, Inner
   :  :- BroadcastNestedLoopJoin BuildRight, Inner
   :  :  :- BroadcastNestedLoopJoin BuildRight, Inner
   :  :  :  :- BroadcastNestedLoopJoin BuildRight, Inner
   :  :  :  :  :- HashAggregate(keys=[], functions=[avg(ss_list_price#1260), count(ss_list_price#1260), count(distinct ss_list_price#26145)], output=[B1_LP#25658, B1_CNT#25659L, B1_CNTD#25660L])
   :  :  :  :  :  +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=72857]
   :  :  :  :  :     +- HashAggregate(keys=[], functions=[merge_avg(ss_list_price#1260), merge_count(ss_list_price#1260), partial_count(distinct ss_list_price#26145)], output=[sum#25889, count#25890L, count#25892L, count#26148L])
   :  :  :  :  :        +- HashAggregate(keys=[ss_list_price#26145], functions=[merge_avg(ss_list_price#1260), merge_count(ss_list_price#1260)], output=[ss_list_price#26145, sum#25889, count#25890L, count#25892L])
   :  :  :  :  :           +- Exchange hashpartitioning(ss_list_price#26145, 200), ENSURE_REQUIREMENTS, [plan_id=72853]
   :  :  :  :  :              +- HashAggregate(keys=[knownfloatingpointnormalized(normalizenanandzero(ss_list_price#1260)) AS ss_list_price#26145], functions=[partial_avg(ss_list_price#1260), partial_count(ss_list_price#1260)], output=[ss_list_price#26145, sum#25889, count#25890L, count#25892L])
   :  :  :  :  :                 +- Project [ss_list_price#1260]
   :  :  :  :  :                    +- Filter (((isnotnull(ss_quantity#1258) AND (ss_quantity#1258 >= 0)) AND (ss_quantity#1258 <= 5)) AND ((((ss_list_price#1260 >= 32.0) AND (ss_list_price#1260 <= 42.0)) OR ((ss_coupon_amt#1267 >= 4429.0) AND (ss_coupon_amt#1267 <= 5429.0))) OR ((ss_wholesale_cost#1259 >= 0.0) AND (ss_wholesale_cost#1259 <= 20.0))))
   :  :  :  :  :                       +- FileScan parquet spark_catalog.m.store_sales[ss_quantity#1258,ss_wholesale_cost#1259,ss_list_price#1260,ss_coupon_amt#1267] Batched: true, DataFilters: [isnotnull(ss_quantity#1258), (ss_quantity#1258 >= 0), (ss_quantity#1258 <= 5), ((((ss_list_price..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,0), LessThanOrEqual(ss_quantity,5), Or(Or..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:double,ss_list_price:double,ss_coupon_amt:double>
   :  :  :  :  +- BroadcastExchange IdentityBroadcastMode, [plan_id=72866]
   :  :  :  :     +- HashAggregate(keys=[], functions=[avg(ss_list_price#25688), count(ss_list_price#25688), count(distinct ss_list_price#26150)], output=[B2_LP#25661, B2_CNT#25662L, B2_CNTD#25663L])
   :  :  :  :        +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=72863]
   :  :  :  :           +- HashAggregate(keys=[], functions=[merge_avg(ss_list_price#25688), merge_count(ss_list_price#25688), partial_count(distinct ss_list_price#26150)], output=[sum#25900, count#25901L, count#25903L, count#26153L])
   :  :  :  :              +- HashAggregate(keys=[ss_list_price#26150], functions=[merge_avg(ss_list_price#25688), merge_count(ss_list_price#25688)], output=[ss_list_price#26150, sum#25900, count#25901L, count#25903L])
   :  :  :  :                 +- Exchange hashpartitioning(ss_list_price#26150, 200), ENSURE_REQUIREMENTS, [plan_id=72859]
   :  :  :  :                    +- HashAggregate(keys=[knownfloatingpointnormalized(normalizenanandzero(ss_list_price#25688)) AS ss_list_price#26150], functions=[partial_avg(ss_list_price#25688), partial_count(ss_list_price#25688)], output=[ss_list_price#26150, sum#25900, count#25901L, count#25903L])
   :  :  :  :                       +- Project [ss_list_price#25688]
   :  :  :  :                          +- Filter (((isnotnull(ss_quantity#25686) AND (ss_quantity#25686 >= 6)) AND (ss_quantity#25686 <= 10)) AND ((((ss_list_price#25688 >= 170.0) AND (ss_list_price#25688 <= 180.0)) OR ((ss_coupon_amt#25695 >= 4727.0) AND (ss_coupon_amt#25695 <= 5727.0))) OR ((ss_wholesale_cost#25687 >= 8.0) AND (ss_wholesale_cost#25687 <= 28.0))))
   :  :  :  :                             +- FileScan parquet spark_catalog.m.store_sales[ss_quantity#25686,ss_wholesale_cost#25687,ss_list_price#25688,ss_coupon_amt#25695] Batched: true, DataFilters: [isnotnull(ss_quantity#25686), (ss_quantity#25686 >= 6), (ss_quantity#25686 <= 10), ((((ss_list_p..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,6), LessThanOrEqual(ss_quantity,10), Or(O..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:double,ss_list_price:double,ss_coupon_amt:double>
   :  :  :  +- BroadcastExchange IdentityBroadcastMode, [plan_id=72875]
   :  :  :     +- HashAggregate(keys=[], functions=[avg(ss_list_price#25711), count(ss_list_price#25711), count(distinct ss_list_price#26155)], output=[B3_LP#25664, B3_CNT#25665L, B3_CNTD#25666L])
   :  :  :        +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=72872]
   :  :  :           +- HashAggregate(keys=[], functions=[merge_avg(ss_list_price#25711), merge_count(ss_list_price#25711), partial_count(distinct ss_list_price#26155)], output=[sum#25911, count#25912L, count#25914L, count#26158L])
   :  :  :              +- HashAggregate(keys=[ss_list_price#26155], functions=[merge_avg(ss_list_price#25711), merge_count(ss_list_price#25711)], output=[ss_list_price#26155, sum#25911, count#25912L, count#25914L])
   :  :  :                 +- Exchange hashpartitioning(ss_list_price#26155, 200), ENSURE_REQUIREMENTS, [plan_id=72868]
   :  :  :                    +- HashAggregate(keys=[knownfloatingpointnormalized(normalizenanandzero(ss_list_price#25711)) AS ss_list_price#26155], functions=[partial_avg(ss_list_price#25711), partial_count(ss_list_price#25711)], output=[ss_list_price#26155, sum#25911, count#25912L, count#25914L])
   :  :  :                       +- Project [ss_list_price#25711]
   :  :  :                          +- Filter (((isnotnull(ss_quantity#25709) AND (ss_quantity#25709 >= 11)) AND (ss_quantity#25709 <= 15)) AND ((((ss_list_price#25711 >= 124.0) AND (ss_list_price#25711 <= 134.0)) OR ((ss_coupon_amt#25718 >= 9657.0) AND (ss_coupon_amt#25718 <= 10657.0))) OR ((ss_wholesale_cost#25710 >= 43.0) AND (ss_wholesale_cost#25710 <= 63.0))))
   :  :  :                             +- FileScan parquet spark_catalog.m.store_sales[ss_quantity#25709,ss_wholesale_cost#25710,ss_list_price#25711,ss_coupon_amt#25718] Batched: true, DataFilters: [isnotnull(ss_quantity#25709), (ss_quantity#25709 >= 11), (ss_quantity#25709 <= 15), ((((ss_list_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,11), LessThanOrEqual(ss_quantity,15), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:double,ss_list_price:double,ss_coupon_amt:double>
   :  :  +- BroadcastExchange IdentityBroadcastMode, [plan_id=72884]
   :  :     +- HashAggregate(keys=[], functions=[avg(ss_list_price#25734), count(ss_list_price#25734), count(distinct ss_list_price#26160)], output=[B4_LP#25667, B4_CNT#25668L, B4_CNTD#25669L])
   :  :        +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=72881]
   :  :           +- HashAggregate(keys=[], functions=[merge_avg(ss_list_price#25734), merge_count(ss_list_price#25734), partial_count(distinct ss_list_price#26160)], output=[sum#25922, count#25923L, count#25925L, count#26163L])
   :  :              +- HashAggregate(keys=[ss_list_price#26160], functions=[merge_avg(ss_list_price#25734), merge_count(ss_list_price#25734)], output=[ss_list_price#26160, sum#25922, count#25923L, count#25925L])
   :  :                 +- Exchange hashpartitioning(ss_list_price#26160, 200), ENSURE_REQUIREMENTS, [plan_id=72877]
   :  :                    +- HashAggregate(keys=[knownfloatingpointnormalized(normalizenanandzero(ss_list_price#25734)) AS ss_list_price#26160], functions=[partial_avg(ss_list_price#25734), partial_count(ss_list_price#25734)], output=[ss_list_price#26160, sum#25922, count#25923L, count#25925L])
   :  :                       +- Project [ss_list_price#25734]
   :  :                          +- Filter (((isnotnull(ss_quantity#25732) AND (ss_quantity#25732 >= 16)) AND (ss_quantity#25732 <= 20)) AND ((((ss_list_price#25734 >= 104.0) AND (ss_list_price#25734 <= 114.0)) OR ((ss_coupon_amt#25741 >= 17161.0) AND (ss_coupon_amt#25741 <= 18161.0))) OR ((ss_wholesale_cost#25733 >= 34.0) AND (ss_wholesale_cost#25733 <= 54.0))))
   :  :                             +- FileScan parquet spark_catalog.m.store_sales[ss_quantity#25732,ss_wholesale_cost#25733,ss_list_price#25734,ss_coupon_amt#25741] Batched: true, DataFilters: [isnotnull(ss_quantity#25732), (ss_quantity#25732 >= 16), (ss_quantity#25732 <= 20), ((((ss_list_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,16), LessThanOrEqual(ss_quantity,20), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:double,ss_list_price:double,ss_coupon_amt:double>
   :  +- BroadcastExchange IdentityBroadcastMode, [plan_id=72893]
   :     +- HashAggregate(keys=[], functions=[avg(ss_list_price#25757), count(ss_list_price#25757), count(distinct ss_list_price#26165)], output=[B5_LP#25670, B5_CNT#25671L, B5_CNTD#25672L])
   :        +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=72890]
   :           +- HashAggregate(keys=[], functions=[merge_avg(ss_list_price#25757), merge_count(ss_list_price#25757), partial_count(distinct ss_list_price#26165)], output=[sum#25933, count#25934L, count#25936L, count#26168L])
   :              +- HashAggregate(keys=[ss_list_price#26165], functions=[merge_avg(ss_list_price#25757), merge_count(ss_list_price#25757)], output=[ss_list_price#26165, sum#25933, count#25934L, count#25936L])
   :                 +- Exchange hashpartitioning(ss_list_price#26165, 200), ENSURE_REQUIREMENTS, [plan_id=72886]
   :                    +- HashAggregate(keys=[knownfloatingpointnormalized(normalizenanandzero(ss_list_price#25757)) AS ss_list_price#26165], functions=[partial_avg(ss_list_price#25757), partial_count(ss_list_price#25757)], output=[ss_list_price#26165, sum#25933, count#25934L, count#25936L])
   :                       +- Project [ss_list_price#25757]
   :                          +- Filter (((isnotnull(ss_quantity#25755) AND (ss_quantity#25755 >= 21)) AND (ss_quantity#25755 <= 25)) AND ((((ss_list_price#25757 >= 73.0) AND (ss_list_price#25757 <= 83.0)) OR ((ss_coupon_amt#25764 >= 17064.0) AND (ss_coupon_amt#25764 <= 18064.0))) OR ((ss_wholesale_cost#25756 >= 56.0) AND (ss_wholesale_cost#25756 <= 76.0))))
   :                             +- FileScan parquet spark_catalog.m.store_sales[ss_quantity#25755,ss_wholesale_cost#25756,ss_list_price#25757,ss_coupon_amt#25764] Batched: true, DataFilters: [isnotnull(ss_quantity#25755), (ss_quantity#25755 >= 21), (ss_quantity#25755 <= 25), ((((ss_list_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,25), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:double,ss_list_price:double,ss_coupon_amt:double>
   +- BroadcastExchange IdentityBroadcastMode, [plan_id=72902]
      +- HashAggregate(keys=[], functions=[avg(ss_list_price#25780), count(ss_list_price#25780), count(distinct ss_list_price#26170)], output=[B6_LP#25673, B6_CNT#25674L, B6_CNTD#25675L])
         +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=72899]
            +- HashAggregate(keys=[], functions=[merge_avg(ss_list_price#25780), merge_count(ss_list_price#25780), partial_count(distinct ss_list_price#26170)], output=[sum#25944, count#25945L, count#25947L, count#26173L])
               +- HashAggregate(keys=[ss_list_price#26170], functions=[merge_avg(ss_list_price#25780), merge_count(ss_list_price#25780)], output=[ss_list_price#26170, sum#25944, count#25945L, count#25947L])
                  +- Exchange hashpartitioning(ss_list_price#26170, 200), ENSURE_REQUIREMENTS, [plan_id=72895]
                     +- HashAggregate(keys=[knownfloatingpointnormalized(normalizenanandzero(ss_list_price#25780)) AS ss_list_price#26170], functions=[partial_avg(ss_list_price#25780), partial_count(ss_list_price#25780)], output=[ss_list_price#26170, sum#25944, count#25945L, count#25947L])
                        +- Project [ss_list_price#25780]
                           +- Filter (((isnotnull(ss_quantity#25778) AND (ss_quantity#25778 >= 26)) AND (ss_quantity#25778 <= 30)) AND ((((ss_list_price#25780 >= 65.0) AND (ss_list_price#25780 <= 75.0)) OR ((ss_coupon_amt#25787 >= 10899.0) AND (ss_coupon_amt#25787 <= 11899.0))) OR ((ss_wholesale_cost#25779 >= 54.0) AND (ss_wholesale_cost#25779 <= 74.0))))
                              +- FileScan parquet spark_catalog.m.store_sales[ss_quantity#25778,ss_wholesale_cost#25779,ss_list_price#25780,ss_coupon_amt#25787] Batched: true, DataFilters: [isnotnull(ss_quantity#25778), (ss_quantity#25778 >= 26), (ss_quantity#25778 <= 30), ((((ss_list_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,26), LessThanOrEqual(ss_quantity,30), Or(..., ReadSchema: struct<ss_quantity:int,ss_wholesale_cost:double,ss_list_price:double,ss_coupon_amt:double>
