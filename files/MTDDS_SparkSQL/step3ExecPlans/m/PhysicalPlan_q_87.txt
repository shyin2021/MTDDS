AdaptiveSparkPlan isFinalPlan=false
+- HashAggregate(keys=[], functions=[count(1)], output=[count(1)#47863L])
   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=166052]
      +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#47873L])
         +- Project
            +- SortMergeJoin [coalesce(c_last_name#90, ), isnull(c_last_name#90), coalesce(c_first_name#89, ), isnull(c_first_name#89), coalesce(d_date#26, ), isnull(d_date#26)], [coalesce(c_last_name#47854, ), isnull(c_last_name#47854), coalesce(c_first_name#47853, ), isnull(c_first_name#47853), coalesce(d_date#47819, ), isnull(d_date#47819)], LeftAnti
               :- SortMergeJoin [coalesce(c_last_name#90, ), isnull(c_last_name#90), coalesce(c_first_name#89, ), isnull(c_first_name#89), coalesce(d_date#26, ), isnull(d_date#26)], [coalesce(c_last_name#47808, ), isnull(c_last_name#47808), coalesce(c_first_name#47807, ), isnull(c_first_name#47807), coalesce(d_date#47773, ), isnull(d_date#47773)], LeftAnti
               :  :- Sort [coalesce(c_last_name#90, ) ASC NULLS FIRST, isnull(c_last_name#90) ASC NULLS FIRST, coalesce(c_first_name#89, ) ASC NULLS FIRST, isnull(c_first_name#89) ASC NULLS FIRST, coalesce(d_date#26, ) ASC NULLS FIRST, isnull(d_date#26) ASC NULLS FIRST], false, 0
               :  :  +- Exchange hashpartitioning(coalesce(c_last_name#90, ), isnull(c_last_name#90), coalesce(c_first_name#89, ), isnull(c_first_name#89), coalesce(d_date#26, ), isnull(d_date#26), 200), ENSURE_REQUIREMENTS, [plan_id=166028]
               :  :     +- HashAggregate(keys=[c_last_name#90, c_first_name#89, d_date#26], functions=[], output=[c_last_name#90, c_first_name#89, d_date#26])
               :  :        +- Exchange hashpartitioning(c_last_name#90, c_first_name#89, d_date#26, 200), ENSURE_REQUIREMENTS, [plan_id=166013]
               :  :           +- HashAggregate(keys=[c_last_name#90, c_first_name#89, d_date#26], functions=[], output=[c_last_name#90, c_first_name#89, d_date#26])
               :  :              +- Project [c_last_name#90, c_first_name#89, d_date#26]
               :  :                 +- BroadcastHashJoin [ss_customer_sk#1251], [c_customer_sk#81], Inner, BuildRight, false
               :  :                    :- Project [ss_customer_sk#1251, d_date#26]
               :  :                    :  +- BroadcastHashJoin [ss_sold_date_sk#1248], [d_date_sk#24], Inner, BuildRight, false
               :  :                    :     :- Filter (isnotnull(ss_sold_date_sk#1248) AND isnotnull(ss_customer_sk#1251))
               :  :                    :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#1248,ss_customer_sk#1251] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#1248), isnotnull(ss_customer_sk#1251)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_customer_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_customer_sk:int>
               :  :                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=166004]
               :  :                    :        +- Project [d_date_sk#24, d_date#26]
               :  :                    :           +- Filter (((isnotnull(d_month_seq#27) AND (d_month_seq#27 >= 1197)) AND (d_month_seq#27 <= 1208)) AND isnotnull(d_date_sk#24))
               :  :                    :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#24,d_date#26,d_month_seq#27] Batched: true, DataFilters: [isnotnull(d_month_seq#27), (d_month_seq#27 >= 1197), (d_month_seq#27 <= 1208), isnotnull(d_date_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_date_sk:int,d_date:string,d_month_seq:int>
               :  :                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=166008]
               :  :                       +- Filter isnotnull(c_customer_sk#81)
               :  :                          +- FileScan parquet spark_catalog.m.customer[c_customer_sk#81,c_first_name#89,c_last_name#90] Batched: true, DataFilters: [isnotnull(c_customer_sk#81)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string>
               :  +- Sort [coalesce(c_last_name#47808, ) ASC NULLS FIRST, isnull(c_last_name#47808) ASC NULLS FIRST, coalesce(c_first_name#47807, ) ASC NULLS FIRST, isnull(c_first_name#47807) ASC NULLS FIRST, coalesce(d_date#47773, ) ASC NULLS FIRST, isnull(d_date#47773) ASC NULLS FIRST], false, 0
               :     +- Exchange hashpartitioning(coalesce(c_last_name#47808, ), isnull(c_last_name#47808), coalesce(c_first_name#47807, ), isnull(c_first_name#47807), coalesce(d_date#47773, ), isnull(d_date#47773), 200), ENSURE_REQUIREMENTS, [plan_id=166029]
               :        +- HashAggregate(keys=[c_last_name#47808, c_first_name#47807, d_date#47773], functions=[], output=[c_last_name#47808, c_first_name#47807, d_date#47773])
               :           +- Exchange hashpartitioning(c_last_name#47808, c_first_name#47807, d_date#47773, 200), ENSURE_REQUIREMENTS, [plan_id=166024]
               :              +- HashAggregate(keys=[c_last_name#47808, c_first_name#47807, d_date#47773], functions=[], output=[c_last_name#47808, c_first_name#47807, d_date#47773])
               :                 +- Project [c_last_name#47808, c_first_name#47807, d_date#47773]
               :                    +- BroadcastHashJoin [cs_bill_customer_sk#464], [c_customer_sk#47799], Inner, BuildRight, false
               :                       :- Project [cs_bill_customer_sk#464, d_date#47773]
               :                       :  +- BroadcastHashJoin [cs_sold_date_sk#461], [d_date_sk#47771], Inner, BuildRight, false
               :                       :     :- Filter (isnotnull(cs_sold_date_sk#461) AND isnotnull(cs_bill_customer_sk#464))
               :                       :     :  +- FileScan parquet spark_catalog.m.catalog_sales[cs_sold_date_sk#461,cs_bill_customer_sk#464] Batched: true, DataFilters: [isnotnull(cs_sold_date_sk#461), isnotnull(cs_bill_customer_sk#464)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_sold_date_sk), IsNotNull(cs_bill_customer_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_bill_customer_sk:int>
               :                       :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=166015]
               :                       :        +- Project [d_date_sk#47771, d_date#47773]
               :                       :           +- Filter (((isnotnull(d_month_seq#47774) AND (d_month_seq#47774 >= 1197)) AND (d_month_seq#47774 <= 1208)) AND isnotnull(d_date_sk#47771))
               :                       :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#47771,d_date#47773,d_month_seq#47774] Batched: true, DataFilters: [isnotnull(d_month_seq#47774), (d_month_seq#47774 >= 1197), (d_month_seq#47774 <= 1208), isnotnul..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_date_sk:int,d_date:string,d_month_seq:int>
               :                       +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=166019]
               :                          +- Filter isnotnull(c_customer_sk#47799)
               :                             +- FileScan parquet spark_catalog.m.customer[c_customer_sk#47799,c_first_name#47807,c_last_name#47808] Batched: true, DataFilters: [isnotnull(c_customer_sk#47799)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string>
               +- Sort [coalesce(c_last_name#47854, ) ASC NULLS FIRST, isnull(c_last_name#47854) ASC NULLS FIRST, coalesce(c_first_name#47853, ) ASC NULLS FIRST, isnull(c_first_name#47853) ASC NULLS FIRST, coalesce(d_date#47819, ) ASC NULLS FIRST, isnull(d_date#47819) ASC NULLS FIRST], false, 0
                  +- Exchange hashpartitioning(coalesce(c_last_name#47854, ), isnull(c_last_name#47854), coalesce(c_first_name#47853, ), isnull(c_first_name#47853), coalesce(d_date#47819, ), isnull(d_date#47819), 200), ENSURE_REQUIREMENTS, [plan_id=166046]
                     +- HashAggregate(keys=[c_last_name#47854, c_first_name#47853, d_date#47819], functions=[], output=[c_last_name#47854, c_first_name#47853, d_date#47819])
                        +- Exchange hashpartitioning(c_last_name#47854, c_first_name#47853, d_date#47819, 200), ENSURE_REQUIREMENTS, [plan_id=166042]
                           +- HashAggregate(keys=[c_last_name#47854, c_first_name#47853, d_date#47819], functions=[], output=[c_last_name#47854, c_first_name#47853, d_date#47819])
                              +- Project [c_last_name#47854, c_first_name#47853, d_date#47819]
                                 +- BroadcastHashJoin [ws_bill_customer_sk#431], [c_customer_sk#47845], Inner, BuildRight, false
                                    :- Project [ws_bill_customer_sk#431, d_date#47819]
                                    :  +- BroadcastHashJoin [ws_sold_date_sk#427], [d_date_sk#47817], Inner, BuildRight, false
                                    :     :- Filter (isnotnull(ws_sold_date_sk#427) AND isnotnull(ws_bill_customer_sk#431))
                                    :     :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_date_sk#427,ws_bill_customer_sk#431] Batched: true, DataFilters: [isnotnull(ws_sold_date_sk#427), isnotnull(ws_bill_customer_sk#431)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_sold_date_sk), IsNotNull(ws_bill_customer_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_bill_customer_sk:int>
                                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=166033]
                                    :        +- Project [d_date_sk#47817, d_date#47819]
                                    :           +- Filter (((isnotnull(d_month_seq#47820) AND (d_month_seq#47820 >= 1197)) AND (d_month_seq#47820 <= 1208)) AND isnotnull(d_date_sk#47817))
                                    :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#47817,d_date#47819,d_month_seq#47820] Batched: true, DataFilters: [isnotnull(d_month_seq#47820), (d_month_seq#47820 >= 1197), (d_month_seq#47820 <= 1208), isnotnul..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1197), LessThanOrEqual(d_month_seq,1208),..., ReadSchema: struct<d_date_sk:int,d_date:string,d_month_seq:int>
                                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=166037]
                                       +- Filter isnotnull(c_customer_sk#47845)
                                          +- FileScan parquet spark_catalog.m.customer[c_customer_sk#47845,c_first_name#47853,c_last_name#47854] Batched: true, DataFilters: [isnotnull(c_customer_sk#47845)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string>
