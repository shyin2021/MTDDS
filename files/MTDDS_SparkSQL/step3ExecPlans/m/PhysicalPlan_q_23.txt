AdaptiveSparkPlan isFinalPlan=false
+- TakeOrderedAndProject(limit=100, orderBy=[c_last_name#22617 ASC NULLS FIRST,c_first_name#22616 ASC NULLS FIRST,sales#22500 ASC NULLS FIRST], output=[c_last_name#22617,c_first_name#22616,sales#22500])
   +- Union
      :- HashAggregate(keys=[c_last_name#22617, c_first_name#22616], functions=[sum((cast(cs_quantity#479 as double) * cs_list_price#481))], output=[c_last_name#22617, c_first_name#22616, sales#22500])
      :  +- Exchange hashpartitioning(c_last_name#22617, c_first_name#22616, 200), ENSURE_REQUIREMENTS, [plan_id=65215]
      :     +- HashAggregate(keys=[c_last_name#22617, c_first_name#22616], functions=[partial_sum((cast(cs_quantity#479 as double) * cs_list_price#481))], output=[c_last_name#22617, c_first_name#22616, sum#23486])
      :        +- Project [cs_quantity#479, cs_list_price#481, c_first_name#22616, c_last_name#22617]
      :           +- BroadcastHashJoin [cs_sold_date_sk#461], [d_date_sk#22626], Inner, BuildRight, false
      :              :- Project [cs_sold_date_sk#461, cs_quantity#479, cs_list_price#481, c_first_name#22616, c_last_name#22617]
      :              :  +- BroadcastHashJoin [cs_bill_customer_sk#464], [c_customer_sk#22608], Inner, BuildRight, false
      :              :     :- SortMergeJoin [cs_bill_customer_sk#464], [c_customer_sk#22590], LeftSemi
      :              :     :  :- Sort [cs_bill_customer_sk#464 ASC NULLS FIRST], false, 0
      :              :     :  :  +- Exchange hashpartitioning(cs_bill_customer_sk#464, 200), ENSURE_REQUIREMENTS, [plan_id=65186]
      :              :     :  :     +- Project [cs_sold_date_sk#461, cs_bill_customer_sk#464, cs_quantity#479, cs_list_price#481]
      :              :     :  :        +- SortMergeJoin [cs_item_sk#476], [item_sk#22507], LeftSemi
      :              :     :  :           :- Sort [cs_item_sk#476 ASC NULLS FIRST], false, 0
      :              :     :  :           :  +- Exchange hashpartitioning(cs_item_sk#476, 200), ENSURE_REQUIREMENTS, [plan_id=65169]
      :              :     :  :           :     +- Filter (isnotnull(cs_bill_customer_sk#464) AND isnotnull(cs_sold_date_sk#461))
      :              :     :  :           :        +- FileScan parquet spark_catalog.m.catalog_sales[cs_sold_date_sk#461,cs_bill_customer_sk#464,cs_item_sk#476,cs_quantity#479,cs_list_price#481] Batched: true, DataFilters: [isnotnull(cs_bill_customer_sk#464), isnotnull(cs_sold_date_sk#461)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_bill_customer_sk), IsNotNull(cs_sold_date_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_bill_customer_sk:int,cs_item_sk:int,cs_quantity:int,cs_list_price:d...
      :              :     :  :           +- Sort [item_sk#22507 ASC NULLS FIRST], false, 0
      :              :     :  :              +- Exchange hashpartitioning(item_sk#22507, 200), ENSURE_REQUIREMENTS, [plan_id=65170]
      :              :     :  :                 +- Project [item_sk#22507]
      :              :     :  :                    +- Filter (cnt#22509L > 4)
      :              :     :  :                       +- HashAggregate(keys=[_groupingexpression#23559, i_item_sk#1271, d_date#26], functions=[count(1)], output=[item_sk#22507, cnt#22509L])
      :              :     :  :                          +- Exchange hashpartitioning(_groupingexpression#23559, i_item_sk#1271, d_date#26, 200), ENSURE_REQUIREMENTS, [plan_id=65163]
      :              :     :  :                             +- HashAggregate(keys=[_groupingexpression#23559, i_item_sk#1271, d_date#26], functions=[partial_count(1)], output=[_groupingexpression#23559, i_item_sk#1271, d_date#26, count#23488L])
      :              :     :  :                                +- Project [d_date#26, i_item_sk#1271, substr(i_item_desc#1275, 1, 30) AS _groupingexpression#23559]
      :              :     :  :                                   +- BroadcastHashJoin [ss_item_sk#1250], [i_item_sk#1271], Inner, BuildRight, false
      :              :     :  :                                      :- Project [ss_item_sk#1250, d_date#26]
      :              :     :  :                                      :  +- BroadcastHashJoin [ss_sold_date_sk#1248], [d_date_sk#24], Inner, BuildRight, false
      :              :     :  :                                      :     :- Filter (isnotnull(ss_sold_date_sk#1248) AND isnotnull(ss_item_sk#1250))
      :              :     :  :                                      :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#1248,ss_item_sk#1250] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#1248), isnotnull(ss_item_sk#1250)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_item_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int>
      :              :     :  :                                      :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=65154]
      :              :     :  :                                      :        +- Project [d_date_sk#24, d_date#26]
      :              :     :  :                                      :           +- Filter (d_year#30 IN (1999,2000,2001,2002) AND isnotnull(d_date_sk#24))
      :              :     :  :                                      :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#24,d_date#26,d_year#30] Batched: true, DataFilters: [d_year#30 IN (1999,2000,2001,2002), isnotnull(d_date_sk#24)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [In(d_year, [1999,2000,2001,2002]), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_date:string,d_year:int>
      :              :     :  :                                      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=65158]
      :              :     :  :                                         +- Filter isnotnull(i_item_sk#1271)
      :              :     :  :                                            +- FileScan parquet spark_catalog.m.item[i_item_sk#1271,i_item_desc#1275] Batched: true, DataFilters: [isnotnull(i_item_sk#1271)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_item_desc:string>
      :              :     :  +- Sort [c_customer_sk#22590 ASC NULLS FIRST], false, 0
      :              :     :     +- Project [c_customer_sk#22590]
      :              :     :        +- Filter (isnotnull(ssales#22512) AND (ssales#22512 > (0.95 * Subquery subquery#22513, [id=#65061])))
      :              :     :           :  +- Subquery subquery#22513, [id=#65061]
      :              :     :           :     +- AdaptiveSparkPlan isFinalPlan=false
      :              :     :           :        +- HashAggregate(keys=[], functions=[max(csales#22510)], output=[tpcds_cmax#22511])
      :              :     :           :           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=65059]
      :              :     :           :              +- HashAggregate(keys=[], functions=[partial_max(csales#22510)], output=[max#23496])
      :              :     :           :                 +- HashAggregate(keys=[c_customer_sk#81], functions=[sum((cast(ss_quantity#22526 as double) * ss_sales_price#22529))], output=[csales#22510])
      :              :     :           :                    +- Exchange hashpartitioning(c_customer_sk#81, 200), ENSURE_REQUIREMENTS, [plan_id=65055]
      :              :     :           :                       +- HashAggregate(keys=[c_customer_sk#81], functions=[partial_sum((cast(ss_quantity#22526 as double) * ss_sales_price#22529))], output=[c_customer_sk#81, sum#23498])
      :              :     :           :                          +- Project [ss_quantity#22526, ss_sales_price#22529, c_customer_sk#81]
      :              :     :           :                             +- BroadcastHashJoin [ss_sold_date_sk#22516], [d_date_sk#22539], Inner, BuildRight, false
      :              :     :           :                                :- Project [ss_sold_date_sk#22516, ss_quantity#22526, ss_sales_price#22529, c_customer_sk#81]
      :              :     :           :                                :  +- BroadcastHashJoin [ss_customer_sk#22519], [c_customer_sk#81], Inner, BuildRight, false
      :              :     :           :                                :     :- Filter (isnotnull(ss_customer_sk#22519) AND isnotnull(ss_sold_date_sk#22516))
      :              :     :           :                                :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#22516,ss_customer_sk#22519,ss_quantity#22526,ss_sales_price#22529] Batched: true, DataFilters: [isnotnull(ss_customer_sk#22519), isnotnull(ss_sold_date_sk#22516)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_customer_sk), IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_customer_sk:int,ss_quantity:int,ss_sales_price:double>
      :              :     :           :                                :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=65046]
      :              :     :           :                                :        +- Filter isnotnull(c_customer_sk#81)
      :              :     :           :                                :           +- FileScan parquet spark_catalog.m.customer[c_customer_sk#81] Batched: true, DataFilters: [isnotnull(c_customer_sk#81)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int>
      :              :     :           :                                +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=65050]
      :              :     :           :                                   +- Project [d_date_sk#22539]
      :              :     :           :                                      +- Filter (d_year#22545 IN (1999,2000,2001,2002) AND isnotnull(d_date_sk#22539))
      :              :     :           :                                         +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#22539,d_year#22545] Batched: true, DataFilters: [d_year#22545 IN (1999,2000,2001,2002), isnotnull(d_date_sk#22539)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [In(d_year, [1999,2000,2001,2002]), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int>
      :              :     :           +- HashAggregate(keys=[c_customer_sk#22590], functions=[sum((cast(ss_quantity#22577 as double) * ss_sales_price#22580))], output=[c_customer_sk#22590, ssales#22512])
      :              :     :              +- Exchange hashpartitioning(c_customer_sk#22590, 200), ENSURE_REQUIREMENTS, [plan_id=65180]
      :              :     :                 +- HashAggregate(keys=[c_customer_sk#22590], functions=[partial_sum((cast(ss_quantity#22577 as double) * ss_sales_price#22580))], output=[c_customer_sk#22590, sum#23490])
      :              :     :                    +- Project [ss_quantity#22577, ss_sales_price#22580, c_customer_sk#22590]
      :              :     :                       +- BroadcastHashJoin [ss_customer_sk#22570], [c_customer_sk#22590], Inner, BuildRight, false
      :              :     :                          :- Filter isnotnull(ss_customer_sk#22570)
      :              :     :                          :  +- FileScan parquet spark_catalog.m.store_sales[ss_customer_sk#22570,ss_quantity#22577,ss_sales_price#22580] Batched: true, DataFilters: [isnotnull(ss_customer_sk#22570)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_customer_sk)], ReadSchema: struct<ss_customer_sk:int,ss_quantity:int,ss_sales_price:double>
      :              :     :                          +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=65175]
      :              :     :                             +- Filter isnotnull(c_customer_sk#22590)
      :              :     :                                +- FileScan parquet spark_catalog.m.customer[c_customer_sk#22590] Batched: true, DataFilters: [isnotnull(c_customer_sk#22590)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int>
      :              :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=65206]
      :              :        +- SortMergeJoin [c_customer_sk#22608], [c_customer_sk#22590], LeftSemi
      :              :           :- Sort [c_customer_sk#22608 ASC NULLS FIRST], false, 0
      :              :           :  +- Exchange hashpartitioning(c_customer_sk#22608, 200), ENSURE_REQUIREMENTS, [plan_id=65201]
      :              :           :     +- Filter isnotnull(c_customer_sk#22608)
      :              :           :        +- FileScan parquet spark_catalog.m.customer[c_customer_sk#22608,c_first_name#22616,c_last_name#22617] Batched: true, DataFilters: [isnotnull(c_customer_sk#22608)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string>
      :              :           +- Sort [c_customer_sk#22590 ASC NULLS FIRST], false, 0
      :              :              +- Project [c_customer_sk#22590]
      :              :                 +- Filter (isnotnull(ssales#22512) AND (ssales#22512 > (0.95 * Subquery subquery#22513, [id=#65065])))
      :              :                    :  +- Subquery subquery#22513, [id=#65065]
      :              :                    :     +- AdaptiveSparkPlan isFinalPlan=false
      :              :                    :        +- HashAggregate(keys=[], functions=[max(csales#22510)], output=[tpcds_cmax#22511])
      :              :                    :           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=65059]
      :              :                    :              +- HashAggregate(keys=[], functions=[partial_max(csales#22510)], output=[max#23496])
      :              :                    :                 +- HashAggregate(keys=[c_customer_sk#81], functions=[sum((cast(ss_quantity#22526 as double) * ss_sales_price#22529))], output=[csales#22510])
      :              :                    :                    +- Exchange hashpartitioning(c_customer_sk#81, 200), ENSURE_REQUIREMENTS, [plan_id=65055]
      :              :                    :                       +- HashAggregate(keys=[c_customer_sk#81], functions=[partial_sum((cast(ss_quantity#22526 as double) * ss_sales_price#22529))], output=[c_customer_sk#81, sum#23498])
      :              :                    :                          +- Project [ss_quantity#22526, ss_sales_price#22529, c_customer_sk#81]
      :              :                    :                             +- BroadcastHashJoin [ss_sold_date_sk#22516], [d_date_sk#22539], Inner, BuildRight, false
      :              :                    :                                :- Project [ss_sold_date_sk#22516, ss_quantity#22526, ss_sales_price#22529, c_customer_sk#81]
      :              :                    :                                :  +- BroadcastHashJoin [ss_customer_sk#22519], [c_customer_sk#81], Inner, BuildRight, false
      :              :                    :                                :     :- Filter (isnotnull(ss_customer_sk#22519) AND isnotnull(ss_sold_date_sk#22516))
      :              :                    :                                :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#22516,ss_customer_sk#22519,ss_quantity#22526,ss_sales_price#22529] Batched: true, DataFilters: [isnotnull(ss_customer_sk#22519), isnotnull(ss_sold_date_sk#22516)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_customer_sk), IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_customer_sk:int,ss_quantity:int,ss_sales_price:double>
      :              :                    :                                :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=65046]
      :              :                    :                                :        +- Filter isnotnull(c_customer_sk#81)
      :              :                    :                                :           +- FileScan parquet spark_catalog.m.customer[c_customer_sk#81] Batched: true, DataFilters: [isnotnull(c_customer_sk#81)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int>
      :              :                    :                                +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=65050]
      :              :                    :                                   +- Project [d_date_sk#22539]
      :              :                    :                                      +- Filter (d_year#22545 IN (1999,2000,2001,2002) AND isnotnull(d_date_sk#22539))
      :              :                    :                                         +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#22539,d_year#22545] Batched: true, DataFilters: [d_year#22545 IN (1999,2000,2001,2002), isnotnull(d_date_sk#22539)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [In(d_year, [1999,2000,2001,2002]), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int>
      :              :                    +- HashAggregate(keys=[c_customer_sk#22590], functions=[sum((cast(ss_quantity#22577 as double) * ss_sales_price#22580))], output=[c_customer_sk#22590, ssales#22512])
      :              :                       +- Exchange hashpartitioning(c_customer_sk#22590, 200), ENSURE_REQUIREMENTS, [plan_id=65195]
      :              :                          +- HashAggregate(keys=[c_customer_sk#22590], functions=[partial_sum((cast(ss_quantity#22577 as double) * ss_sales_price#22580))], output=[c_customer_sk#22590, sum#23490])
      :              :                             +- Project [ss_quantity#22577, ss_sales_price#22580, c_customer_sk#22590]
      :              :                                +- BroadcastHashJoin [ss_customer_sk#22570], [c_customer_sk#22590], Inner, BuildRight, false
      :              :                                   :- Filter isnotnull(ss_customer_sk#22570)
      :              :                                   :  +- FileScan parquet spark_catalog.m.store_sales[ss_customer_sk#22570,ss_quantity#22577,ss_sales_price#22580] Batched: true, DataFilters: [isnotnull(ss_customer_sk#22570)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_customer_sk)], ReadSchema: struct<ss_customer_sk:int,ss_quantity:int,ss_sales_price:double>
      :              :                                   +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=65190]
      :              :                                      +- Filter isnotnull(c_customer_sk#22590)
      :              :                                         +- FileScan parquet spark_catalog.m.customer[c_customer_sk#22590] Batched: true, DataFilters: [isnotnull(c_customer_sk#22590)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int>
      :              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=65210]
      :                 +- Project [d_date_sk#22626]
      :                    +- Filter ((((isnotnull(d_year#22632) AND isnotnull(d_moy#22634)) AND (d_year#22632 = 1999)) AND (d_moy#22634 = 7)) AND isnotnull(d_date_sk#22626))
      :                       +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#22626,d_year#22632,d_moy#22634] Batched: true, DataFilters: [isnotnull(d_year#22632), isnotnull(d_moy#22634), (d_year#22632 = 1999), (d_moy#22634 = 7), isnot..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), EqualTo(d_year,1999), EqualTo(d_moy,7), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>
      +- HashAggregate(keys=[c_last_name#22663, c_first_name#22662], functions=[sum((cast(ws_quantity#445 as double) * ws_list_price#447))], output=[c_last_name#22663, c_first_name#22662, sales#22503])
         +- Exchange hashpartitioning(c_last_name#22663, c_first_name#22662, 200), ENSURE_REQUIREMENTS, [plan_id=65278]
            +- HashAggregate(keys=[c_last_name#22663, c_first_name#22662], functions=[partial_sum((cast(ws_quantity#445 as double) * ws_list_price#447))], output=[c_last_name#22663, c_first_name#22662, sum#23492])
               +- Project [ws_quantity#445, ws_list_price#447, c_first_name#22662, c_last_name#22663]
                  +- BroadcastHashJoin [ws_sold_date_sk#427], [d_date_sk#22672], Inner, BuildRight, false
                     :- Project [ws_sold_date_sk#427, ws_quantity#445, ws_list_price#447, c_first_name#22662, c_last_name#22663]
                     :  +- BroadcastHashJoin [ws_bill_customer_sk#431], [c_customer_sk#22654], Inner, BuildRight, false
                     :     :- SortMergeJoin [ws_bill_customer_sk#431], [c_customer_sk#23660], LeftSemi
                     :     :  :- Sort [ws_bill_customer_sk#431 ASC NULLS FIRST], false, 0
                     :     :  :  +- Exchange hashpartitioning(ws_bill_customer_sk#431, 200), ENSURE_REQUIREMENTS, [plan_id=65249]
                     :     :  :     +- Project [ws_sold_date_sk#427, ws_bill_customer_sk#431, ws_quantity#445, ws_list_price#447]
                     :     :  :        +- SortMergeJoin [ws_item_sk#430], [item_sk#23634], LeftSemi
                     :     :  :           :- Sort [ws_item_sk#430 ASC NULLS FIRST], false, 0
                     :     :  :           :  +- Exchange hashpartitioning(ws_item_sk#430, 200), ENSURE_REQUIREMENTS, [plan_id=65232]
                     :     :  :           :     +- Filter (isnotnull(ws_bill_customer_sk#431) AND isnotnull(ws_sold_date_sk#427))
                     :     :  :           :        +- FileScan parquet spark_catalog.m.web_sales[ws_sold_date_sk#427,ws_item_sk#430,ws_bill_customer_sk#431,ws_quantity#445,ws_list_price#447] Batched: true, DataFilters: [isnotnull(ws_bill_customer_sk#431), isnotnull(ws_sold_date_sk#427)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_bill_customer_sk), IsNotNull(ws_sold_date_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_item_sk:int,ws_bill_customer_sk:int,ws_quantity:int,ws_list_price:d...
                     :     :  :           +- Sort [item_sk#23634 ASC NULLS FIRST], false, 0
                     :     :  :              +- Exchange hashpartitioning(item_sk#23634, 200), ENSURE_REQUIREMENTS, [plan_id=65233]
                     :     :  :                 +- Project [item_sk#23634]
                     :     :  :                    +- Filter (cnt#23636L > 4)
                     :     :  :                       +- HashAggregate(keys=[_groupingexpression#23559, i_item_sk#23611, d_date#23585], functions=[count(1)], output=[item_sk#23634, cnt#23636L])
                     :     :  :                          +- Exchange hashpartitioning(_groupingexpression#23559, i_item_sk#23611, d_date#23585, 200), ENSURE_REQUIREMENTS, [plan_id=65226]
                     :     :  :                             +- HashAggregate(keys=[_groupingexpression#23559, i_item_sk#23611, d_date#23585], functions=[partial_count(1)], output=[_groupingexpression#23559, i_item_sk#23611, d_date#23585, count#23488L])
                     :     :  :                                +- Project [d_date#23585, i_item_sk#23611, substr(i_item_desc#23615, 1, 30) AS _groupingexpression#23559]
                     :     :  :                                   +- BroadcastHashJoin [ss_item_sk#23562], [i_item_sk#23611], Inner, BuildRight, false
                     :     :  :                                      :- Project [ss_item_sk#23562, d_date#23585]
                     :     :  :                                      :  +- BroadcastHashJoin [ss_sold_date_sk#23560], [d_date_sk#23583], Inner, BuildRight, false
                     :     :  :                                      :     :- Filter (isnotnull(ss_sold_date_sk#23560) AND isnotnull(ss_item_sk#23562))
                     :     :  :                                      :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#23560,ss_item_sk#23562] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#23560), isnotnull(ss_item_sk#23562)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_item_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int>
                     :     :  :                                      :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=65217]
                     :     :  :                                      :        +- Project [d_date_sk#23583, d_date#23585]
                     :     :  :                                      :           +- Filter (d_year#23589 IN (1999,2000,2001,2002) AND isnotnull(d_date_sk#23583))
                     :     :  :                                      :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#23583,d_date#23585,d_year#23589] Batched: true, DataFilters: [d_year#23589 IN (1999,2000,2001,2002), isnotnull(d_date_sk#23583)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [In(d_year, [1999,2000,2001,2002]), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_date:string,d_year:int>
                     :     :  :                                      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=65221]
                     :     :  :                                         +- Filter isnotnull(i_item_sk#23611)
                     :     :  :                                            +- FileScan parquet spark_catalog.m.item[i_item_sk#23611,i_item_desc#23615] Batched: true, DataFilters: [isnotnull(i_item_sk#23611)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_item_desc:string>
                     :     :  +- Sort [c_customer_sk#23660 ASC NULLS FIRST], false, 0
                     :     :     +- Project [c_customer_sk#23660]
                     :     :        +- Filter (isnotnull(ssales#23747) AND (ssales#23747 > (0.95 * Subquery subquery#22513, [id=#65075])))
                     :     :           :  +- Subquery subquery#22513, [id=#65075]
                     :     :           :     +- AdaptiveSparkPlan isFinalPlan=false
                     :     :           :        +- HashAggregate(keys=[], functions=[max(csales#22510)], output=[tpcds_cmax#22511])
                     :     :           :           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=65059]
                     :     :           :              +- HashAggregate(keys=[], functions=[partial_max(csales#22510)], output=[max#23496])
                     :     :           :                 +- HashAggregate(keys=[c_customer_sk#81], functions=[sum((cast(ss_quantity#22526 as double) * ss_sales_price#22529))], output=[csales#22510])
                     :     :           :                    +- Exchange hashpartitioning(c_customer_sk#81, 200), ENSURE_REQUIREMENTS, [plan_id=65055]
                     :     :           :                       +- HashAggregate(keys=[c_customer_sk#81], functions=[partial_sum((cast(ss_quantity#22526 as double) * ss_sales_price#22529))], output=[c_customer_sk#81, sum#23498])
                     :     :           :                          +- Project [ss_quantity#22526, ss_sales_price#22529, c_customer_sk#81]
                     :     :           :                             +- BroadcastHashJoin [ss_sold_date_sk#22516], [d_date_sk#22539], Inner, BuildRight, false
                     :     :           :                                :- Project [ss_sold_date_sk#22516, ss_quantity#22526, ss_sales_price#22529, c_customer_sk#81]
                     :     :           :                                :  +- BroadcastHashJoin [ss_customer_sk#22519], [c_customer_sk#81], Inner, BuildRight, false
                     :     :           :                                :     :- Filter (isnotnull(ss_customer_sk#22519) AND isnotnull(ss_sold_date_sk#22516))
                     :     :           :                                :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#22516,ss_customer_sk#22519,ss_quantity#22526,ss_sales_price#22529] Batched: true, DataFilters: [isnotnull(ss_customer_sk#22519), isnotnull(ss_sold_date_sk#22516)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_customer_sk), IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_customer_sk:int,ss_quantity:int,ss_sales_price:double>
                     :     :           :                                :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=65046]
                     :     :           :                                :        +- Filter isnotnull(c_customer_sk#81)
                     :     :           :                                :           +- FileScan parquet spark_catalog.m.customer[c_customer_sk#81] Batched: true, DataFilters: [isnotnull(c_customer_sk#81)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int>
                     :     :           :                                +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=65050]
                     :     :           :                                   +- Project [d_date_sk#22539]
                     :     :           :                                      +- Filter (d_year#22545 IN (1999,2000,2001,2002) AND isnotnull(d_date_sk#22539))
                     :     :           :                                         +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#22539,d_year#22545] Batched: true, DataFilters: [d_year#22545 IN (1999,2000,2001,2002), isnotnull(d_date_sk#22539)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [In(d_year, [1999,2000,2001,2002]), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int>
                     :     :           +- HashAggregate(keys=[c_customer_sk#23660], functions=[sum((cast(ss_quantity#23647 as double) * ss_sales_price#23650))], output=[c_customer_sk#23660, ssales#23747])
                     :     :              +- Exchange hashpartitioning(c_customer_sk#23660, 200), ENSURE_REQUIREMENTS, [plan_id=65243]
                     :     :                 +- HashAggregate(keys=[c_customer_sk#23660], functions=[partial_sum((cast(ss_quantity#23647 as double) * ss_sales_price#23650))], output=[c_customer_sk#23660, sum#23749])
                     :     :                    +- Project [ss_quantity#23647, ss_sales_price#23650, c_customer_sk#23660]
                     :     :                       +- BroadcastHashJoin [ss_customer_sk#23640], [c_customer_sk#23660], Inner, BuildRight, false
                     :     :                          :- Filter isnotnull(ss_customer_sk#23640)
                     :     :                          :  +- FileScan parquet spark_catalog.m.store_sales[ss_customer_sk#23640,ss_quantity#23647,ss_sales_price#23650] Batched: true, DataFilters: [isnotnull(ss_customer_sk#23640)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_customer_sk)], ReadSchema: struct<ss_customer_sk:int,ss_quantity:int,ss_sales_price:double>
                     :     :                          +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=65238]
                     :     :                             +- Filter isnotnull(c_customer_sk#23660)
                     :     :                                +- FileScan parquet spark_catalog.m.customer[c_customer_sk#23660] Batched: true, DataFilters: [isnotnull(c_customer_sk#23660)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int>
                     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=65269]
                     :        +- SortMergeJoin [c_customer_sk#22654], [c_customer_sk#23660], LeftSemi
                     :           :- Sort [c_customer_sk#22654 ASC NULLS FIRST], false, 0
                     :           :  +- Exchange hashpartitioning(c_customer_sk#22654, 200), ENSURE_REQUIREMENTS, [plan_id=65264]
                     :           :     +- Filter isnotnull(c_customer_sk#22654)
                     :           :        +- FileScan parquet spark_catalog.m.customer[c_customer_sk#22654,c_first_name#22662,c_last_name#22663] Batched: true, DataFilters: [isnotnull(c_customer_sk#22654)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string>
                     :           +- Sort [c_customer_sk#23660 ASC NULLS FIRST], false, 0
                     :              +- Project [c_customer_sk#23660]
                     :                 +- Filter (isnotnull(ssales#23747) AND (ssales#23747 > (0.95 * Subquery subquery#22513, [id=#65079])))
                     :                    :  +- Subquery subquery#22513, [id=#65079]
                     :                    :     +- AdaptiveSparkPlan isFinalPlan=false
                     :                    :        +- HashAggregate(keys=[], functions=[max(csales#22510)], output=[tpcds_cmax#22511])
                     :                    :           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=65059]
                     :                    :              +- HashAggregate(keys=[], functions=[partial_max(csales#22510)], output=[max#23496])
                     :                    :                 +- HashAggregate(keys=[c_customer_sk#81], functions=[sum((cast(ss_quantity#22526 as double) * ss_sales_price#22529))], output=[csales#22510])
                     :                    :                    +- Exchange hashpartitioning(c_customer_sk#81, 200), ENSURE_REQUIREMENTS, [plan_id=65055]
                     :                    :                       +- HashAggregate(keys=[c_customer_sk#81], functions=[partial_sum((cast(ss_quantity#22526 as double) * ss_sales_price#22529))], output=[c_customer_sk#81, sum#23498])
                     :                    :                          +- Project [ss_quantity#22526, ss_sales_price#22529, c_customer_sk#81]
                     :                    :                             +- BroadcastHashJoin [ss_sold_date_sk#22516], [d_date_sk#22539], Inner, BuildRight, false
                     :                    :                                :- Project [ss_sold_date_sk#22516, ss_quantity#22526, ss_sales_price#22529, c_customer_sk#81]
                     :                    :                                :  +- BroadcastHashJoin [ss_customer_sk#22519], [c_customer_sk#81], Inner, BuildRight, false
                     :                    :                                :     :- Filter (isnotnull(ss_customer_sk#22519) AND isnotnull(ss_sold_date_sk#22516))
                     :                    :                                :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#22516,ss_customer_sk#22519,ss_quantity#22526,ss_sales_price#22529] Batched: true, DataFilters: [isnotnull(ss_customer_sk#22519), isnotnull(ss_sold_date_sk#22516)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_customer_sk), IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_customer_sk:int,ss_quantity:int,ss_sales_price:double>
                     :                    :                                :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=65046]
                     :                    :                                :        +- Filter isnotnull(c_customer_sk#81)
                     :                    :                                :           +- FileScan parquet spark_catalog.m.customer[c_customer_sk#81] Batched: true, DataFilters: [isnotnull(c_customer_sk#81)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int>
                     :                    :                                +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=65050]
                     :                    :                                   +- Project [d_date_sk#22539]
                     :                    :                                      +- Filter (d_year#22545 IN (1999,2000,2001,2002) AND isnotnull(d_date_sk#22539))
                     :                    :                                         +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#22539,d_year#22545] Batched: true, DataFilters: [d_year#22545 IN (1999,2000,2001,2002), isnotnull(d_date_sk#22539)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [In(d_year, [1999,2000,2001,2002]), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int>
                     :                    +- HashAggregate(keys=[c_customer_sk#23660], functions=[sum((cast(ss_quantity#23647 as double) * ss_sales_price#23650))], output=[c_customer_sk#23660, ssales#23747])
                     :                       +- Exchange hashpartitioning(c_customer_sk#23660, 200), ENSURE_REQUIREMENTS, [plan_id=65258]
                     :                          +- HashAggregate(keys=[c_customer_sk#23660], functions=[partial_sum((cast(ss_quantity#23647 as double) * ss_sales_price#23650))], output=[c_customer_sk#23660, sum#23749])
                     :                             +- Project [ss_quantity#23647, ss_sales_price#23650, c_customer_sk#23660]
                     :                                +- BroadcastHashJoin [ss_customer_sk#23640], [c_customer_sk#23660], Inner, BuildRight, false
                     :                                   :- Filter isnotnull(ss_customer_sk#23640)
                     :                                   :  +- FileScan parquet spark_catalog.m.store_sales[ss_customer_sk#23640,ss_quantity#23647,ss_sales_price#23650] Batched: true, DataFilters: [isnotnull(ss_customer_sk#23640)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_customer_sk)], ReadSchema: struct<ss_customer_sk:int,ss_quantity:int,ss_sales_price:double>
                     :                                   +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=65253]
                     :                                      +- Filter isnotnull(c_customer_sk#23660)
                     :                                         +- FileScan parquet spark_catalog.m.customer[c_customer_sk#23660] Batched: true, DataFilters: [isnotnull(c_customer_sk#23660)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int>
                     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=65273]
                        +- Project [d_date_sk#22672]
                           +- Filter ((((isnotnull(d_year#22678) AND isnotnull(d_moy#22680)) AND (d_year#22678 = 1999)) AND (d_moy#22680 = 7)) AND isnotnull(d_date_sk#22672))
                              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#22672,d_year#22678,d_moy#22680] Batched: true, DataFilters: [isnotnull(d_year#22678), isnotnull(d_moy#22680), (d_year#22678 = 1999), (d_moy#22680 = 7), isnot..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), EqualTo(d_year,1999), EqualTo(d_moy,7), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>
