AdaptiveSparkPlan isFinalPlan=false
+- Project [(cast(amc#48500L as decimal(15,4)) / cast(pmc#48501L as decimal(15,4))) AS am_pm_ratio#48502]
   +- BroadcastNestedLoopJoin BuildRight, Inner
      :- HashAggregate(keys=[], functions=[count(1)], output=[amc#48500L])
      :  +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=172791]
      :     +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#48577L])
      :        +- Project
      :           +- BroadcastHashJoin [ws_web_page_sk#439], [wp_web_page_sk#45845], Inner, BuildRight, false
      :              :- Project [ws_web_page_sk#439]
      :              :  +- BroadcastHashJoin [ws_sold_time_sk#428], [t_time_sk#39576], Inner, BuildRight, false
      :              :     :- Project [ws_sold_time_sk#428, ws_web_page_sk#439]
      :              :     :  +- BroadcastHashJoin [ws_ship_hdemo_sk#437], [hd_demo_sk#12110], Inner, BuildRight, false
      :              :     :     :- Filter ((isnotnull(ws_ship_hdemo_sk#437) AND isnotnull(ws_sold_time_sk#428)) AND isnotnull(ws_web_page_sk#439))
      :              :     :     :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_time_sk#428,ws_ship_hdemo_sk#437,ws_web_page_sk#439] Batched: true, DataFilters: [isnotnull(ws_ship_hdemo_sk#437), isnotnull(ws_sold_time_sk#428), isnotnull(ws_web_page_sk#439)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_ship_hdemo_sk), IsNotNull(ws_sold_time_sk), IsNotNull(ws_web_page_sk)], ReadSchema: struct<ws_sold_time_sk:int,ws_ship_hdemo_sk:int,ws_web_page_sk:int>
      :              :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=172778]
      :              :     :        +- Project [hd_demo_sk#12110]
      :              :     :           +- Filter ((isnotnull(hd_dep_count#12113) AND (hd_dep_count#12113 = 2)) AND isnotnull(hd_demo_sk#12110))
      :              :     :              +- FileScan parquet spark_catalog.m.household_demographics[hd_demo_sk#12110,hd_dep_count#12113] Batched: true, DataFilters: [isnotnull(hd_dep_count#12113), (hd_dep_count#12113 = 2), isnotnull(hd_demo_sk#12110)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/household_demograp..., PartitionFilters: [], PushedFilters: [IsNotNull(hd_dep_count), EqualTo(hd_dep_count,2), IsNotNull(hd_demo_sk)], ReadSchema: struct<hd_demo_sk:int,hd_dep_count:int>
      :              :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=172782]
      :              :        +- Project [t_time_sk#39576]
      :              :           +- Filter (((isnotnull(t_hour#39579) AND (t_hour#39579 >= 8)) AND (t_hour#39579 <= 9)) AND isnotnull(t_time_sk#39576))
      :              :              +- FileScan parquet spark_catalog.m.time_dim[t_time_sk#39576,t_hour#39579] Batched: true, DataFilters: [isnotnull(t_hour#39579), (t_hour#39579 >= 8), (t_hour#39579 <= 9), isnotnull(t_time_sk#39576)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/time_dim], PartitionFilters: [], PushedFilters: [IsNotNull(t_hour), GreaterThanOrEqual(t_hour,8), LessThanOrEqual(t_hour,9), IsNotNull(t_time_sk)], ReadSchema: struct<t_time_sk:int,t_hour:int>
      :              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=172786]
      :                 +- Project [wp_web_page_sk#45845]
      :                    +- Filter (((isnotnull(wp_char_count#45855) AND (wp_char_count#45855 >= 5000)) AND (wp_char_count#45855 <= 5200)) AND isnotnull(wp_web_page_sk#45845))
      :                       +- FileScan parquet spark_catalog.m.web_page[wp_web_page_sk#45845,wp_char_count#45855] Batched: true, DataFilters: [isnotnull(wp_char_count#45855), (wp_char_count#45855 >= 5000), (wp_char_count#45855 <= 5200), is..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_page], PartitionFilters: [], PushedFilters: [IsNotNull(wp_char_count), GreaterThanOrEqual(wp_char_count,5000), LessThanOrEqual(wp_char_count,..., ReadSchema: struct<wp_web_page_sk:int,wp_char_count:int>
      +- BroadcastExchange IdentityBroadcastMode, [plan_id=172809]
         +- HashAggregate(keys=[], functions=[count(1)], output=[pmc#48501L])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=172806]
               +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#48579L])
                  +- Project
                     +- BroadcastHashJoin [ws_web_page_sk#48517], [wp_web_page_sk#48554], Inner, BuildRight, false
                        :- Project [ws_web_page_sk#48517]
                        :  +- BroadcastHashJoin [ws_sold_time_sk#48506], [t_time_sk#48544], Inner, BuildRight, false
                        :     :- Project [ws_sold_time_sk#48506, ws_web_page_sk#48517]
                        :     :  +- BroadcastHashJoin [ws_ship_hdemo_sk#48515], [hd_demo_sk#48539], Inner, BuildRight, false
                        :     :     :- Filter ((isnotnull(ws_ship_hdemo_sk#48515) AND isnotnull(ws_sold_time_sk#48506)) AND isnotnull(ws_web_page_sk#48517))
                        :     :     :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_time_sk#48506,ws_ship_hdemo_sk#48515,ws_web_page_sk#48517] Batched: true, DataFilters: [isnotnull(ws_ship_hdemo_sk#48515), isnotnull(ws_sold_time_sk#48506), isnotnull(ws_web_page_sk#48..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_ship_hdemo_sk), IsNotNull(ws_sold_time_sk), IsNotNull(ws_web_page_sk)], ReadSchema: struct<ws_sold_time_sk:int,ws_ship_hdemo_sk:int,ws_web_page_sk:int>
                        :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=172793]
                        :     :        +- Project [hd_demo_sk#48539]
                        :     :           +- Filter ((isnotnull(hd_dep_count#48542) AND (hd_dep_count#48542 = 2)) AND isnotnull(hd_demo_sk#48539))
                        :     :              +- FileScan parquet spark_catalog.m.household_demographics[hd_demo_sk#48539,hd_dep_count#48542] Batched: true, DataFilters: [isnotnull(hd_dep_count#48542), (hd_dep_count#48542 = 2), isnotnull(hd_demo_sk#48539)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/household_demograp..., PartitionFilters: [], PushedFilters: [IsNotNull(hd_dep_count), EqualTo(hd_dep_count,2), IsNotNull(hd_demo_sk)], ReadSchema: struct<hd_demo_sk:int,hd_dep_count:int>
                        :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=172797]
                        :        +- Project [t_time_sk#48544]
                        :           +- Filter (((isnotnull(t_hour#48547) AND (t_hour#48547 >= 14)) AND (t_hour#48547 <= 15)) AND isnotnull(t_time_sk#48544))
                        :              +- FileScan parquet spark_catalog.m.time_dim[t_time_sk#48544,t_hour#48547] Batched: true, DataFilters: [isnotnull(t_hour#48547), (t_hour#48547 >= 14), (t_hour#48547 <= 15), isnotnull(t_time_sk#48544)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/time_dim], PartitionFilters: [], PushedFilters: [IsNotNull(t_hour), GreaterThanOrEqual(t_hour,14), LessThanOrEqual(t_hour,15), IsNotNull(t_time_sk)], ReadSchema: struct<t_time_sk:int,t_hour:int>
                        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=172801]
                           +- Project [wp_web_page_sk#48554]
                              +- Filter (((isnotnull(wp_char_count#48564) AND (wp_char_count#48564 >= 5000)) AND (wp_char_count#48564 <= 5200)) AND isnotnull(wp_web_page_sk#48554))
                                 +- FileScan parquet spark_catalog.m.web_page[wp_web_page_sk#48554,wp_char_count#48564] Batched: true, DataFilters: [isnotnull(wp_char_count#48564), (wp_char_count#48564 >= 5000), (wp_char_count#48564 <= 5200), is..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_page], PartitionFilters: [], PushedFilters: [IsNotNull(wp_char_count), GreaterThanOrEqual(wp_char_count,5000), LessThanOrEqual(wp_char_count,..., ReadSchema: struct<wp_web_page_sk:int,wp_char_count:int>
