AdaptiveSparkPlan isFinalPlan=false
+- TakeOrderedAndProject(limit=100, orderBy=[ca_state#8179 ASC NULLS FIRST,cd_gender#8267 ASC NULLS FIRST,cd_marital_status#8268 ASC NULLS FIRST,cd_dep_count#8272 ASC NULLS FIRST,cd_dep_employed_count#8273 ASC NULLS FIRST,cd_dep_college_count#8274 ASC NULLS FIRST], output=[ca_state#8179,cd_gender#8267,cd_marital_status#8268,cd_dep_count#8272,cnt1#28961L,sum(cd_dep_count)#29059L,min(cd_dep_count)#29060,stddev_samp(cd_dep_count)#29097,cd_dep_employed_count#8273,cnt2#28962L,sum(cd_dep_employed_count)#29061L,min(cd_dep_employed_count)#29062,stddev_samp(cd_dep_employed_count)#29106,cd_dep_college_count#8274,cnt3#28963L,sum(cd_dep_college_count)#29063L,min(cd_dep_college_count)#29064,stddev_samp(cd_dep_college_count)#29115])
   +- HashAggregate(keys=[ca_state#8179, cd_gender#8267, cd_marital_status#8268, cd_dep_count#8272, cd_dep_employed_count#8273, cd_dep_college_count#8274], functions=[count(1), sum(cd_dep_count#8272), min(cd_dep_count#8272), stddev_samp(cast(cd_dep_count#8272 as double)), sum(cd_dep_employed_count#8273), min(cd_dep_employed_count#8273), stddev_samp(cast(cd_dep_employed_count#8273 as double)), sum(cd_dep_college_count#8274), min(cd_dep_college_count#8274), stddev_samp(cast(cd_dep_college_count#8274 as double))], output=[ca_state#8179, cd_gender#8267, cd_marital_status#8268, cd_dep_count#8272, cnt1#28961L, sum(cd_dep_count)#29059L, min(cd_dep_count)#29060, stddev_samp(cd_dep_count)#29097, cd_dep_employed_count#8273, cnt2#28962L, sum(cd_dep_employed_count)#29061L, min(cd_dep_employed_count)#29062, stddev_samp(cd_dep_employed_count)#29106, cd_dep_college_count#8274, cnt3#28963L, sum(cd_dep_college_count)#29063L, min(cd_dep_college_count)#29064, stddev_samp(cd_dep_college_count)#29115])
      +- Exchange hashpartitioning(ca_state#8179, cd_gender#8267, cd_marital_status#8268, cd_dep_count#8272, cd_dep_employed_count#8273, cd_dep_college_count#8274, 200), ENSURE_REQUIREMENTS, [plan_id=85197]
         +- HashAggregate(keys=[ca_state#8179, cd_gender#8267, cd_marital_status#8268, cd_dep_count#8272, cd_dep_employed_count#8273, cd_dep_college_count#8274], functions=[partial_count(1), partial_sum(cd_dep_count#8272), partial_min(cd_dep_count#8272), partial_stddev_samp(cast(cd_dep_count#8272 as double)), partial_sum(cd_dep_employed_count#8273), partial_min(cd_dep_employed_count#8273), partial_stddev_samp(cast(cd_dep_employed_count#8273 as double)), partial_sum(cd_dep_college_count#8274), partial_min(cd_dep_college_count#8274), partial_stddev_samp(cast(cd_dep_college_count#8274 as double))], output=[ca_state#8179, cd_gender#8267, cd_marital_status#8268, cd_dep_count#8272, cd_dep_employed_count#8273, cd_dep_college_count#8274, count#29245L, sum#29246L, min#29247, n#29121, avg#29122, m2#29123, sum#29248L, min#29249, n#29129, avg#29130, m2#29131, sum#29250L, min#29251, n#29137, avg#29138, m2#29139])
            +- Project [ca_state#8179, cd_gender#8267, cd_marital_status#8268, cd_dep_count#8272, cd_dep_employed_count#8273, cd_dep_college_count#8274]
               +- BroadcastHashJoin [c_current_cdemo_sk#83], [cd_demo_sk#8266], Inner, BuildRight, false
                  :- Project [c_current_cdemo_sk#83, ca_state#8179]
                  :  +- BroadcastHashJoin [c_current_addr_sk#85], [ca_address_sk#8171], Inner, BuildRight, false
                  :     :- Project [c_current_cdemo_sk#83, c_current_addr_sk#85]
                  :     :  +- Filter (exists#29703 OR exists#29704)
                  :     :     +- SortMergeJoin [c_customer_sk#81], [cs_ship_customer_sk#468], ExistenceJoin(exists#29704)
                  :     :        :- SortMergeJoin [c_customer_sk#81], [ws_bill_customer_sk#431], ExistenceJoin(exists#29703)
                  :     :        :  :- SortMergeJoin [c_customer_sk#81], [ss_customer_sk#1251], LeftSemi
                  :     :        :  :  :- Sort [c_customer_sk#81 ASC NULLS FIRST], false, 0
                  :     :        :  :  :  +- Exchange hashpartitioning(c_customer_sk#81, 200), ENSURE_REQUIREMENTS, [plan_id=85164]
                  :     :        :  :  :     +- Filter (isnotnull(c_current_addr_sk#85) AND isnotnull(c_current_cdemo_sk#83))
                  :     :        :  :  :        +- FileScan parquet spark_catalog.m.customer[c_customer_sk#81,c_current_cdemo_sk#83,c_current_addr_sk#85] Batched: true, DataFilters: [isnotnull(c_current_addr_sk#85), isnotnull(c_current_cdemo_sk#83)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_current_addr_sk), IsNotNull(c_current_cdemo_sk)], ReadSchema: struct<c_customer_sk:int,c_current_cdemo_sk:int,c_current_addr_sk:int>
                  :     :        :  :  +- Sort [ss_customer_sk#1251 ASC NULLS FIRST], false, 0
                  :     :        :  :     +- Exchange hashpartitioning(ss_customer_sk#1251, 200), ENSURE_REQUIREMENTS, [plan_id=85165]
                  :     :        :  :        +- Project [ss_customer_sk#1251]
                  :     :        :  :           +- BroadcastHashJoin [ss_sold_date_sk#1248], [d_date_sk#24], Inner, BuildRight, false
                  :     :        :  :              :- Filter isnotnull(ss_sold_date_sk#1248)
                  :     :        :  :              :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#1248,ss_customer_sk#1251] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#1248)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_customer_sk:int>
                  :     :        :  :              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=85159]
                  :     :        :  :                 +- Project [d_date_sk#24]
                  :     :        :  :                    +- Filter ((((isnotnull(d_year#30) AND isnotnull(d_qoy#34)) AND (d_year#30 = 1999)) AND (d_qoy#34 < 4)) AND isnotnull(d_date_sk#24))
                  :     :        :  :                       +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#24,d_year#30,d_qoy#34] Batched: true, DataFilters: [isnotnull(d_year#30), isnotnull(d_qoy#34), (d_year#30 = 1999), (d_qoy#34 < 4), isnotnull(d_date_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), IsNotNull(d_qoy), EqualTo(d_year,1999), LessThan(d_qoy,4), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>
                  :     :        :  +- Sort [ws_bill_customer_sk#431 ASC NULLS FIRST], false, 0
                  :     :        :     +- Exchange hashpartitioning(ws_bill_customer_sk#431, 200), ENSURE_REQUIREMENTS, [plan_id=85174]
                  :     :        :        +- Project [ws_bill_customer_sk#431]
                  :     :        :           +- BroadcastHashJoin [ws_sold_date_sk#427], [d_date_sk#28970], Inner, BuildRight, false
                  :     :        :              :- Filter isnotnull(ws_sold_date_sk#427)
                  :     :        :              :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_date_sk#427,ws_bill_customer_sk#431] Batched: true, DataFilters: [isnotnull(ws_sold_date_sk#427)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_sold_date_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_bill_customer_sk:int>
                  :     :        :              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=85169]
                  :     :        :                 +- Project [d_date_sk#28970]
                  :     :        :                    +- Filter ((((isnotnull(d_year#28976) AND isnotnull(d_qoy#28980)) AND (d_year#28976 = 1999)) AND (d_qoy#28980 < 4)) AND isnotnull(d_date_sk#28970))
                  :     :        :                       +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#28970,d_year#28976,d_qoy#28980] Batched: true, DataFilters: [isnotnull(d_year#28976), isnotnull(d_qoy#28980), (d_year#28976 = 1999), (d_qoy#28980 < 4), isnot..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), IsNotNull(d_qoy), EqualTo(d_year,1999), LessThan(d_qoy,4), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>
                  :     :        +- Sort [cs_ship_customer_sk#468 ASC NULLS FIRST], false, 0
                  :     :           +- Exchange hashpartitioning(cs_ship_customer_sk#468, 200), ENSURE_REQUIREMENTS, [plan_id=85182]
                  :     :              +- Project [cs_ship_customer_sk#468]
                  :     :                 +- BroadcastHashJoin [cs_sold_date_sk#461], [d_date_sk#28998], Inner, BuildRight, false
                  :     :                    :- Filter isnotnull(cs_sold_date_sk#461)
                  :     :                    :  +- FileScan parquet spark_catalog.m.catalog_sales[cs_sold_date_sk#461,cs_ship_customer_sk#468] Batched: true, DataFilters: [isnotnull(cs_sold_date_sk#461)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_sold_date_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_ship_customer_sk:int>
                  :     :                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=85177]
                  :     :                       +- Project [d_date_sk#28998]
                  :     :                          +- Filter ((((isnotnull(d_year#29004) AND isnotnull(d_qoy#29008)) AND (d_year#29004 = 1999)) AND (d_qoy#29008 < 4)) AND isnotnull(d_date_sk#28998))
                  :     :                             +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#28998,d_year#29004,d_qoy#29008] Batched: true, DataFilters: [isnotnull(d_year#29004), isnotnull(d_qoy#29008), (d_year#29004 = 1999), (d_qoy#29008 < 4), isnot..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), IsNotNull(d_qoy), EqualTo(d_year,1999), LessThan(d_qoy,4), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>
                  :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=85188]
                  :        +- Filter isnotnull(ca_address_sk#8171)
                  :           +- FileScan parquet spark_catalog.m.customer_address[ca_address_sk#8171,ca_state#8179] Batched: true, DataFilters: [isnotnull(ca_address_sk#8171)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk)], ReadSchema: struct<ca_address_sk:int,ca_state:string>
                  +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=85192]
                     +- Filter isnotnull(cd_demo_sk#8266)
                        +- FileScan parquet spark_catalog.m.customer_demographics[cd_demo_sk#8266,cd_gender#8267,cd_marital_status#8268,cd_dep_count#8272,cd_dep_employed_count#8273,cd_dep_college_count#8274] Batched: true, DataFilters: [isnotnull(cd_demo_sk#8266)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_demograph..., PartitionFilters: [], PushedFilters: [IsNotNull(cd_demo_sk)], ReadSchema: struct<cd_demo_sk:int,cd_gender:string,cd_marital_status:string,cd_dep_count:int,cd_dep_employed_...
