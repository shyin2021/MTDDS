AdaptiveSparkPlan isFinalPlan=false
+- Sort [w_warehouse_sk#21220 ASC NULLS FIRST, i_item_sk#1271 ASC NULLS FIRST, d_moy#32 ASC NULLS FIRST, mean#30581 ASC NULLS FIRST, cov#30582 ASC NULLS FIRST, d_moy#31219 ASC NULLS FIRST, mean#30614 ASC NULLS FIRST, cov#30615 ASC NULLS FIRST], true, 0
   +- Exchange rangepartitioning(w_warehouse_sk#21220 ASC NULLS FIRST, i_item_sk#1271 ASC NULLS FIRST, d_moy#32 ASC NULLS FIRST, mean#30581 ASC NULLS FIRST, cov#30582 ASC NULLS FIRST, d_moy#31219 ASC NULLS FIRST, mean#30614 ASC NULLS FIRST, cov#30615 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=90854]
      +- SortMergeJoin [i_item_sk#1271, w_warehouse_sk#21220], [i_item_sk#31175, w_warehouse_sk#31197], Inner
         :- Sort [i_item_sk#1271 ASC NULLS FIRST, w_warehouse_sk#21220 ASC NULLS FIRST], false, 0
         :  +- Exchange hashpartitioning(i_item_sk#1271, w_warehouse_sk#21220, 200), ENSURE_REQUIREMENTS, [plan_id=90848]
         :     +- Project [w_warehouse_sk#21220, i_item_sk#1271, d_moy#32, mean#30581, CASE WHEN (mean#30581 = 0.0) THEN null ELSE (stdev#30580 / mean#30581) END AS cov#30582]
         :        +- Filter (CASE WHEN (mean#30581 = 0.0) THEN false ELSE ((stdev#30580 / mean#30581) > 1.0) END AND CASE WHEN (mean#30581 = 0.0) THEN false ELSE ((stdev#30580 / mean#30581) > 1.5) END)
         :           +- HashAggregate(keys=[w_warehouse_name#21222, w_warehouse_sk#21220, i_item_sk#1271, d_moy#32], functions=[stddev_samp(cast(inv_quantity_on_hand#21219L as double)), avg(inv_quantity_on_hand#21219L)], output=[w_warehouse_sk#21220, i_item_sk#1271, d_moy#32, stdev#30580, mean#30581])
         :              +- Exchange hashpartitioning(w_warehouse_name#21222, w_warehouse_sk#21220, i_item_sk#1271, d_moy#32, 200), ENSURE_REQUIREMENTS, [plan_id=90825]
         :                 +- HashAggregate(keys=[w_warehouse_name#21222, w_warehouse_sk#21220, i_item_sk#1271, d_moy#32], functions=[partial_stddev_samp(cast(inv_quantity_on_hand#21219L as double)), partial_avg(inv_quantity_on_hand#21219L)], output=[w_warehouse_name#21222, w_warehouse_sk#21220, i_item_sk#1271, d_moy#32, n#30606, avg#30607, m2#30608, sum#31006, count#31007L])
         :                    +- Project [inv_quantity_on_hand#21219L, i_item_sk#1271, w_warehouse_sk#21220, w_warehouse_name#21222, d_moy#32]
         :                       +- BroadcastHashJoin [inv_date_sk#21216], [d_date_sk#24], Inner, BuildRight, false
         :                          :- Project [inv_date_sk#21216, inv_quantity_on_hand#21219L, i_item_sk#1271, w_warehouse_sk#21220, w_warehouse_name#21222]
         :                          :  +- BroadcastHashJoin [inv_warehouse_sk#21218], [w_warehouse_sk#21220], Inner, BuildRight, false
         :                          :     :- Project [inv_date_sk#21216, inv_warehouse_sk#21218, inv_quantity_on_hand#21219L, i_item_sk#1271]
         :                          :     :  +- BroadcastHashJoin [inv_item_sk#21217], [i_item_sk#1271], Inner, BuildRight, false
         :                          :     :     :- Filter ((isnotnull(inv_item_sk#21217) AND isnotnull(inv_warehouse_sk#21218)) AND isnotnull(inv_date_sk#21216))
         :                          :     :     :  +- FileScan parquet spark_catalog.m.inventory[inv_date_sk#21216,inv_item_sk#21217,inv_warehouse_sk#21218,inv_quantity_on_hand#21219L] Batched: true, DataFilters: [isnotnull(inv_item_sk#21217), isnotnull(inv_warehouse_sk#21218), isnotnull(inv_date_sk#21216)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/inventory], PartitionFilters: [], PushedFilters: [IsNotNull(inv_item_sk), IsNotNull(inv_warehouse_sk), IsNotNull(inv_date_sk)], ReadSchema: struct<inv_date_sk:int,inv_item_sk:int,inv_warehouse_sk:int,inv_quantity_on_hand:bigint>
         :                          :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=90812]
         :                          :     :        +- Filter isnotnull(i_item_sk#1271)
         :                          :     :           +- FileScan parquet spark_catalog.m.item[i_item_sk#1271] Batched: true, DataFilters: [isnotnull(i_item_sk#1271)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int>
         :                          :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=90816]
         :                          :        +- Filter isnotnull(w_warehouse_sk#21220)
         :                          :           +- FileScan parquet spark_catalog.m.warehouse[w_warehouse_sk#21220,w_warehouse_name#21222] Batched: true, DataFilters: [isnotnull(w_warehouse_sk#21220)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/warehouse], PartitionFilters: [], PushedFilters: [IsNotNull(w_warehouse_sk)], ReadSchema: struct<w_warehouse_sk:int,w_warehouse_name:string>
         :                          +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=90820]
         :                             +- Project [d_date_sk#24, d_moy#32]
         :                                +- Filter ((((isnotnull(d_year#30) AND isnotnull(d_moy#32)) AND (d_year#30 = 1998)) AND (d_moy#32 = 4)) AND isnotnull(d_date_sk#24))
         :                                   +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#24,d_year#30,d_moy#32] Batched: true, DataFilters: [isnotnull(d_year#30), isnotnull(d_moy#32), (d_year#30 = 1998), (d_moy#32 = 4), isnotnull(d_date_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), EqualTo(d_year,1998), EqualTo(d_moy,4), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>
         +- Sort [i_item_sk#31175 ASC NULLS FIRST, w_warehouse_sk#31197 ASC NULLS FIRST], false, 0
            +- Exchange hashpartitioning(i_item_sk#31175, w_warehouse_sk#31197, 200), ENSURE_REQUIREMENTS, [plan_id=90849]
               +- Project [w_warehouse_sk#31197, i_item_sk#31175, d_moy#31219, mean#30581 AS mean#30614, CASE WHEN (mean#30581 = 0.0) THEN null ELSE (stdev#30580 / mean#30581) END AS cov#30615]
                  +- Filter CASE WHEN (mean#30581 = 0.0) THEN false ELSE ((stdev#30580 / mean#30581) > 1.0) END
                     +- HashAggregate(keys=[w_warehouse_name#31199, w_warehouse_sk#31197, i_item_sk#31175, d_moy#31219], functions=[stddev_samp(cast(inv_quantity_on_hand#31174L as double)), avg(inv_quantity_on_hand#31174L)], output=[w_warehouse_sk#31197, i_item_sk#31175, d_moy#31219, stdev#30580, mean#30581])
                        +- Exchange hashpartitioning(w_warehouse_name#31199, w_warehouse_sk#31197, i_item_sk#31175, d_moy#31219, 200), ENSURE_REQUIREMENTS, [plan_id=90842]
                           +- HashAggregate(keys=[w_warehouse_name#31199, w_warehouse_sk#31197, i_item_sk#31175, d_moy#31219], functions=[partial_stddev_samp(cast(inv_quantity_on_hand#31174L as double)), partial_avg(inv_quantity_on_hand#31174L)], output=[w_warehouse_name#31199, w_warehouse_sk#31197, i_item_sk#31175, d_moy#31219, n#31244, avg#31245, m2#31246, sum#31258, count#31259L])
                              +- Project [inv_quantity_on_hand#31174L, i_item_sk#31175, w_warehouse_sk#31197, w_warehouse_name#31199, d_moy#31219]
                                 +- BroadcastHashJoin [inv_date_sk#31171], [d_date_sk#31211], Inner, BuildRight, false
                                    :- Project [inv_date_sk#31171, inv_quantity_on_hand#31174L, i_item_sk#31175, w_warehouse_sk#31197, w_warehouse_name#31199]
                                    :  +- BroadcastHashJoin [inv_warehouse_sk#31173], [w_warehouse_sk#31197], Inner, BuildRight, false
                                    :     :- Project [inv_date_sk#31171, inv_warehouse_sk#31173, inv_quantity_on_hand#31174L, i_item_sk#31175]
                                    :     :  +- BroadcastHashJoin [inv_item_sk#31172], [i_item_sk#31175], Inner, BuildRight, false
                                    :     :     :- Filter ((isnotnull(inv_item_sk#31172) AND isnotnull(inv_warehouse_sk#31173)) AND isnotnull(inv_date_sk#31171))
                                    :     :     :  +- FileScan parquet spark_catalog.m.inventory[inv_date_sk#31171,inv_item_sk#31172,inv_warehouse_sk#31173,inv_quantity_on_hand#31174L] Batched: true, DataFilters: [isnotnull(inv_item_sk#31172), isnotnull(inv_warehouse_sk#31173), isnotnull(inv_date_sk#31171)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/inventory], PartitionFilters: [], PushedFilters: [IsNotNull(inv_item_sk), IsNotNull(inv_warehouse_sk), IsNotNull(inv_date_sk)], ReadSchema: struct<inv_date_sk:int,inv_item_sk:int,inv_warehouse_sk:int,inv_quantity_on_hand:bigint>
                                    :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=90829]
                                    :     :        +- Filter isnotnull(i_item_sk#31175)
                                    :     :           +- FileScan parquet spark_catalog.m.item[i_item_sk#31175] Batched: true, DataFilters: [isnotnull(i_item_sk#31175)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int>
                                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=90833]
                                    :        +- Filter isnotnull(w_warehouse_sk#31197)
                                    :           +- FileScan parquet spark_catalog.m.warehouse[w_warehouse_sk#31197,w_warehouse_name#31199] Batched: true, DataFilters: [isnotnull(w_warehouse_sk#31197)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/warehouse], PartitionFilters: [], PushedFilters: [IsNotNull(w_warehouse_sk)], ReadSchema: struct<w_warehouse_sk:int,w_warehouse_name:string>
                                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=90837]
                                       +- Project [d_date_sk#31211, d_moy#31219]
                                          +- Filter ((((isnotnull(d_year#31217) AND isnotnull(d_moy#31219)) AND (d_year#31217 = 1998)) AND (d_moy#31219 = 5)) AND isnotnull(d_date_sk#31211))
                                             +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#31211,d_year#31217,d_moy#31219] Batched: true, DataFilters: [isnotnull(d_year#31217), isnotnull(d_moy#31219), (d_year#31217 = 1998), (d_moy#31219 = 5), isnot..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), EqualTo(d_year,1998), EqualTo(d_moy,5), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>
