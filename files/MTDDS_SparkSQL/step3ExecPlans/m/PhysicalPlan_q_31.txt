AdaptiveSparkPlan isFinalPlan=false
+- Sort [store_q2_q3_increase#27025 ASC NULLS FIRST], true, 0
   +- Exchange rangepartitioning(store_q2_q3_increase#27025 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=79788]
      +- Project [ca_county#8178, d_year#30, (web_sales#27084 / web_sales#27027) AS web_q1_q2_increase#27022, (store_sales#27076 / store_sales#27026) AS store_q1_q2_increase#27023, (web_sales#27088 / web_sales#27084) AS web_q2_q3_increase#27024, (store_sales#27080 / store_sales#27076) AS store_q2_q3_increase#27025]
         +- SortMergeJoin [ca_county#27063], [ca_county#28565], Inner, (CASE WHEN (web_sales#27084 > 0.0) THEN (web_sales#27088 / web_sales#27084) END > CASE WHEN (store_sales#27076 > 0.0) THEN (store_sales#27080 / store_sales#27076) END)
            :- Project [ca_county#8178, d_year#30, store_sales#27026, store_sales#27076, store_sales#27080, ca_county#27063, web_sales#27027, web_sales#27084]
            :  +- SortMergeJoin [ca_county#27063], [ca_county#28489], Inner, (CASE WHEN (web_sales#27027 > 0.0) THEN (web_sales#27084 / web_sales#27027) END > CASE WHEN (store_sales#27026 > 0.0) THEN (store_sales#27076 / store_sales#27026) END)
            :     :- SortMergeJoin [ca_county#8178], [ca_county#27063], Inner
            :     :  :- Project [ca_county#8178, d_year#30, store_sales#27026, store_sales#27076, store_sales#27080]
            :     :  :  +- SortMergeJoin [ca_county#28348], [ca_county#28413], Inner
            :     :  :     :- SortMergeJoin [ca_county#8178], [ca_county#28348], Inner
            :     :  :     :  :- Sort [ca_county#8178 ASC NULLS FIRST], false, 0
            :     :  :     :  :  +- Exchange hashpartitioning(ca_county#8178, 200), ENSURE_REQUIREMENTS, [plan_id=79715]
            :     :  :     :  :     +- HashAggregate(keys=[ca_county#8178, d_qoy#34, d_year#30], functions=[sum(ss_ext_sales_price#1263)], output=[ca_county#8178, d_year#30, store_sales#27026])
            :     :  :     :  :        +- Exchange hashpartitioning(ca_county#8178, d_qoy#34, d_year#30, 200), ENSURE_REQUIREMENTS, [plan_id=79700]
            :     :  :     :  :           +- HashAggregate(keys=[ca_county#8178, d_qoy#34, d_year#30], functions=[partial_sum(ss_ext_sales_price#1263)], output=[ca_county#8178, d_qoy#34, d_year#30, sum#28242])
            :     :  :     :  :              +- Project [ss_ext_sales_price#1263, d_year#30, d_qoy#34, ca_county#8178]
            :     :  :     :  :                 +- BroadcastHashJoin [ss_addr_sk#1254], [ca_address_sk#8171], Inner, BuildRight, false
            :     :  :     :  :                    :- Project [ss_addr_sk#1254, ss_ext_sales_price#1263, d_year#30, d_qoy#34]
            :     :  :     :  :                    :  +- BroadcastHashJoin [ss_sold_date_sk#1248], [d_date_sk#24], Inner, BuildRight, false
            :     :  :     :  :                    :     :- Filter (isnotnull(ss_sold_date_sk#1248) AND isnotnull(ss_addr_sk#1254))
            :     :  :     :  :                    :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#1248,ss_addr_sk#1254,ss_ext_sales_price#1263] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#1248), isnotnull(ss_addr_sk#1254)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_addr_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_addr_sk:int,ss_ext_sales_price:double>
            :     :  :     :  :                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=79691]
            :     :  :     :  :                    :        +- Filter ((((isnotnull(d_qoy#34) AND isnotnull(d_year#30)) AND (d_qoy#34 = 1)) AND (d_year#30 = 2000)) AND isnotnull(d_date_sk#24))
            :     :  :     :  :                    :           +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#24,d_year#30,d_qoy#34] Batched: true, DataFilters: [isnotnull(d_qoy#34), isnotnull(d_year#30), (d_qoy#34 = 1), (d_year#30 = 2000), isnotnull(d_date_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_qoy), IsNotNull(d_year), EqualTo(d_qoy,1), EqualTo(d_year,2000), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>
            :     :  :     :  :                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=79695]
            :     :  :     :  :                       +- Filter (isnotnull(ca_address_sk#8171) AND isnotnull(ca_county#8178))
            :     :  :     :  :                          +- FileScan parquet spark_catalog.m.customer_address[ca_address_sk#8171,ca_county#8178] Batched: true, DataFilters: [isnotnull(ca_address_sk#8171), isnotnull(ca_county#8178)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk), IsNotNull(ca_county)], ReadSchema: struct<ca_address_sk:int,ca_county:string>
            :     :  :     :  +- Sort [ca_county#28348 ASC NULLS FIRST], false, 0
            :     :  :     :     +- Exchange hashpartitioning(ca_county#28348, 200), ENSURE_REQUIREMENTS, [plan_id=79716]
            :     :  :     :        +- HashAggregate(keys=[ca_county#28348, d_qoy#28323, d_year#28319], functions=[sum(ss_ext_sales_price#28305)], output=[ca_county#28348, store_sales#27076])
            :     :  :     :           +- Exchange hashpartitioning(ca_county#28348, d_qoy#28323, d_year#28319, 200), ENSURE_REQUIREMENTS, [plan_id=79711]
            :     :  :     :              +- HashAggregate(keys=[ca_county#28348, d_qoy#28323, d_year#28319], functions=[partial_sum(ss_ext_sales_price#28305)], output=[ca_county#28348, d_qoy#28323, d_year#28319, sum#28573])
            :     :  :     :                 +- Project [ss_ext_sales_price#28305, d_year#28319, d_qoy#28323, ca_county#28348]
            :     :  :     :                    +- BroadcastHashJoin [ss_addr_sk#28296], [ca_address_sk#28341], Inner, BuildRight, false
            :     :  :     :                       :- Project [ss_addr_sk#28296, ss_ext_sales_price#28305, d_year#28319, d_qoy#28323]
            :     :  :     :                       :  +- BroadcastHashJoin [ss_sold_date_sk#28290], [d_date_sk#28313], Inner, BuildRight, false
            :     :  :     :                       :     :- Filter (isnotnull(ss_sold_date_sk#28290) AND isnotnull(ss_addr_sk#28296))
            :     :  :     :                       :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#28290,ss_addr_sk#28296,ss_ext_sales_price#28305] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#28290), isnotnull(ss_addr_sk#28296)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_addr_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_addr_sk:int,ss_ext_sales_price:double>
            :     :  :     :                       :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=79702]
            :     :  :     :                       :        +- Filter ((((isnotnull(d_qoy#28323) AND isnotnull(d_year#28319)) AND (d_qoy#28323 = 2)) AND (d_year#28319 = 2000)) AND isnotnull(d_date_sk#28313))
            :     :  :     :                       :           +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#28313,d_year#28319,d_qoy#28323] Batched: true, DataFilters: [isnotnull(d_qoy#28323), isnotnull(d_year#28319), (d_qoy#28323 = 2), (d_year#28319 = 2000), isnot..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_qoy), IsNotNull(d_year), EqualTo(d_qoy,2), EqualTo(d_year,2000), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>
            :     :  :     :                       +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=79706]
            :     :  :     :                          +- Filter (isnotnull(ca_address_sk#28341) AND isnotnull(ca_county#28348))
            :     :  :     :                             +- FileScan parquet spark_catalog.m.customer_address[ca_address_sk#28341,ca_county#28348] Batched: true, DataFilters: [isnotnull(ca_address_sk#28341), isnotnull(ca_county#28348)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk), IsNotNull(ca_county)], ReadSchema: struct<ca_address_sk:int,ca_county:string>
            :     :  :     +- Sort [ca_county#28413 ASC NULLS FIRST], false, 0
            :     :  :        +- Exchange hashpartitioning(ca_county#28413, 200), ENSURE_REQUIREMENTS, [plan_id=79733]
            :     :  :           +- HashAggregate(keys=[ca_county#28413, d_qoy#28388, d_year#28384], functions=[sum(ss_ext_sales_price#28370)], output=[ca_county#28413, store_sales#27080])
            :     :  :              +- Exchange hashpartitioning(ca_county#28413, d_qoy#28388, d_year#28384, 200), ENSURE_REQUIREMENTS, [plan_id=79729]
            :     :  :                 +- HashAggregate(keys=[ca_county#28413, d_qoy#28388, d_year#28384], functions=[partial_sum(ss_ext_sales_price#28370)], output=[ca_county#28413, d_qoy#28388, d_year#28384, sum#28575])
            :     :  :                    +- Project [ss_ext_sales_price#28370, d_year#28384, d_qoy#28388, ca_county#28413]
            :     :  :                       +- BroadcastHashJoin [ss_addr_sk#28361], [ca_address_sk#28406], Inner, BuildRight, false
            :     :  :                          :- Project [ss_addr_sk#28361, ss_ext_sales_price#28370, d_year#28384, d_qoy#28388]
            :     :  :                          :  +- BroadcastHashJoin [ss_sold_date_sk#28355], [d_date_sk#28378], Inner, BuildRight, false
            :     :  :                          :     :- Filter (isnotnull(ss_sold_date_sk#28355) AND isnotnull(ss_addr_sk#28361))
            :     :  :                          :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#28355,ss_addr_sk#28361,ss_ext_sales_price#28370] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#28355), isnotnull(ss_addr_sk#28361)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_addr_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_addr_sk:int,ss_ext_sales_price:double>
            :     :  :                          :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=79720]
            :     :  :                          :        +- Filter ((((isnotnull(d_qoy#28388) AND isnotnull(d_year#28384)) AND (d_qoy#28388 = 3)) AND (d_year#28384 = 2000)) AND isnotnull(d_date_sk#28378))
            :     :  :                          :           +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#28378,d_year#28384,d_qoy#28388] Batched: true, DataFilters: [isnotnull(d_qoy#28388), isnotnull(d_year#28384), (d_qoy#28388 = 3), (d_year#28384 = 2000), isnot..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_qoy), IsNotNull(d_year), EqualTo(d_qoy,3), EqualTo(d_year,2000), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>
            :     :  :                          +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=79724]
            :     :  :                             +- Filter (isnotnull(ca_address_sk#28406) AND isnotnull(ca_county#28413))
            :     :  :                                +- FileScan parquet spark_catalog.m.customer_address[ca_address_sk#28406,ca_county#28413] Batched: true, DataFilters: [isnotnull(ca_address_sk#28406), isnotnull(ca_county#28413)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk), IsNotNull(ca_county)], ReadSchema: struct<ca_address_sk:int,ca_county:string>
            :     :  +- Sort [ca_county#27063 ASC NULLS FIRST], false, 0
            :     :     +- Exchange hashpartitioning(ca_county#27063, 200), ENSURE_REQUIREMENTS, [plan_id=79750]
            :     :        +- HashAggregate(keys=[ca_county#27063, d_qoy#27038, d_year#27034], functions=[sum(ws_ext_sales_price#450)], output=[ca_county#27063, web_sales#27027])
            :     :           +- Exchange hashpartitioning(ca_county#27063, d_qoy#27038, d_year#27034, 200), ENSURE_REQUIREMENTS, [plan_id=79746]
            :     :              +- HashAggregate(keys=[ca_county#27063, d_qoy#27038, d_year#27034], functions=[partial_sum(ws_ext_sales_price#450)], output=[ca_county#27063, d_qoy#27038, d_year#27034, sum#28248])
            :     :                 +- Project [ws_ext_sales_price#450, d_year#27034, d_qoy#27038, ca_county#27063]
            :     :                    +- BroadcastHashJoin [ws_bill_addr_sk#434], [ca_address_sk#27056], Inner, BuildRight, false
            :     :                       :- Project [ws_bill_addr_sk#434, ws_ext_sales_price#450, d_year#27034, d_qoy#27038]
            :     :                       :  +- BroadcastHashJoin [ws_sold_date_sk#427], [d_date_sk#27028], Inner, BuildRight, false
            :     :                       :     :- Filter (isnotnull(ws_sold_date_sk#427) AND isnotnull(ws_bill_addr_sk#434))
            :     :                       :     :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_date_sk#427,ws_bill_addr_sk#434,ws_ext_sales_price#450] Batched: true, DataFilters: [isnotnull(ws_sold_date_sk#427), isnotnull(ws_bill_addr_sk#434)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_sold_date_sk), IsNotNull(ws_bill_addr_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_bill_addr_sk:int,ws_ext_sales_price:double>
            :     :                       :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=79737]
            :     :                       :        +- Filter ((((isnotnull(d_qoy#27038) AND isnotnull(d_year#27034)) AND (d_qoy#27038 = 1)) AND (d_year#27034 = 2000)) AND isnotnull(d_date_sk#27028))
            :     :                       :           +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#27028,d_year#27034,d_qoy#27038] Batched: true, DataFilters: [isnotnull(d_qoy#27038), isnotnull(d_year#27034), (d_qoy#27038 = 1), (d_year#27034 = 2000), isnot..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_qoy), IsNotNull(d_year), EqualTo(d_qoy,1), EqualTo(d_year,2000), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>
            :     :                       +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=79741]
            :     :                          +- Filter (isnotnull(ca_address_sk#27056) AND isnotnull(ca_county#27063))
            :     :                             +- FileScan parquet spark_catalog.m.customer_address[ca_address_sk#27056,ca_county#27063] Batched: true, DataFilters: [isnotnull(ca_address_sk#27056), isnotnull(ca_county#27063)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk), IsNotNull(ca_county)], ReadSchema: struct<ca_address_sk:int,ca_county:string>
            :     +- Sort [ca_county#28489 ASC NULLS FIRST], false, 0
            :        +- Exchange hashpartitioning(ca_county#28489, 200), ENSURE_REQUIREMENTS, [plan_id=79766]
            :           +- HashAggregate(keys=[ca_county#28489, d_qoy#28464, d_year#28460], functions=[sum(ws_ext_sales_price#28443)], output=[ca_county#28489, web_sales#27084])
            :              +- Exchange hashpartitioning(ca_county#28489, d_qoy#28464, d_year#28460, 200), ENSURE_REQUIREMENTS, [plan_id=79762]
            :                 +- HashAggregate(keys=[ca_county#28489, d_qoy#28464, d_year#28460], functions=[partial_sum(ws_ext_sales_price#28443)], output=[ca_county#28489, d_qoy#28464, d_year#28460, sum#28577])
            :                    +- Project [ws_ext_sales_price#28443, d_year#28460, d_qoy#28464, ca_county#28489]
            :                       +- BroadcastHashJoin [ws_bill_addr_sk#28427], [ca_address_sk#28482], Inner, BuildRight, false
            :                          :- Project [ws_bill_addr_sk#28427, ws_ext_sales_price#28443, d_year#28460, d_qoy#28464]
            :                          :  +- BroadcastHashJoin [ws_sold_date_sk#28420], [d_date_sk#28454], Inner, BuildRight, false
            :                          :     :- Filter (isnotnull(ws_sold_date_sk#28420) AND isnotnull(ws_bill_addr_sk#28427))
            :                          :     :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_date_sk#28420,ws_bill_addr_sk#28427,ws_ext_sales_price#28443] Batched: true, DataFilters: [isnotnull(ws_sold_date_sk#28420), isnotnull(ws_bill_addr_sk#28427)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_sold_date_sk), IsNotNull(ws_bill_addr_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_bill_addr_sk:int,ws_ext_sales_price:double>
            :                          :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=79753]
            :                          :        +- Filter ((((isnotnull(d_qoy#28464) AND isnotnull(d_year#28460)) AND (d_qoy#28464 = 2)) AND (d_year#28460 = 2000)) AND isnotnull(d_date_sk#28454))
            :                          :           +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#28454,d_year#28460,d_qoy#28464] Batched: true, DataFilters: [isnotnull(d_qoy#28464), isnotnull(d_year#28460), (d_qoy#28464 = 2), (d_year#28460 = 2000), isnot..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_qoy), IsNotNull(d_year), EqualTo(d_qoy,2), EqualTo(d_year,2000), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>
            :                          +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=79757]
            :                             +- Filter (isnotnull(ca_address_sk#28482) AND isnotnull(ca_county#28489))
            :                                +- FileScan parquet spark_catalog.m.customer_address[ca_address_sk#28482,ca_county#28489] Batched: true, DataFilters: [isnotnull(ca_address_sk#28482), isnotnull(ca_county#28489)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk), IsNotNull(ca_county)], ReadSchema: struct<ca_address_sk:int,ca_county:string>
            +- Sort [ca_county#28565 ASC NULLS FIRST], false, 0
               +- Exchange hashpartitioning(ca_county#28565, 200), ENSURE_REQUIREMENTS, [plan_id=79783]
                  +- HashAggregate(keys=[ca_county#28565, d_qoy#28540, d_year#28536], functions=[sum(ws_ext_sales_price#28519)], output=[ca_county#28565, web_sales#27088])
                     +- Exchange hashpartitioning(ca_county#28565, d_qoy#28540, d_year#28536, 200), ENSURE_REQUIREMENTS, [plan_id=79779]
                        +- HashAggregate(keys=[ca_county#28565, d_qoy#28540, d_year#28536], functions=[partial_sum(ws_ext_sales_price#28519)], output=[ca_county#28565, d_qoy#28540, d_year#28536, sum#28579])
                           +- Project [ws_ext_sales_price#28519, d_year#28536, d_qoy#28540, ca_county#28565]
                              +- BroadcastHashJoin [ws_bill_addr_sk#28503], [ca_address_sk#28558], Inner, BuildRight, false
                                 :- Project [ws_bill_addr_sk#28503, ws_ext_sales_price#28519, d_year#28536, d_qoy#28540]
                                 :  +- BroadcastHashJoin [ws_sold_date_sk#28496], [d_date_sk#28530], Inner, BuildRight, false
                                 :     :- Filter (isnotnull(ws_sold_date_sk#28496) AND isnotnull(ws_bill_addr_sk#28503))
                                 :     :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_date_sk#28496,ws_bill_addr_sk#28503,ws_ext_sales_price#28519] Batched: true, DataFilters: [isnotnull(ws_sold_date_sk#28496), isnotnull(ws_bill_addr_sk#28503)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_sold_date_sk), IsNotNull(ws_bill_addr_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_bill_addr_sk:int,ws_ext_sales_price:double>
                                 :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=79770]
                                 :        +- Filter ((((isnotnull(d_qoy#28540) AND isnotnull(d_year#28536)) AND (d_qoy#28540 = 3)) AND (d_year#28536 = 2000)) AND isnotnull(d_date_sk#28530))
                                 :           +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#28530,d_year#28536,d_qoy#28540] Batched: true, DataFilters: [isnotnull(d_qoy#28540), isnotnull(d_year#28536), (d_qoy#28540 = 3), (d_year#28536 = 2000), isnot..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_qoy), IsNotNull(d_year), EqualTo(d_qoy,3), EqualTo(d_year,2000), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_qoy:int>
                                 +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=79774]
                                    +- Filter (isnotnull(ca_address_sk#28558) AND isnotnull(ca_county#28565))
                                       +- FileScan parquet spark_catalog.m.customer_address[ca_address_sk#28558,ca_county#28565] Batched: true, DataFilters: [isnotnull(ca_address_sk#28558), isnotnull(ca_county#28565)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk), IsNotNull(ca_county)], ReadSchema: struct<ca_address_sk:int,ca_county:string>
