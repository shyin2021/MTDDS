AdaptiveSparkPlan isFinalPlan=false
+- TakeOrderedAndProject(limit=100, orderBy=[i_brand_id#17715 ASC NULLS FIRST,i_class_id#17717 ASC NULLS FIRST,i_category_id#17719 ASC NULLS FIRST], output=[ty_channel#17363,ty_brand#17364,ty_class#17365,ty_category#17366,ty_sales#17367,ty_number_sales#17368L,ly_channel#17369,ly_brand#17370,ly_class#17371,ly_category#17372,ly_sales#17373,ly_number_sales#17374L])
   +- Project [i_brand_id#17715 AS ty_brand#17364, i_class_id#17717 AS ty_class#17365, i_category_id#17719 AS ty_category#17366, sales#17352 AS ty_sales#17367, number_sales#17353L AS ty_number_sales#17368L, i_brand_id#17788 AS ly_brand#17370, i_class_id#17790 AS ly_class#17371, i_category_id#17792 AS ly_category#17372, sales#17358 AS ly_sales#17373, number_sales#17359L AS ly_number_sales#17374L, i_brand_id#17715, i_class_id#17717, i_category_id#17719]
      +- SortMergeJoin [i_brand_id#17715, i_class_id#17717, i_category_id#17719], [i_brand_id#17788, i_class_id#17790, i_category_id#17792], Inner
         :- Sort [i_brand_id#17715 ASC NULLS FIRST, i_class_id#17717 ASC NULLS FIRST, i_category_id#17719 ASC NULLS FIRST], false, 0
         :  +- Filter (isnotnull(sales#17352) AND (sales#17352 > Subquery subquery#17356, [id=#48081]))
         :     :  +- Subquery subquery#17356, [id=#48081]
         :     :     +- AdaptiveSparkPlan isFinalPlan=false
         :     :        +- HashAggregate(keys=[], functions=[avg((cast(quantity#17379 as double) * list_price#17380))], output=[average_sales#17385])
         :     :           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=47990]
         :     :              +- HashAggregate(keys=[], functions=[partial_avg((cast(quantity#17379 as double) * list_price#17380))], output=[sum#19729, count#19730L])
         :     :                 +- Union
         :     :                    :- Project [ss_quantity#17520 AS quantity#17379, ss_list_price#17522 AS list_price#17380]
         :     :                    :  +- BroadcastHashJoin [ss_sold_date_sk#17510], [d_date_sk#17533], Inner, BuildRight, false
         :     :                    :     :- Filter isnotnull(ss_sold_date_sk#17510)
         :     :                    :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#17510,ss_quantity#17520,ss_list_price#17522] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#17510)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_quantity:int,ss_list_price:double>
         :     :                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=47978]
         :     :                    :        +- Project [d_date_sk#17533]
         :     :                    :           +- Filter (((isnotnull(d_year#17539) AND (d_year#17539 >= 1998)) AND (d_year#17539 <= 2000)) AND isnotnull(d_date_sk#17533))
         :     :                    :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#17533,d_year#17539] Batched: true, DataFilters: [isnotnull(d_year#17539), (d_year#17539 >= 1998), (d_year#17539 <= 2000), isnotnull(d_date_sk#175..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
         :     :                    :- Project [cs_quantity#17579 AS quantity#17381, cs_list_price#17581 AS list_price#17382]
         :     :                    :  +- BroadcastHashJoin [cs_sold_date_sk#17561], [d_date_sk#17595], Inner, BuildRight, false
         :     :                    :     :- Filter isnotnull(cs_sold_date_sk#17561)
         :     :                    :     :  +- FileScan parquet spark_catalog.m.catalog_sales[cs_sold_date_sk#17561,cs_quantity#17579,cs_list_price#17581] Batched: true, DataFilters: [isnotnull(cs_sold_date_sk#17561)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_sold_date_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_quantity:int,cs_list_price:double>
         :     :                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=47981]
         :     :                    :        +- Project [d_date_sk#17595]
         :     :                    :           +- Filter (((isnotnull(d_year#17601) AND (d_year#17601 >= 1998)) AND (d_year#17601 <= 2000)) AND isnotnull(d_date_sk#17595))
         :     :                    :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#17595,d_year#17601] Batched: true, DataFilters: [isnotnull(d_year#17601), (d_year#17601 >= 1998), (d_year#17601 <= 2000), isnotnull(d_date_sk#175..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
         :     :                    +- Project [ws_quantity#17641 AS quantity#17383, ws_list_price#17643 AS list_price#17384]
         :     :                       +- BroadcastHashJoin [ws_sold_date_sk#17623], [d_date_sk#17657], Inner, BuildRight, false
         :     :                          :- Filter isnotnull(ws_sold_date_sk#17623)
         :     :                          :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_date_sk#17623,ws_quantity#17641,ws_list_price#17643] Batched: true, DataFilters: [isnotnull(ws_sold_date_sk#17623)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_sold_date_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_quantity:int,ws_list_price:double>
         :     :                          +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=47984]
         :     :                             +- Project [d_date_sk#17657]
         :     :                                +- Filter (((isnotnull(d_year#17663) AND (d_year#17663 >= 1998)) AND (d_year#17663 <= 2000)) AND isnotnull(d_date_sk#17657))
         :     :                                   +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#17657,d_year#17663] Batched: true, DataFilters: [isnotnull(d_year#17663), (d_year#17663 >= 1998), (d_year#17663 <= 2000), isnotnull(d_date_sk#176..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
         :     +- HashAggregate(keys=[i_brand_id#17715, i_class_id#17717, i_category_id#17719], functions=[sum((cast(ss_quantity#17695 as double) * ss_list_price#17697)), count(1)], output=[i_brand_id#17715, i_class_id#17717, i_category_id#17719, sales#17352, number_sales#17353L])
         :        +- Exchange hashpartitioning(i_brand_id#17715, i_class_id#17717, i_category_id#17719, 200), ENSURE_REQUIREMENTS, [plan_id=48310]
         :           +- HashAggregate(keys=[i_brand_id#17715, i_class_id#17717, i_category_id#17719], functions=[partial_sum((cast(ss_quantity#17695 as double) * ss_list_price#17697)), partial_count(1)], output=[i_brand_id#17715, i_class_id#17717, i_category_id#17719, sum#19721, count#19722L])
         :              +- Project [ss_quantity#17695, ss_list_price#17697, i_brand_id#17715, i_class_id#17717, i_category_id#17719]
         :                 +- BroadcastHashJoin [ss_sold_date_sk#17685], [d_date_sk#17730], Inner, BuildRight, false
         :                    :- Project [ss_sold_date_sk#17685, ss_quantity#17695, ss_list_price#17697, i_brand_id#17715, i_class_id#17717, i_category_id#17719]
         :                    :  +- BroadcastHashJoin [ss_item_sk#17687], [i_item_sk#17708], Inner, BuildRight, false
         :                    :     :- SortMergeJoin [ss_item_sk#17687], [ss_item_sk#17378], LeftSemi
         :                    :     :  :- Sort [ss_item_sk#17687 ASC NULLS FIRST], false, 0
         :                    :     :  :  +- Exchange hashpartitioning(ss_item_sk#17687, 200), ENSURE_REQUIREMENTS, [plan_id=48244]
         :                    :     :  :     +- Filter (isnotnull(ss_item_sk#17687) AND isnotnull(ss_sold_date_sk#17685))
         :                    :     :  :        +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#17685,ss_item_sk#17687,ss_quantity#17695,ss_list_price#17697] Batched: true, DataFilters: [isnotnull(ss_item_sk#17687), isnotnull(ss_sold_date_sk#17685)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_item_sk), IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_quantity:int,ss_list_price:double>
         :                    :     :  +- Sort [ss_item_sk#17378 ASC NULLS FIRST], false, 0
         :                    :     :     +- Exchange hashpartitioning(ss_item_sk#17378, 200), ENSURE_REQUIREMENTS, [plan_id=48245]
         :                    :     :        +- Project [i_item_sk#1271 AS ss_item_sk#17378]
         :                    :     :           +- BroadcastHashJoin [i_brand_id#1278, i_class_id#1280, i_category_id#1282], [brand_id#17375, class_id#17376, category_id#17377], Inner, BuildLeft, false
         :                    :     :              :- BroadcastExchange HashedRelationBroadcastMode(List(input[1, int, false], input[2, int, false], input[3, int, false]),false), [plan_id=48239]
         :                    :     :              :  +- Filter ((isnotnull(i_brand_id#1278) AND isnotnull(i_class_id#1280)) AND isnotnull(i_category_id#1282))
         :                    :     :              :     +- FileScan parquet spark_catalog.m.item[i_item_sk#1271,i_brand_id#1278,i_class_id#1280,i_category_id#1282] Batched: true, DataFilters: [isnotnull(i_brand_id#1278), isnotnull(i_class_id#1280), isnotnull(i_category_id#1282)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
         :                    :     :              +- SortMergeJoin [coalesce(brand_id#17375, 0), isnull(brand_id#17375), coalesce(class_id#17376, 0), isnull(class_id#17376), coalesce(category_id#17377, 0), isnull(category_id#17377)], [coalesce(i_brand_id#17467, 0), isnull(i_brand_id#17467), coalesce(i_class_id#17469, 0), isnull(i_class_id#17469), coalesce(i_category_id#17471, 0), isnull(i_category_id#17471)], LeftSemi
         :                    :     :                 :- Sort [coalesce(brand_id#17375, 0) ASC NULLS FIRST, isnull(brand_id#17375) ASC NULLS FIRST, coalesce(class_id#17376, 0) ASC NULLS FIRST, isnull(class_id#17376) ASC NULLS FIRST, coalesce(category_id#17377, 0) ASC NULLS FIRST, isnull(category_id#17377) ASC NULLS FIRST], false, 0
         :                    :     :                 :  +- Exchange hashpartitioning(coalesce(brand_id#17375, 0), isnull(brand_id#17375), coalesce(class_id#17376, 0), isnull(class_id#17376), coalesce(category_id#17377, 0), isnull(category_id#17377), 200), ENSURE_REQUIREMENTS, [plan_id=48233]
         :                    :     :                 :     +- HashAggregate(keys=[brand_id#17375, class_id#17376, category_id#17377], functions=[], output=[brand_id#17375, class_id#17376, category_id#17377])
         :                    :     :                 :        +- Exchange hashpartitioning(brand_id#17375, class_id#17376, category_id#17377, 200), ENSURE_REQUIREMENTS, [plan_id=48222]
         :                    :     :                 :           +- HashAggregate(keys=[brand_id#17375, class_id#17376, category_id#17377], functions=[], output=[brand_id#17375, class_id#17376, category_id#17377])
         :                    :     :                 :              +- Project [i_brand_id#17395 AS brand_id#17375, i_class_id#17397 AS class_id#17376, i_category_id#17399 AS category_id#17377]
         :                    :     :                 :                 +- BroadcastHashJoin [ss_sold_date_sk#1248], [d_date_sk#24], Inner, BuildRight, false
         :                    :     :                 :                    :- Project [ss_sold_date_sk#1248, i_brand_id#17395, i_class_id#17397, i_category_id#17399]
         :                    :     :                 :                    :  +- BroadcastHashJoin [ss_item_sk#1250], [i_item_sk#17388], Inner, BuildRight, false
         :                    :     :                 :                    :     :- Filter (isnotnull(ss_item_sk#1250) AND isnotnull(ss_sold_date_sk#1248))
         :                    :     :                 :                    :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#1248,ss_item_sk#1250] Batched: true, DataFilters: [isnotnull(ss_item_sk#1250), isnotnull(ss_sold_date_sk#1248)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_item_sk), IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int>
         :                    :     :                 :                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48213]
         :                    :     :                 :                    :        +- SortMergeJoin [coalesce(i_brand_id#17395, 0), isnull(i_brand_id#17395), coalesce(i_class_id#17397, 0), isnull(i_class_id#17397), coalesce(i_category_id#17399, 0), isnull(i_category_id#17399)], [coalesce(i_brand_id#17417, 0), isnull(i_brand_id#17417), coalesce(i_class_id#17419, 0), isnull(i_class_id#17419), coalesce(i_category_id#17421, 0), isnull(i_category_id#17421)], LeftSemi
         :                    :     :                 :                    :           :- Sort [coalesce(i_brand_id#17395, 0) ASC NULLS FIRST, isnull(i_brand_id#17395) ASC NULLS FIRST, coalesce(i_class_id#17397, 0) ASC NULLS FIRST, isnull(i_class_id#17397) ASC NULLS FIRST, coalesce(i_category_id#17399, 0) ASC NULLS FIRST, isnull(i_category_id#17399) ASC NULLS FIRST], false, 0
         :                    :     :                 :                    :           :  +- Exchange hashpartitioning(coalesce(i_brand_id#17395, 0), isnull(i_brand_id#17395), coalesce(i_class_id#17397, 0), isnull(i_class_id#17397), coalesce(i_category_id#17399, 0), isnull(i_category_id#17399), 200), ENSURE_REQUIREMENTS, [plan_id=48207]
         :                    :     :                 :                    :           :     +- Filter (((isnotnull(i_item_sk#17388) AND isnotnull(i_brand_id#17395)) AND isnotnull(i_class_id#17397)) AND isnotnull(i_category_id#17399))
         :                    :     :                 :                    :           :        +- FileScan parquet spark_catalog.m.item[i_item_sk#17388,i_brand_id#17395,i_class_id#17397,i_category_id#17399] Batched: true, DataFilters: [isnotnull(i_item_sk#17388), isnotnull(i_brand_id#17395), isnotnull(i_class_id#17397), isnotnull(..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
         :                    :     :                 :                    :           +- Sort [coalesce(i_brand_id#17417, 0) ASC NULLS FIRST, isnull(i_brand_id#17417) ASC NULLS FIRST, coalesce(i_class_id#17419, 0) ASC NULLS FIRST, isnull(i_class_id#17419) ASC NULLS FIRST, coalesce(i_category_id#17421, 0) ASC NULLS FIRST, isnull(i_category_id#17421) ASC NULLS FIRST], false, 0
         :                    :     :                 :                    :              +- Exchange hashpartitioning(coalesce(i_brand_id#17417, 0), isnull(i_brand_id#17417), coalesce(i_class_id#17419, 0), isnull(i_class_id#17419), coalesce(i_category_id#17421, 0), isnull(i_category_id#17421), 200), ENSURE_REQUIREMENTS, [plan_id=48208]
         :                    :     :                 :                    :                 +- Project [i_brand_id#17417, i_class_id#17419, i_category_id#17421]
         :                    :     :                 :                    :                    +- BroadcastHashJoin [cs_sold_date_sk#461], [d_date_sk#17432], Inner, BuildRight, false
         :                    :     :                 :                    :                       :- Project [cs_sold_date_sk#461, i_brand_id#17417, i_class_id#17419, i_category_id#17421]
         :                    :     :                 :                    :                       :  +- BroadcastHashJoin [cs_item_sk#476], [i_item_sk#17410], Inner, BuildRight, false
         :                    :     :                 :                    :                       :     :- Filter (isnotnull(cs_item_sk#476) AND isnotnull(cs_sold_date_sk#461))
         :                    :     :                 :                    :                       :     :  +- FileScan parquet spark_catalog.m.catalog_sales[cs_sold_date_sk#461,cs_item_sk#476] Batched: true, DataFilters: [isnotnull(cs_item_sk#476), isnotnull(cs_sold_date_sk#461)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_item_sk), IsNotNull(cs_sold_date_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_item_sk:int>
         :                    :     :                 :                    :                       :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48198]
         :                    :     :                 :                    :                       :        +- Filter isnotnull(i_item_sk#17410)
         :                    :     :                 :                    :                       :           +- FileScan parquet spark_catalog.m.item[i_item_sk#17410,i_brand_id#17417,i_class_id#17419,i_category_id#17421] Batched: true, DataFilters: [isnotnull(i_item_sk#17410)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
         :                    :     :                 :                    :                       +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48202]
         :                    :     :                 :                    :                          +- Project [d_date_sk#17432]
         :                    :     :                 :                    :                             +- Filter (((isnotnull(d_year#17438) AND (d_year#17438 >= 1998)) AND (d_year#17438 <= 2000)) AND isnotnull(d_date_sk#17432))
         :                    :     :                 :                    :                                +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#17432,d_year#17438] Batched: true, DataFilters: [isnotnull(d_year#17438), (d_year#17438 >= 1998), (d_year#17438 <= 2000), isnotnull(d_date_sk#174..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
         :                    :     :                 :                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48217]
         :                    :     :                 :                       +- Project [d_date_sk#24]
         :                    :     :                 :                          +- Filter (((isnotnull(d_year#30) AND (d_year#30 >= 1998)) AND (d_year#30 <= 2000)) AND isnotnull(d_date_sk#24))
         :                    :     :                 :                             +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#24,d_year#30] Batched: true, DataFilters: [isnotnull(d_year#30), (d_year#30 >= 1998), (d_year#30 <= 2000), isnotnull(d_date_sk#24)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
         :                    :     :                 +- Sort [coalesce(i_brand_id#17467, 0) ASC NULLS FIRST, isnull(i_brand_id#17467) ASC NULLS FIRST, coalesce(i_class_id#17469, 0) ASC NULLS FIRST, isnull(i_class_id#17469) ASC NULLS FIRST, coalesce(i_category_id#17471, 0) ASC NULLS FIRST, isnull(i_category_id#17471) ASC NULLS FIRST], false, 0
         :                    :     :                    +- Exchange hashpartitioning(coalesce(i_brand_id#17467, 0), isnull(i_brand_id#17467), coalesce(i_class_id#17469, 0), isnull(i_class_id#17469), coalesce(i_category_id#17471, 0), isnull(i_category_id#17471), 200), ENSURE_REQUIREMENTS, [plan_id=48234]
         :                    :     :                       +- Project [i_brand_id#17467, i_class_id#17469, i_category_id#17471]
         :                    :     :                          +- BroadcastHashJoin [ws_sold_date_sk#427], [d_date_sk#17482], Inner, BuildRight, false
         :                    :     :                             :- Project [ws_sold_date_sk#427, i_brand_id#17467, i_class_id#17469, i_category_id#17471]
         :                    :     :                             :  +- BroadcastHashJoin [ws_item_sk#430], [i_item_sk#17460], Inner, BuildRight, false
         :                    :     :                             :     :- Filter (isnotnull(ws_item_sk#430) AND isnotnull(ws_sold_date_sk#427))
         :                    :     :                             :     :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_date_sk#427,ws_item_sk#430] Batched: true, DataFilters: [isnotnull(ws_item_sk#430), isnotnull(ws_sold_date_sk#427)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_item_sk), IsNotNull(ws_sold_date_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_item_sk:int>
         :                    :     :                             :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48224]
         :                    :     :                             :        +- Filter isnotnull(i_item_sk#17460)
         :                    :     :                             :           +- FileScan parquet spark_catalog.m.item[i_item_sk#17460,i_brand_id#17467,i_class_id#17469,i_category_id#17471] Batched: true, DataFilters: [isnotnull(i_item_sk#17460)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
         :                    :     :                             +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48228]
         :                    :     :                                +- Project [d_date_sk#17482]
         :                    :     :                                   +- Filter (((isnotnull(d_year#17488) AND (d_year#17488 >= 1998)) AND (d_year#17488 <= 2000)) AND isnotnull(d_date_sk#17482))
         :                    :     :                                      +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#17482,d_year#17488] Batched: true, DataFilters: [isnotnull(d_year#17488), (d_year#17488 >= 1998), (d_year#17488 <= 2000), isnotnull(d_date_sk#174..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
         :                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48301]
         :                    :        +- SortMergeJoin [i_item_sk#17708], [ss_item_sk#17378], LeftSemi
         :                    :           :- Sort [i_item_sk#17708 ASC NULLS FIRST], false, 0
         :                    :           :  +- Exchange hashpartitioning(i_item_sk#17708, 200), ENSURE_REQUIREMENTS, [plan_id=48295]
         :                    :           :     +- Filter (((isnotnull(i_item_sk#17708) AND isnotnull(i_brand_id#17715)) AND isnotnull(i_class_id#17717)) AND isnotnull(i_category_id#17719))
         :                    :           :        +- FileScan parquet spark_catalog.m.item[i_item_sk#17708,i_brand_id#17715,i_class_id#17717,i_category_id#17719] Batched: true, DataFilters: [isnotnull(i_item_sk#17708), isnotnull(i_brand_id#17715), isnotnull(i_class_id#17717), isnotnull(..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
         :                    :           +- Sort [ss_item_sk#17378 ASC NULLS FIRST], false, 0
         :                    :              +- Exchange hashpartitioning(ss_item_sk#17378, 200), ENSURE_REQUIREMENTS, [plan_id=48296]
         :                    :                 +- Project [i_item_sk#1271 AS ss_item_sk#17378]
         :                    :                    +- BroadcastHashJoin [i_brand_id#1278, i_class_id#1280, i_category_id#1282], [brand_id#17375, class_id#17376, category_id#17377], Inner, BuildLeft, false
         :                    :                       :- BroadcastExchange HashedRelationBroadcastMode(List(input[1, int, false], input[2, int, false], input[3, int, false]),false), [plan_id=48290]
         :                    :                       :  +- Filter ((isnotnull(i_brand_id#1278) AND isnotnull(i_class_id#1280)) AND isnotnull(i_category_id#1282))
         :                    :                       :     +- FileScan parquet spark_catalog.m.item[i_item_sk#1271,i_brand_id#1278,i_class_id#1280,i_category_id#1282] Batched: true, DataFilters: [isnotnull(i_brand_id#1278), isnotnull(i_class_id#1280), isnotnull(i_category_id#1282)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
         :                    :                       +- SortMergeJoin [coalesce(brand_id#17375, 0), isnull(brand_id#17375), coalesce(class_id#17376, 0), isnull(class_id#17376), coalesce(category_id#17377, 0), isnull(category_id#17377)], [coalesce(i_brand_id#17467, 0), isnull(i_brand_id#17467), coalesce(i_class_id#17469, 0), isnull(i_class_id#17469), coalesce(i_category_id#17471, 0), isnull(i_category_id#17471)], LeftSemi
         :                    :                          :- Sort [coalesce(brand_id#17375, 0) ASC NULLS FIRST, isnull(brand_id#17375) ASC NULLS FIRST, coalesce(class_id#17376, 0) ASC NULLS FIRST, isnull(class_id#17376) ASC NULLS FIRST, coalesce(category_id#17377, 0) ASC NULLS FIRST, isnull(category_id#17377) ASC NULLS FIRST], false, 0
         :                    :                          :  +- Exchange hashpartitioning(coalesce(brand_id#17375, 0), isnull(brand_id#17375), coalesce(class_id#17376, 0), isnull(class_id#17376), coalesce(category_id#17377, 0), isnull(category_id#17377), 200), ENSURE_REQUIREMENTS, [plan_id=48284]
         :                    :                          :     +- HashAggregate(keys=[brand_id#17375, class_id#17376, category_id#17377], functions=[], output=[brand_id#17375, class_id#17376, category_id#17377])
         :                    :                          :        +- Exchange hashpartitioning(brand_id#17375, class_id#17376, category_id#17377, 200), ENSURE_REQUIREMENTS, [plan_id=48273]
         :                    :                          :           +- HashAggregate(keys=[brand_id#17375, class_id#17376, category_id#17377], functions=[], output=[brand_id#17375, class_id#17376, category_id#17377])
         :                    :                          :              +- Project [i_brand_id#17395 AS brand_id#17375, i_class_id#17397 AS class_id#17376, i_category_id#17399 AS category_id#17377]
         :                    :                          :                 +- BroadcastHashJoin [ss_sold_date_sk#1248], [d_date_sk#24], Inner, BuildRight, false
         :                    :                          :                    :- Project [ss_sold_date_sk#1248, i_brand_id#17395, i_class_id#17397, i_category_id#17399]
         :                    :                          :                    :  +- BroadcastHashJoin [ss_item_sk#1250], [i_item_sk#17388], Inner, BuildRight, false
         :                    :                          :                    :     :- Filter (isnotnull(ss_item_sk#1250) AND isnotnull(ss_sold_date_sk#1248))
         :                    :                          :                    :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#1248,ss_item_sk#1250] Batched: true, DataFilters: [isnotnull(ss_item_sk#1250), isnotnull(ss_sold_date_sk#1248)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_item_sk), IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int>
         :                    :                          :                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48264]
         :                    :                          :                    :        +- SortMergeJoin [coalesce(i_brand_id#17395, 0), isnull(i_brand_id#17395), coalesce(i_class_id#17397, 0), isnull(i_class_id#17397), coalesce(i_category_id#17399, 0), isnull(i_category_id#17399)], [coalesce(i_brand_id#17417, 0), isnull(i_brand_id#17417), coalesce(i_class_id#17419, 0), isnull(i_class_id#17419), coalesce(i_category_id#17421, 0), isnull(i_category_id#17421)], LeftSemi
         :                    :                          :                    :           :- Sort [coalesce(i_brand_id#17395, 0) ASC NULLS FIRST, isnull(i_brand_id#17395) ASC NULLS FIRST, coalesce(i_class_id#17397, 0) ASC NULLS FIRST, isnull(i_class_id#17397) ASC NULLS FIRST, coalesce(i_category_id#17399, 0) ASC NULLS FIRST, isnull(i_category_id#17399) ASC NULLS FIRST], false, 0
         :                    :                          :                    :           :  +- Exchange hashpartitioning(coalesce(i_brand_id#17395, 0), isnull(i_brand_id#17395), coalesce(i_class_id#17397, 0), isnull(i_class_id#17397), coalesce(i_category_id#17399, 0), isnull(i_category_id#17399), 200), ENSURE_REQUIREMENTS, [plan_id=48258]
         :                    :                          :                    :           :     +- Filter (((isnotnull(i_item_sk#17388) AND isnotnull(i_brand_id#17395)) AND isnotnull(i_class_id#17397)) AND isnotnull(i_category_id#17399))
         :                    :                          :                    :           :        +- FileScan parquet spark_catalog.m.item[i_item_sk#17388,i_brand_id#17395,i_class_id#17397,i_category_id#17399] Batched: true, DataFilters: [isnotnull(i_item_sk#17388), isnotnull(i_brand_id#17395), isnotnull(i_class_id#17397), isnotnull(..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
         :                    :                          :                    :           +- Sort [coalesce(i_brand_id#17417, 0) ASC NULLS FIRST, isnull(i_brand_id#17417) ASC NULLS FIRST, coalesce(i_class_id#17419, 0) ASC NULLS FIRST, isnull(i_class_id#17419) ASC NULLS FIRST, coalesce(i_category_id#17421, 0) ASC NULLS FIRST, isnull(i_category_id#17421) ASC NULLS FIRST], false, 0
         :                    :                          :                    :              +- Exchange hashpartitioning(coalesce(i_brand_id#17417, 0), isnull(i_brand_id#17417), coalesce(i_class_id#17419, 0), isnull(i_class_id#17419), coalesce(i_category_id#17421, 0), isnull(i_category_id#17421), 200), ENSURE_REQUIREMENTS, [plan_id=48259]
         :                    :                          :                    :                 +- Project [i_brand_id#17417, i_class_id#17419, i_category_id#17421]
         :                    :                          :                    :                    +- BroadcastHashJoin [cs_sold_date_sk#461], [d_date_sk#17432], Inner, BuildRight, false
         :                    :                          :                    :                       :- Project [cs_sold_date_sk#461, i_brand_id#17417, i_class_id#17419, i_category_id#17421]
         :                    :                          :                    :                       :  +- BroadcastHashJoin [cs_item_sk#476], [i_item_sk#17410], Inner, BuildRight, false
         :                    :                          :                    :                       :     :- Filter (isnotnull(cs_item_sk#476) AND isnotnull(cs_sold_date_sk#461))
         :                    :                          :                    :                       :     :  +- FileScan parquet spark_catalog.m.catalog_sales[cs_sold_date_sk#461,cs_item_sk#476] Batched: true, DataFilters: [isnotnull(cs_item_sk#476), isnotnull(cs_sold_date_sk#461)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_item_sk), IsNotNull(cs_sold_date_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_item_sk:int>
         :                    :                          :                    :                       :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48249]
         :                    :                          :                    :                       :        +- Filter isnotnull(i_item_sk#17410)
         :                    :                          :                    :                       :           +- FileScan parquet spark_catalog.m.item[i_item_sk#17410,i_brand_id#17417,i_class_id#17419,i_category_id#17421] Batched: true, DataFilters: [isnotnull(i_item_sk#17410)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
         :                    :                          :                    :                       +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48253]
         :                    :                          :                    :                          +- Project [d_date_sk#17432]
         :                    :                          :                    :                             +- Filter (((isnotnull(d_year#17438) AND (d_year#17438 >= 1998)) AND (d_year#17438 <= 2000)) AND isnotnull(d_date_sk#17432))
         :                    :                          :                    :                                +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#17432,d_year#17438] Batched: true, DataFilters: [isnotnull(d_year#17438), (d_year#17438 >= 1998), (d_year#17438 <= 2000), isnotnull(d_date_sk#174..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
         :                    :                          :                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48268]
         :                    :                          :                       +- Project [d_date_sk#24]
         :                    :                          :                          +- Filter (((isnotnull(d_year#30) AND (d_year#30 >= 1998)) AND (d_year#30 <= 2000)) AND isnotnull(d_date_sk#24))
         :                    :                          :                             +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#24,d_year#30] Batched: true, DataFilters: [isnotnull(d_year#30), (d_year#30 >= 1998), (d_year#30 <= 2000), isnotnull(d_date_sk#24)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
         :                    :                          +- Sort [coalesce(i_brand_id#17467, 0) ASC NULLS FIRST, isnull(i_brand_id#17467) ASC NULLS FIRST, coalesce(i_class_id#17469, 0) ASC NULLS FIRST, isnull(i_class_id#17469) ASC NULLS FIRST, coalesce(i_category_id#17471, 0) ASC NULLS FIRST, isnull(i_category_id#17471) ASC NULLS FIRST], false, 0
         :                    :                             +- Exchange hashpartitioning(coalesce(i_brand_id#17467, 0), isnull(i_brand_id#17467), coalesce(i_class_id#17469, 0), isnull(i_class_id#17469), coalesce(i_category_id#17471, 0), isnull(i_category_id#17471), 200), ENSURE_REQUIREMENTS, [plan_id=48285]
         :                    :                                +- Project [i_brand_id#17467, i_class_id#17469, i_category_id#17471]
         :                    :                                   +- BroadcastHashJoin [ws_sold_date_sk#427], [d_date_sk#17482], Inner, BuildRight, false
         :                    :                                      :- Project [ws_sold_date_sk#427, i_brand_id#17467, i_class_id#17469, i_category_id#17471]
         :                    :                                      :  +- BroadcastHashJoin [ws_item_sk#430], [i_item_sk#17460], Inner, BuildRight, false
         :                    :                                      :     :- Filter (isnotnull(ws_item_sk#430) AND isnotnull(ws_sold_date_sk#427))
         :                    :                                      :     :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_date_sk#427,ws_item_sk#430] Batched: true, DataFilters: [isnotnull(ws_item_sk#430), isnotnull(ws_sold_date_sk#427)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_item_sk), IsNotNull(ws_sold_date_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_item_sk:int>
         :                    :                                      :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48275]
         :                    :                                      :        +- Filter isnotnull(i_item_sk#17460)
         :                    :                                      :           +- FileScan parquet spark_catalog.m.item[i_item_sk#17460,i_brand_id#17467,i_class_id#17469,i_category_id#17471] Batched: true, DataFilters: [isnotnull(i_item_sk#17460)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
         :                    :                                      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48279]
         :                    :                                         +- Project [d_date_sk#17482]
         :                    :                                            +- Filter (((isnotnull(d_year#17488) AND (d_year#17488 >= 1998)) AND (d_year#17488 <= 2000)) AND isnotnull(d_date_sk#17482))
         :                    :                                               +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#17482,d_year#17488] Batched: true, DataFilters: [isnotnull(d_year#17488), (d_year#17488 >= 1998), (d_year#17488 <= 2000), isnotnull(d_date_sk#174..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
         :                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48305]
         :                       +- Project [d_date_sk#17730]
         :                          +- Filter ((isnotnull(d_week_seq#17734) AND (d_week_seq#17734 = Subquery subquery#17355, [id=#48083])) AND isnotnull(d_date_sk#17730))
         :                             :  +- Subquery subquery#17355, [id=#48083]
         :                             :     +- AdaptiveSparkPlan isFinalPlan=false
         :                             :        +- Project [d_week_seq#17846]
         :                             :           +- Filter (((((isnotnull(d_year#17848) AND isnotnull(d_moy#17850)) AND isnotnull(d_dom#17851)) AND (d_year#17848 = 1999)) AND (d_moy#17850 = 12)) AND (d_dom#17851 = 20))
         :                             :              +- FileScan parquet spark_catalog.m.date_dim[d_week_seq#17846,d_year#17848,d_moy#17850,d_dom#17851] Batched: true, DataFilters: [isnotnull(d_year#17848), isnotnull(d_moy#17850), isnotnull(d_dom#17851), (d_year#17848 = 1999), ..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), IsNotNull(d_dom), EqualTo(d_year,1999), EqualTo(d_moy,12), ..., ReadSchema: struct<d_week_seq:int,d_year:int,d_moy:int,d_dom:int>
         :                             +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#17730,d_week_seq#17734] Batched: true, DataFilters: [isnotnull(d_week_seq#17734), isnotnull(d_date_sk#17730)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_week_seq), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_week_seq:int>
         +- Sort [i_brand_id#17788 ASC NULLS FIRST, i_class_id#17790 ASC NULLS FIRST, i_category_id#17792 ASC NULLS FIRST], false, 0
            +- Filter (isnotnull(sales#17358) AND (sales#17358 > Subquery subquery#17362, [id=#48091]))
               :  +- Subquery subquery#17362, [id=#48091]
               :     +- AdaptiveSparkPlan isFinalPlan=false
               :        +- HashAggregate(keys=[], functions=[avg((cast(quantity#17379 as double) * list_price#17380))], output=[average_sales#17385])
               :           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=48074]
               :              +- HashAggregate(keys=[], functions=[partial_avg((cast(quantity#17379 as double) * list_price#17380))], output=[sum#19729, count#19730L])
               :                 +- Union
               :                    :- Project [ss_quantity#17520 AS quantity#17379, ss_list_price#17522 AS list_price#17380]
               :                    :  +- BroadcastHashJoin [ss_sold_date_sk#17510], [d_date_sk#17533], Inner, BuildRight, false
               :                    :     :- Filter isnotnull(ss_sold_date_sk#17510)
               :                    :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#17510,ss_quantity#17520,ss_list_price#17522] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#17510)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_quantity:int,ss_list_price:double>
               :                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48062]
               :                    :        +- Project [d_date_sk#17533]
               :                    :           +- Filter (((isnotnull(d_year#17539) AND (d_year#17539 >= 1998)) AND (d_year#17539 <= 2000)) AND isnotnull(d_date_sk#17533))
               :                    :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#17533,d_year#17539] Batched: true, DataFilters: [isnotnull(d_year#17539), (d_year#17539 >= 1998), (d_year#17539 <= 2000), isnotnull(d_date_sk#175..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
               :                    :- Project [cs_quantity#17579 AS quantity#17381, cs_list_price#17581 AS list_price#17382]
               :                    :  +- BroadcastHashJoin [cs_sold_date_sk#17561], [d_date_sk#17595], Inner, BuildRight, false
               :                    :     :- Filter isnotnull(cs_sold_date_sk#17561)
               :                    :     :  +- FileScan parquet spark_catalog.m.catalog_sales[cs_sold_date_sk#17561,cs_quantity#17579,cs_list_price#17581] Batched: true, DataFilters: [isnotnull(cs_sold_date_sk#17561)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_sold_date_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_quantity:int,cs_list_price:double>
               :                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48065]
               :                    :        +- Project [d_date_sk#17595]
               :                    :           +- Filter (((isnotnull(d_year#17601) AND (d_year#17601 >= 1998)) AND (d_year#17601 <= 2000)) AND isnotnull(d_date_sk#17595))
               :                    :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#17595,d_year#17601] Batched: true, DataFilters: [isnotnull(d_year#17601), (d_year#17601 >= 1998), (d_year#17601 <= 2000), isnotnull(d_date_sk#175..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
               :                    +- Project [ws_quantity#17641 AS quantity#17383, ws_list_price#17643 AS list_price#17384]
               :                       +- BroadcastHashJoin [ws_sold_date_sk#17623], [d_date_sk#17657], Inner, BuildRight, false
               :                          :- Filter isnotnull(ws_sold_date_sk#17623)
               :                          :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_date_sk#17623,ws_quantity#17641,ws_list_price#17643] Batched: true, DataFilters: [isnotnull(ws_sold_date_sk#17623)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_sold_date_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_quantity:int,ws_list_price:double>
               :                          +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48068]
               :                             +- Project [d_date_sk#17657]
               :                                +- Filter (((isnotnull(d_year#17663) AND (d_year#17663 >= 1998)) AND (d_year#17663 <= 2000)) AND isnotnull(d_date_sk#17657))
               :                                   +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#17657,d_year#17663] Batched: true, DataFilters: [isnotnull(d_year#17663), (d_year#17663 >= 1998), (d_year#17663 <= 2000), isnotnull(d_date_sk#176..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
               +- HashAggregate(keys=[i_brand_id#17788, i_class_id#17790, i_category_id#17792], functions=[sum((cast(ss_quantity#17768 as double) * ss_list_price#17770)), count(1)], output=[i_brand_id#17788, i_class_id#17790, i_category_id#17792, sales#17358, number_sales#17359L])
                  +- Exchange hashpartitioning(i_brand_id#17788, i_class_id#17790, i_category_id#17792, 200), ENSURE_REQUIREMENTS, [plan_id=48425]
                     +- HashAggregate(keys=[i_brand_id#17788, i_class_id#17790, i_category_id#17792], functions=[partial_sum((cast(ss_quantity#17768 as double) * ss_list_price#17770)), partial_count(1)], output=[i_brand_id#17788, i_class_id#17790, i_category_id#17792, sum#19725, count#19726L])
                        +- Project [ss_quantity#17768, ss_list_price#17770, i_brand_id#17788, i_class_id#17790, i_category_id#17792]
                           +- BroadcastHashJoin [ss_sold_date_sk#17758], [d_date_sk#17803], Inner, BuildRight, false
                              :- Project [ss_sold_date_sk#17758, ss_quantity#17768, ss_list_price#17770, i_brand_id#17788, i_class_id#17790, i_category_id#17792]
                              :  +- BroadcastHashJoin [ss_item_sk#17760], [i_item_sk#17781], Inner, BuildRight, false
                              :     :- SortMergeJoin [ss_item_sk#17760], [ss_item_sk#17870], LeftSemi
                              :     :  :- Sort [ss_item_sk#17760 ASC NULLS FIRST], false, 0
                              :     :  :  +- Exchange hashpartitioning(ss_item_sk#17760, 200), ENSURE_REQUIREMENTS, [plan_id=48359]
                              :     :  :     +- Filter (isnotnull(ss_item_sk#17760) AND isnotnull(ss_sold_date_sk#17758))
                              :     :  :        +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#17758,ss_item_sk#17760,ss_quantity#17768,ss_list_price#17770] Batched: true, DataFilters: [isnotnull(ss_item_sk#17760), isnotnull(ss_sold_date_sk#17758)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_item_sk), IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_quantity:int,ss_list_price:double>
                              :     :  +- Sort [ss_item_sk#17870 ASC NULLS FIRST], false, 0
                              :     :     +- Exchange hashpartitioning(ss_item_sk#17870, 200), ENSURE_REQUIREMENTS, [plan_id=48360]
                              :     :        +- Project [i_item_sk#19784 AS ss_item_sk#17870]
                              :     :           +- BroadcastHashJoin [i_brand_id#19791, i_class_id#19793, i_category_id#19795], [brand_id#17375, class_id#17376, category_id#17377], Inner, BuildLeft, false
                              :     :              :- BroadcastExchange HashedRelationBroadcastMode(List(input[1, int, false], input[2, int, false], input[3, int, false]),false), [plan_id=48354]
                              :     :              :  +- Filter ((isnotnull(i_brand_id#19791) AND isnotnull(i_class_id#19793)) AND isnotnull(i_category_id#19795))
                              :     :              :     +- FileScan parquet spark_catalog.m.item[i_item_sk#19784,i_brand_id#19791,i_class_id#19793,i_category_id#19795] Batched: true, DataFilters: [isnotnull(i_brand_id#19791), isnotnull(i_class_id#19793), isnotnull(i_category_id#19795)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
                              :     :              +- SortMergeJoin [coalesce(brand_id#17375, 0), isnull(brand_id#17375), coalesce(class_id#17376, 0), isnull(class_id#17376), coalesce(category_id#17377, 0), isnull(category_id#17377)], [coalesce(i_brand_id#20004, 0), isnull(i_brand_id#20004), coalesce(i_class_id#20006, 0), isnull(i_class_id#20006), coalesce(i_category_id#20008, 0), isnull(i_category_id#20008)], LeftSemi
                              :     :                 :- Sort [coalesce(brand_id#17375, 0) ASC NULLS FIRST, isnull(brand_id#17375) ASC NULLS FIRST, coalesce(class_id#17376, 0) ASC NULLS FIRST, isnull(class_id#17376) ASC NULLS FIRST, coalesce(category_id#17377, 0) ASC NULLS FIRST, isnull(category_id#17377) ASC NULLS FIRST], false, 0
                              :     :                 :  +- Exchange hashpartitioning(coalesce(brand_id#17375, 0), isnull(brand_id#17375), coalesce(class_id#17376, 0), isnull(class_id#17376), coalesce(category_id#17377, 0), isnull(category_id#17377), 200), ENSURE_REQUIREMENTS, [plan_id=48348]
                              :     :                 :     +- HashAggregate(keys=[brand_id#17375, class_id#17376, category_id#17377], functions=[], output=[brand_id#17375, class_id#17376, category_id#17377])
                              :     :                 :        +- Exchange hashpartitioning(brand_id#17375, class_id#17376, category_id#17377, 200), ENSURE_REQUIREMENTS, [plan_id=48337]
                              :     :                 :           +- HashAggregate(keys=[brand_id#17375, class_id#17376, category_id#17377], functions=[], output=[brand_id#17375, class_id#17376, category_id#17377])
                              :     :                 :              +- Project [i_brand_id#19836 AS brand_id#17375, i_class_id#19838 AS class_id#17376, i_category_id#19840 AS category_id#17377]
                              :     :                 :                 +- BroadcastHashJoin [ss_sold_date_sk#19806], [d_date_sk#19851], Inner, BuildRight, false
                              :     :                 :                    :- Project [ss_sold_date_sk#19806, i_brand_id#19836, i_class_id#19838, i_category_id#19840]
                              :     :                 :                    :  +- BroadcastHashJoin [ss_item_sk#19808], [i_item_sk#19829], Inner, BuildRight, false
                              :     :                 :                    :     :- Filter (isnotnull(ss_item_sk#19808) AND isnotnull(ss_sold_date_sk#19806))
                              :     :                 :                    :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#19806,ss_item_sk#19808] Batched: true, DataFilters: [isnotnull(ss_item_sk#19808), isnotnull(ss_sold_date_sk#19806)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_item_sk), IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int>
                              :     :                 :                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48328]
                              :     :                 :                    :        +- SortMergeJoin [coalesce(i_brand_id#19836, 0), isnull(i_brand_id#19836), coalesce(i_class_id#19838, 0), isnull(i_class_id#19838), coalesce(i_category_id#19840, 0), isnull(i_category_id#19840)], [coalesce(i_brand_id#19920, 0), isnull(i_brand_id#19920), coalesce(i_class_id#19922, 0), isnull(i_class_id#19922), coalesce(i_category_id#19924, 0), isnull(i_category_id#19924)], LeftSemi
                              :     :                 :                    :           :- Sort [coalesce(i_brand_id#19836, 0) ASC NULLS FIRST, isnull(i_brand_id#19836) ASC NULLS FIRST, coalesce(i_class_id#19838, 0) ASC NULLS FIRST, isnull(i_class_id#19838) ASC NULLS FIRST, coalesce(i_category_id#19840, 0) ASC NULLS FIRST, isnull(i_category_id#19840) ASC NULLS FIRST], false, 0
                              :     :                 :                    :           :  +- Exchange hashpartitioning(coalesce(i_brand_id#19836, 0), isnull(i_brand_id#19836), coalesce(i_class_id#19838, 0), isnull(i_class_id#19838), coalesce(i_category_id#19840, 0), isnull(i_category_id#19840), 200), ENSURE_REQUIREMENTS, [plan_id=48322]
                              :     :                 :                    :           :     +- Filter (((isnotnull(i_item_sk#19829) AND isnotnull(i_brand_id#19836)) AND isnotnull(i_class_id#19838)) AND isnotnull(i_category_id#19840))
                              :     :                 :                    :           :        +- FileScan parquet spark_catalog.m.item[i_item_sk#19829,i_brand_id#19836,i_class_id#19838,i_category_id#19840] Batched: true, DataFilters: [isnotnull(i_item_sk#19829), isnotnull(i_brand_id#19836), isnotnull(i_class_id#19838), isnotnull(..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
                              :     :                 :                    :           +- Sort [coalesce(i_brand_id#19920, 0) ASC NULLS FIRST, isnull(i_brand_id#19920) ASC NULLS FIRST, coalesce(i_class_id#19922, 0) ASC NULLS FIRST, isnull(i_class_id#19922) ASC NULLS FIRST, coalesce(i_category_id#19924, 0) ASC NULLS FIRST, isnull(i_category_id#19924) ASC NULLS FIRST], false, 0
                              :     :                 :                    :              +- Exchange hashpartitioning(coalesce(i_brand_id#19920, 0), isnull(i_brand_id#19920), coalesce(i_class_id#19922, 0), isnull(i_class_id#19922), coalesce(i_category_id#19924, 0), isnull(i_category_id#19924), 200), ENSURE_REQUIREMENTS, [plan_id=48323]
                              :     :                 :                    :                 +- Project [i_brand_id#19920, i_class_id#19922, i_category_id#19924]
                              :     :                 :                    :                    +- BroadcastHashJoin [cs_sold_date_sk#19879], [d_date_sk#19935], Inner, BuildRight, false
                              :     :                 :                    :                       :- Project [cs_sold_date_sk#19879, i_brand_id#19920, i_class_id#19922, i_category_id#19924]
                              :     :                 :                    :                       :  +- BroadcastHashJoin [cs_item_sk#19894], [i_item_sk#19913], Inner, BuildRight, false
                              :     :                 :                    :                       :     :- Filter (isnotnull(cs_item_sk#19894) AND isnotnull(cs_sold_date_sk#19879))
                              :     :                 :                    :                       :     :  +- FileScan parquet spark_catalog.m.catalog_sales[cs_sold_date_sk#19879,cs_item_sk#19894] Batched: true, DataFilters: [isnotnull(cs_item_sk#19894), isnotnull(cs_sold_date_sk#19879)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_item_sk), IsNotNull(cs_sold_date_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_item_sk:int>
                              :     :                 :                    :                       :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48313]
                              :     :                 :                    :                       :        +- Filter isnotnull(i_item_sk#19913)
                              :     :                 :                    :                       :           +- FileScan parquet spark_catalog.m.item[i_item_sk#19913,i_brand_id#19920,i_class_id#19922,i_category_id#19924] Batched: true, DataFilters: [isnotnull(i_item_sk#19913)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
                              :     :                 :                    :                       +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48317]
                              :     :                 :                    :                          +- Project [d_date_sk#19935]
                              :     :                 :                    :                             +- Filter (((isnotnull(d_year#19941) AND (d_year#19941 >= 1998)) AND (d_year#19941 <= 2000)) AND isnotnull(d_date_sk#19935))
                              :     :                 :                    :                                +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#19935,d_year#19941] Batched: true, DataFilters: [isnotnull(d_year#19941), (d_year#19941 >= 1998), (d_year#19941 <= 2000), isnotnull(d_date_sk#199..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
                              :     :                 :                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48332]
                              :     :                 :                       +- Project [d_date_sk#19851]
                              :     :                 :                          +- Filter (((isnotnull(d_year#19857) AND (d_year#19857 >= 1998)) AND (d_year#19857 <= 2000)) AND isnotnull(d_date_sk#19851))
                              :     :                 :                             +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#19851,d_year#19857] Batched: true, DataFilters: [isnotnull(d_year#19857), (d_year#19857 >= 1998), (d_year#19857 <= 2000), isnotnull(d_date_sk#198..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
                              :     :                 +- Sort [coalesce(i_brand_id#20004, 0) ASC NULLS FIRST, isnull(i_brand_id#20004) ASC NULLS FIRST, coalesce(i_class_id#20006, 0) ASC NULLS FIRST, isnull(i_class_id#20006) ASC NULLS FIRST, coalesce(i_category_id#20008, 0) ASC NULLS FIRST, isnull(i_category_id#20008) ASC NULLS FIRST], false, 0
                              :     :                    +- Exchange hashpartitioning(coalesce(i_brand_id#20004, 0), isnull(i_brand_id#20004), coalesce(i_class_id#20006, 0), isnull(i_class_id#20006), coalesce(i_category_id#20008, 0), isnull(i_category_id#20008), 200), ENSURE_REQUIREMENTS, [plan_id=48349]
                              :     :                       +- Project [i_brand_id#20004, i_class_id#20006, i_category_id#20008]
                              :     :                          +- BroadcastHashJoin [ws_sold_date_sk#19963], [d_date_sk#20019], Inner, BuildRight, false
                              :     :                             :- Project [ws_sold_date_sk#19963, i_brand_id#20004, i_class_id#20006, i_category_id#20008]
                              :     :                             :  +- BroadcastHashJoin [ws_item_sk#19966], [i_item_sk#19997], Inner, BuildRight, false
                              :     :                             :     :- Filter (isnotnull(ws_item_sk#19966) AND isnotnull(ws_sold_date_sk#19963))
                              :     :                             :     :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_date_sk#19963,ws_item_sk#19966] Batched: true, DataFilters: [isnotnull(ws_item_sk#19966), isnotnull(ws_sold_date_sk#19963)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_item_sk), IsNotNull(ws_sold_date_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_item_sk:int>
                              :     :                             :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48339]
                              :     :                             :        +- Filter isnotnull(i_item_sk#19997)
                              :     :                             :           +- FileScan parquet spark_catalog.m.item[i_item_sk#19997,i_brand_id#20004,i_class_id#20006,i_category_id#20008] Batched: true, DataFilters: [isnotnull(i_item_sk#19997)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
                              :     :                             +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48343]
                              :     :                                +- Project [d_date_sk#20019]
                              :     :                                   +- Filter (((isnotnull(d_year#20025) AND (d_year#20025 >= 1998)) AND (d_year#20025 <= 2000)) AND isnotnull(d_date_sk#20019))
                              :     :                                      +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#20019,d_year#20025] Batched: true, DataFilters: [isnotnull(d_year#20025), (d_year#20025 >= 1998), (d_year#20025 <= 2000), isnotnull(d_date_sk#200..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
                              :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48416]
                              :        +- SortMergeJoin [i_item_sk#17781], [ss_item_sk#17870], LeftSemi
                              :           :- Sort [i_item_sk#17781 ASC NULLS FIRST], false, 0
                              :           :  +- Exchange hashpartitioning(i_item_sk#17781, 200), ENSURE_REQUIREMENTS, [plan_id=48410]
                              :           :     +- Filter (((isnotnull(i_item_sk#17781) AND isnotnull(i_brand_id#17788)) AND isnotnull(i_class_id#17790)) AND isnotnull(i_category_id#17792))
                              :           :        +- FileScan parquet spark_catalog.m.item[i_item_sk#17781,i_brand_id#17788,i_class_id#17790,i_category_id#17792] Batched: true, DataFilters: [isnotnull(i_item_sk#17781), isnotnull(i_brand_id#17788), isnotnull(i_class_id#17790), isnotnull(..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
                              :           +- Sort [ss_item_sk#17870 ASC NULLS FIRST], false, 0
                              :              +- Exchange hashpartitioning(ss_item_sk#17870, 200), ENSURE_REQUIREMENTS, [plan_id=48411]
                              :                 +- Project [i_item_sk#19784 AS ss_item_sk#17870]
                              :                    +- BroadcastHashJoin [i_brand_id#19791, i_class_id#19793, i_category_id#19795], [brand_id#17375, class_id#17376, category_id#17377], Inner, BuildLeft, false
                              :                       :- BroadcastExchange HashedRelationBroadcastMode(List(input[1, int, false], input[2, int, false], input[3, int, false]),false), [plan_id=48405]
                              :                       :  +- Filter ((isnotnull(i_brand_id#19791) AND isnotnull(i_class_id#19793)) AND isnotnull(i_category_id#19795))
                              :                       :     +- FileScan parquet spark_catalog.m.item[i_item_sk#19784,i_brand_id#19791,i_class_id#19793,i_category_id#19795] Batched: true, DataFilters: [isnotnull(i_brand_id#19791), isnotnull(i_class_id#19793), isnotnull(i_category_id#19795)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
                              :                       +- SortMergeJoin [coalesce(brand_id#17375, 0), isnull(brand_id#17375), coalesce(class_id#17376, 0), isnull(class_id#17376), coalesce(category_id#17377, 0), isnull(category_id#17377)], [coalesce(i_brand_id#20004, 0), isnull(i_brand_id#20004), coalesce(i_class_id#20006, 0), isnull(i_class_id#20006), coalesce(i_category_id#20008, 0), isnull(i_category_id#20008)], LeftSemi
                              :                          :- Sort [coalesce(brand_id#17375, 0) ASC NULLS FIRST, isnull(brand_id#17375) ASC NULLS FIRST, coalesce(class_id#17376, 0) ASC NULLS FIRST, isnull(class_id#17376) ASC NULLS FIRST, coalesce(category_id#17377, 0) ASC NULLS FIRST, isnull(category_id#17377) ASC NULLS FIRST], false, 0
                              :                          :  +- Exchange hashpartitioning(coalesce(brand_id#17375, 0), isnull(brand_id#17375), coalesce(class_id#17376, 0), isnull(class_id#17376), coalesce(category_id#17377, 0), isnull(category_id#17377), 200), ENSURE_REQUIREMENTS, [plan_id=48399]
                              :                          :     +- HashAggregate(keys=[brand_id#17375, class_id#17376, category_id#17377], functions=[], output=[brand_id#17375, class_id#17376, category_id#17377])
                              :                          :        +- Exchange hashpartitioning(brand_id#17375, class_id#17376, category_id#17377, 200), ENSURE_REQUIREMENTS, [plan_id=48388]
                              :                          :           +- HashAggregate(keys=[brand_id#17375, class_id#17376, category_id#17377], functions=[], output=[brand_id#17375, class_id#17376, category_id#17377])
                              :                          :              +- Project [i_brand_id#19836 AS brand_id#17375, i_class_id#19838 AS class_id#17376, i_category_id#19840 AS category_id#17377]
                              :                          :                 +- BroadcastHashJoin [ss_sold_date_sk#19806], [d_date_sk#19851], Inner, BuildRight, false
                              :                          :                    :- Project [ss_sold_date_sk#19806, i_brand_id#19836, i_class_id#19838, i_category_id#19840]
                              :                          :                    :  +- BroadcastHashJoin [ss_item_sk#19808], [i_item_sk#19829], Inner, BuildRight, false
                              :                          :                    :     :- Filter (isnotnull(ss_item_sk#19808) AND isnotnull(ss_sold_date_sk#19806))
                              :                          :                    :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#19806,ss_item_sk#19808] Batched: true, DataFilters: [isnotnull(ss_item_sk#19808), isnotnull(ss_sold_date_sk#19806)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_item_sk), IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int>
                              :                          :                    :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48379]
                              :                          :                    :        +- SortMergeJoin [coalesce(i_brand_id#19836, 0), isnull(i_brand_id#19836), coalesce(i_class_id#19838, 0), isnull(i_class_id#19838), coalesce(i_category_id#19840, 0), isnull(i_category_id#19840)], [coalesce(i_brand_id#19920, 0), isnull(i_brand_id#19920), coalesce(i_class_id#19922, 0), isnull(i_class_id#19922), coalesce(i_category_id#19924, 0), isnull(i_category_id#19924)], LeftSemi
                              :                          :                    :           :- Sort [coalesce(i_brand_id#19836, 0) ASC NULLS FIRST, isnull(i_brand_id#19836) ASC NULLS FIRST, coalesce(i_class_id#19838, 0) ASC NULLS FIRST, isnull(i_class_id#19838) ASC NULLS FIRST, coalesce(i_category_id#19840, 0) ASC NULLS FIRST, isnull(i_category_id#19840) ASC NULLS FIRST], false, 0
                              :                          :                    :           :  +- Exchange hashpartitioning(coalesce(i_brand_id#19836, 0), isnull(i_brand_id#19836), coalesce(i_class_id#19838, 0), isnull(i_class_id#19838), coalesce(i_category_id#19840, 0), isnull(i_category_id#19840), 200), ENSURE_REQUIREMENTS, [plan_id=48373]
                              :                          :                    :           :     +- Filter (((isnotnull(i_item_sk#19829) AND isnotnull(i_brand_id#19836)) AND isnotnull(i_class_id#19838)) AND isnotnull(i_category_id#19840))
                              :                          :                    :           :        +- FileScan parquet spark_catalog.m.item[i_item_sk#19829,i_brand_id#19836,i_class_id#19838,i_category_id#19840] Batched: true, DataFilters: [isnotnull(i_item_sk#19829), isnotnull(i_brand_id#19836), isnotnull(i_class_id#19838), isnotnull(..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_brand_id), IsNotNull(i_class_id), IsNotNull(i_category_id)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
                              :                          :                    :           +- Sort [coalesce(i_brand_id#19920, 0) ASC NULLS FIRST, isnull(i_brand_id#19920) ASC NULLS FIRST, coalesce(i_class_id#19922, 0) ASC NULLS FIRST, isnull(i_class_id#19922) ASC NULLS FIRST, coalesce(i_category_id#19924, 0) ASC NULLS FIRST, isnull(i_category_id#19924) ASC NULLS FIRST], false, 0
                              :                          :                    :              +- Exchange hashpartitioning(coalesce(i_brand_id#19920, 0), isnull(i_brand_id#19920), coalesce(i_class_id#19922, 0), isnull(i_class_id#19922), coalesce(i_category_id#19924, 0), isnull(i_category_id#19924), 200), ENSURE_REQUIREMENTS, [plan_id=48374]
                              :                          :                    :                 +- Project [i_brand_id#19920, i_class_id#19922, i_category_id#19924]
                              :                          :                    :                    +- BroadcastHashJoin [cs_sold_date_sk#19879], [d_date_sk#19935], Inner, BuildRight, false
                              :                          :                    :                       :- Project [cs_sold_date_sk#19879, i_brand_id#19920, i_class_id#19922, i_category_id#19924]
                              :                          :                    :                       :  +- BroadcastHashJoin [cs_item_sk#19894], [i_item_sk#19913], Inner, BuildRight, false
                              :                          :                    :                       :     :- Filter (isnotnull(cs_item_sk#19894) AND isnotnull(cs_sold_date_sk#19879))
                              :                          :                    :                       :     :  +- FileScan parquet spark_catalog.m.catalog_sales[cs_sold_date_sk#19879,cs_item_sk#19894] Batched: true, DataFilters: [isnotnull(cs_item_sk#19894), isnotnull(cs_sold_date_sk#19879)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_item_sk), IsNotNull(cs_sold_date_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_item_sk:int>
                              :                          :                    :                       :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48364]
                              :                          :                    :                       :        +- Filter isnotnull(i_item_sk#19913)
                              :                          :                    :                       :           +- FileScan parquet spark_catalog.m.item[i_item_sk#19913,i_brand_id#19920,i_class_id#19922,i_category_id#19924] Batched: true, DataFilters: [isnotnull(i_item_sk#19913)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
                              :                          :                    :                       +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48368]
                              :                          :                    :                          +- Project [d_date_sk#19935]
                              :                          :                    :                             +- Filter (((isnotnull(d_year#19941) AND (d_year#19941 >= 1998)) AND (d_year#19941 <= 2000)) AND isnotnull(d_date_sk#19935))
                              :                          :                    :                                +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#19935,d_year#19941] Batched: true, DataFilters: [isnotnull(d_year#19941), (d_year#19941 >= 1998), (d_year#19941 <= 2000), isnotnull(d_date_sk#199..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
                              :                          :                    +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48383]
                              :                          :                       +- Project [d_date_sk#19851]
                              :                          :                          +- Filter (((isnotnull(d_year#19857) AND (d_year#19857 >= 1998)) AND (d_year#19857 <= 2000)) AND isnotnull(d_date_sk#19851))
                              :                          :                             +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#19851,d_year#19857] Batched: true, DataFilters: [isnotnull(d_year#19857), (d_year#19857 >= 1998), (d_year#19857 <= 2000), isnotnull(d_date_sk#198..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
                              :                          +- Sort [coalesce(i_brand_id#20004, 0) ASC NULLS FIRST, isnull(i_brand_id#20004) ASC NULLS FIRST, coalesce(i_class_id#20006, 0) ASC NULLS FIRST, isnull(i_class_id#20006) ASC NULLS FIRST, coalesce(i_category_id#20008, 0) ASC NULLS FIRST, isnull(i_category_id#20008) ASC NULLS FIRST], false, 0
                              :                             +- Exchange hashpartitioning(coalesce(i_brand_id#20004, 0), isnull(i_brand_id#20004), coalesce(i_class_id#20006, 0), isnull(i_class_id#20006), coalesce(i_category_id#20008, 0), isnull(i_category_id#20008), 200), ENSURE_REQUIREMENTS, [plan_id=48400]
                              :                                +- Project [i_brand_id#20004, i_class_id#20006, i_category_id#20008]
                              :                                   +- BroadcastHashJoin [ws_sold_date_sk#19963], [d_date_sk#20019], Inner, BuildRight, false
                              :                                      :- Project [ws_sold_date_sk#19963, i_brand_id#20004, i_class_id#20006, i_category_id#20008]
                              :                                      :  +- BroadcastHashJoin [ws_item_sk#19966], [i_item_sk#19997], Inner, BuildRight, false
                              :                                      :     :- Filter (isnotnull(ws_item_sk#19966) AND isnotnull(ws_sold_date_sk#19963))
                              :                                      :     :  +- FileScan parquet spark_catalog.m.web_sales[ws_sold_date_sk#19963,ws_item_sk#19966] Batched: true, DataFilters: [isnotnull(ws_item_sk#19966), isnotnull(ws_sold_date_sk#19963)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ws_item_sk), IsNotNull(ws_sold_date_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_item_sk:int>
                              :                                      :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=48390]
                              :                                      :        +- Filter isnotnull(i_item_sk#19997)
                              :                                      :           +- FileScan parquet spark_catalog.m.item[i_item_sk#19997,i_brand_id#20004,i_class_id#20006,i_category_id#20008] Batched: true, DataFilters: [isnotnull(i_item_sk#19997)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/item], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_class_id:int,i_category_id:int>
                              :                                      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48394]
                              :                                         +- Project [d_date_sk#20019]
                              :                                            +- Filter (((isnotnull(d_year#20025) AND (d_year#20025 >= 1998)) AND (d_year#20025 <= 2000)) AND isnotnull(d_date_sk#20019))
                              :                                               +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#20019,d_year#20025] Batched: true, DataFilters: [isnotnull(d_year#20025), (d_year#20025 >= 1998), (d_year#20025 <= 2000), isnotnull(d_date_sk#200..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), GreaterThanOrEqual(d_year,1998), LessThanOrEqual(d_year,2000), IsNotNull(d_da..., ReadSchema: struct<d_date_sk:int,d_year:int>
                              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=48420]
                                 +- Project [d_date_sk#17803]
                                    +- Filter ((isnotnull(d_week_seq#17807) AND (d_week_seq#17807 = Subquery subquery#17361, [id=#48093])) AND isnotnull(d_date_sk#17803))
                                       :  +- Subquery subquery#17361, [id=#48093]
                                       :     +- AdaptiveSparkPlan isFinalPlan=false
                                       :        +- Project [d_week_seq#17875]
                                       :           +- Filter (((((isnotnull(d_year#17877) AND isnotnull(d_moy#17879)) AND isnotnull(d_dom#17880)) AND (d_year#17877 = 1998)) AND (d_moy#17879 = 12)) AND (d_dom#17880 = 20))
                                       :              +- FileScan parquet spark_catalog.m.date_dim[d_week_seq#17875,d_year#17877,d_moy#17879,d_dom#17880] Batched: true, DataFilters: [isnotnull(d_year#17877), isnotnull(d_moy#17879), isnotnull(d_dom#17880), (d_year#17877 = 1998), ..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), IsNotNull(d_dom), EqualTo(d_year,1998), EqualTo(d_moy,12), ..., ReadSchema: struct<d_week_seq:int,d_year:int,d_moy:int,d_dom:int>
                                       +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#17803,d_week_seq#17807] Batched: true, DataFilters: [isnotnull(d_week_seq#17807), isnotnull(d_date_sk#17803)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_week_seq), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_week_seq:int>
