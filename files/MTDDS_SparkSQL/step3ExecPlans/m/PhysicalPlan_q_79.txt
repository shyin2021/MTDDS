AdaptiveSparkPlan isFinalPlan=false
+- TakeOrderedAndProject(limit=100, orderBy=[c_last_name#90 ASC NULLS FIRST,c_first_name#89 ASC NULLS FIRST,substr(s_city#74, 1, 30) ASC NULLS FIRST,profit#46396 ASC NULLS FIRST], output=[c_last_name#90,c_first_name#89,substr(s_city, 1, 30)#46399,ss_ticket_number#1257,amt#46395,profit#46396])
   +- Project [c_last_name#90, c_first_name#89, substr(s_city#74, 1, 30) AS substr(s_city, 1, 30)#46399, ss_ticket_number#1257, amt#46395, profit#46396, s_city#74]
      +- BroadcastHashJoin [ss_customer_sk#1251], [c_customer_sk#81], Inner, BuildRight, false
         :- HashAggregate(keys=[ss_ticket_number#1257, ss_customer_sk#1251, ss_addr_sk#1254, s_city#74], functions=[sum(ss_coupon_amt#1267), sum(ss_net_profit#1270)], output=[ss_ticket_number#1257, ss_customer_sk#1251, s_city#74, amt#46395, profit#46396])
         :  +- Exchange hashpartitioning(ss_ticket_number#1257, ss_customer_sk#1251, ss_addr_sk#1254, s_city#74, 200), ENSURE_REQUIREMENTS, [plan_id=153890]
         :     +- HashAggregate(keys=[ss_ticket_number#1257, ss_customer_sk#1251, ss_addr_sk#1254, s_city#74], functions=[partial_sum(ss_coupon_amt#1267), partial_sum(ss_net_profit#1270)], output=[ss_ticket_number#1257, ss_customer_sk#1251, ss_addr_sk#1254, s_city#74, sum#46426, sum#46427])
         :        +- Project [ss_customer_sk#1251, ss_addr_sk#1254, ss_ticket_number#1257, ss_coupon_amt#1267, ss_net_profit#1270, s_city#74]
         :           +- BroadcastHashJoin [ss_hdemo_sk#1253], [hd_demo_sk#12110], Inner, BuildRight, false
         :              :- Project [ss_customer_sk#1251, ss_hdemo_sk#1253, ss_addr_sk#1254, ss_ticket_number#1257, ss_coupon_amt#1267, ss_net_profit#1270, s_city#74]
         :              :  +- BroadcastHashJoin [ss_store_sk#1255], [s_store_sk#52], Inner, BuildRight, false
         :              :     :- Project [ss_customer_sk#1251, ss_hdemo_sk#1253, ss_addr_sk#1254, ss_store_sk#1255, ss_ticket_number#1257, ss_coupon_amt#1267, ss_net_profit#1270]
         :              :     :  +- BroadcastHashJoin [ss_sold_date_sk#1248], [d_date_sk#24], Inner, BuildRight, false
         :              :     :     :- Filter (((isnotnull(ss_sold_date_sk#1248) AND isnotnull(ss_store_sk#1255)) AND isnotnull(ss_hdemo_sk#1253)) AND isnotnull(ss_customer_sk#1251))
         :              :     :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#1248,ss_customer_sk#1251,ss_hdemo_sk#1253,ss_addr_sk#1254,ss_store_sk#1255,ss_ticket_number#1257,ss_coupon_amt#1267,ss_net_profit#1270] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#1248), isnotnull(ss_store_sk#1255), isnotnull(ss_hdemo_sk#1253), isnot..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_store_sk), IsNotNull(ss_hdemo_sk), IsNotNull(ss_custome..., ReadSchema: struct<ss_sold_date_sk:int,ss_customer_sk:int,ss_hdemo_sk:int,ss_addr_sk:int,ss_store_sk:int,ss_t...
         :              :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=153877]
         :              :     :        +- Project [d_date_sk#24]
         :              :     :           +- Filter (((isnotnull(d_dow#31) AND (d_dow#31 = 1)) AND d_year#30 IN (1998,1999,2000)) AND isnotnull(d_date_sk#24))
         :              :     :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#24,d_year#30,d_dow#31] Batched: true, DataFilters: [isnotnull(d_dow#31), (d_dow#31 = 1), d_year#30 IN (1998,1999,2000), isnotnull(d_date_sk#24)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_dow), EqualTo(d_dow,1), In(d_year, [1998,1999,2000]), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int,d_dow:int>
         :              :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=153881]
         :              :        +- Project [s_store_sk#52, s_city#74]
         :              :           +- Filter (((isnotnull(s_number_employees#58) AND (s_number_employees#58 >= 200)) AND (s_number_employees#58 <= 295)) AND isnotnull(s_store_sk#52))
         :              :              +- FileScan parquet spark_catalog.m.store[s_store_sk#52,s_number_employees#58,s_city#74] Batched: true, DataFilters: [isnotnull(s_number_employees#58), (s_number_employees#58 >= 200), (s_number_employees#58 <= 295)..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_number_employees), GreaterThanOrEqual(s_number_employees,200), LessThanOrEqual(s_num..., ReadSchema: struct<s_store_sk:int,s_number_employees:int,s_city:string>
         :              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=153885]
         :                 +- Project [hd_demo_sk#12110]
         :                    +- Filter (((hd_dep_count#12113 = 4) OR (hd_vehicle_count#12114 > 0)) AND isnotnull(hd_demo_sk#12110))
         :                       +- FileScan parquet spark_catalog.m.household_demographics[hd_demo_sk#12110,hd_dep_count#12113,hd_vehicle_count#12114] Batched: true, DataFilters: [((hd_dep_count#12113 = 4) OR (hd_vehicle_count#12114 > 0)), isnotnull(hd_demo_sk#12110)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/household_demograp..., PartitionFilters: [], PushedFilters: [Or(EqualTo(hd_dep_count,4),GreaterThan(hd_vehicle_count,0)), IsNotNull(hd_demo_sk)], ReadSchema: struct<hd_demo_sk:int,hd_dep_count:int,hd_vehicle_count:int>
         +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=153893]
            +- Filter isnotnull(c_customer_sk#81)
               +- FileScan parquet spark_catalog.m.customer[c_customer_sk#81,c_first_name#89,c_last_name#90] Batched: true, DataFilters: [isnotnull(c_customer_sk#81)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk)], ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string>
