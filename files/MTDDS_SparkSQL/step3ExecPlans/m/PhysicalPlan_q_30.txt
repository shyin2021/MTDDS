AdaptiveSparkPlan isFinalPlan=false
+- TakeOrderedAndProject(limit=100, orderBy=[c_customer_id#82 ASC NULLS FIRST,c_salutation#88 ASC NULLS FIRST,c_first_name#89 ASC NULLS FIRST,c_last_name#90 ASC NULLS FIRST,c_preferred_cust_flag#91 ASC NULLS FIRST,c_birth_day#92 ASC NULLS FIRST,c_birth_month#93 ASC NULLS FIRST,c_birth_year#94 ASC NULLS FIRST,c_birth_country#95 ASC NULLS FIRST,c_login#96 ASC NULLS FIRST,c_email_address#97 ASC NULLS FIRST,ctr_total_return#26566 ASC NULLS FIRST], output=[c_customer_id#82,c_salutation#88,c_first_name#89,c_last_name#90,c_preferred_cust_flag#91,c_birth_day#92,c_birth_month#93,c_birth_year#94,c_birth_country#95,c_login#96,c_email_address#97,ctr_total_return#26566])
   +- Project [c_customer_id#82, c_salutation#88, c_first_name#89, c_last_name#90, c_preferred_cust_flag#91, c_birth_day#92, c_birth_month#93, c_birth_year#94, c_birth_country#95, c_login#96, c_email_address#97, ctr_total_return#26566]
      +- BroadcastHashJoin [c_current_addr_sk#85], [ca_address_sk#26567], Inner, BuildRight, false
         :- Project [ctr_total_return#26566, c_customer_id#82, c_current_addr_sk#85, c_salutation#88, c_first_name#89, c_last_name#90, c_preferred_cust_flag#91, c_birth_day#92, c_birth_month#93, c_birth_year#94, c_birth_country#95, c_login#96, c_email_address#97]
         :  +- BroadcastHashJoin [ctr_customer_sk#26564], [c_customer_sk#81], Inner, BuildRight, false
         :     :- Project [ctr_customer_sk#26564, ctr_total_return#26566]
         :     :  +- SortMergeJoin [ctr_state#26565], [ctr_state#26582], Inner, (ctr_total_return#26566 > (avg(ctr_total_return) * 1.2)#26585)
         :     :     :- Sort [ctr_state#26565 ASC NULLS FIRST], false, 0
         :     :     :  +- Exchange hashpartitioning(ctr_state#26565, 200), ENSURE_REQUIREMENTS, [plan_id=75988]
         :     :     :     +- Filter isnotnull(ctr_total_return#26566)
         :     :     :        +- HashAggregate(keys=[wr_returning_customer_sk#7854, ca_state#8179], functions=[sum(wr_return_amt#7862)], output=[ctr_customer_sk#26564, ctr_state#26565, ctr_total_return#26566])
         :     :     :           +- Exchange hashpartitioning(wr_returning_customer_sk#7854, ca_state#8179, 200), ENSURE_REQUIREMENTS, [plan_id=75967]
         :     :     :              +- HashAggregate(keys=[wr_returning_customer_sk#7854, ca_state#8179], functions=[partial_sum(wr_return_amt#7862)], output=[wr_returning_customer_sk#7854, ca_state#8179, sum#26908])
         :     :     :                 +- Project [wr_returning_customer_sk#7854, wr_return_amt#7862, ca_state#8179]
         :     :     :                    +- BroadcastHashJoin [wr_returning_addr_sk#7857], [ca_address_sk#8171], Inner, BuildRight, false
         :     :     :                       :- Project [wr_returning_customer_sk#7854, wr_returning_addr_sk#7857, wr_return_amt#7862]
         :     :     :                       :  +- BroadcastHashJoin [wr_returned_date_sk#7847], [d_date_sk#24], Inner, BuildRight, false
         :     :     :                       :     :- Filter ((isnotnull(wr_returned_date_sk#7847) AND isnotnull(wr_returning_addr_sk#7857)) AND isnotnull(wr_returning_customer_sk#7854))
         :     :     :                       :     :  +- FileScan parquet spark_catalog.m.web_returns[wr_returned_date_sk#7847,wr_returning_customer_sk#7854,wr_returning_addr_sk#7857,wr_return_amt#7862] Batched: true, DataFilters: [isnotnull(wr_returned_date_sk#7847), isnotnull(wr_returning_addr_sk#7857), isnotnull(wr_returnin..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_returns], PartitionFilters: [], PushedFilters: [IsNotNull(wr_returned_date_sk), IsNotNull(wr_returning_addr_sk), IsNotNull(wr_returning_customer..., ReadSchema: struct<wr_returned_date_sk:int,wr_returning_customer_sk:int,wr_returning_addr_sk:int,wr_return_am...
         :     :     :                       :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=75958]
         :     :     :                       :        +- Project [d_date_sk#24]
         :     :     :                       :           +- Filter ((isnotnull(d_year#30) AND (d_year#30 = 2001)) AND isnotnull(d_date_sk#24))
         :     :     :                       :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#24,d_year#30] Batched: true, DataFilters: [isnotnull(d_year#30), (d_year#30 = 2001), isnotnull(d_date_sk#24)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), EqualTo(d_year,2001), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int>
         :     :     :                       +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=75962]
         :     :     :                          +- Filter (isnotnull(ca_address_sk#8171) AND isnotnull(ca_state#8179))
         :     :     :                             +- FileScan parquet spark_catalog.m.customer_address[ca_address_sk#8171,ca_state#8179] Batched: true, DataFilters: [isnotnull(ca_address_sk#8171), isnotnull(ca_state#8179)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk), IsNotNull(ca_state)], ReadSchema: struct<ca_address_sk:int,ca_state:string>
         :     :     +- Sort [ctr_state#26582 ASC NULLS FIRST], false, 0
         :     :        +- Filter isnotnull((avg(ctr_total_return) * 1.2)#26585)
         :     :           +- HashAggregate(keys=[ctr_state#26582], functions=[avg(ctr_total_return#26583)], output=[(avg(ctr_total_return) * 1.2)#26585, ctr_state#26582])
         :     :              +- Exchange hashpartitioning(ctr_state#26582, 200), ENSURE_REQUIREMENTS, [plan_id=75983]
         :     :                 +- HashAggregate(keys=[ctr_state#26582], functions=[partial_avg(ctr_total_return#26583)], output=[ctr_state#26582, sum#26911, count#26912L])
         :     :                    +- HashAggregate(keys=[wr_returning_customer_sk#26959, ca_state#27012], functions=[sum(wr_return_amt#26967)], output=[ctr_state#26582, ctr_total_return#26583])
         :     :                       +- Exchange hashpartitioning(wr_returning_customer_sk#26959, ca_state#27012, 200), ENSURE_REQUIREMENTS, [plan_id=75979]
         :     :                          +- HashAggregate(keys=[wr_returning_customer_sk#26959, ca_state#27012], functions=[partial_sum(wr_return_amt#26967)], output=[wr_returning_customer_sk#26959, ca_state#27012, sum#27021])
         :     :                             +- Project [wr_returning_customer_sk#26959, wr_return_amt#26967, ca_state#27012]
         :     :                                +- BroadcastHashJoin [wr_returning_addr_sk#26962], [ca_address_sk#27004], Inner, BuildRight, false
         :     :                                   :- Project [wr_returning_customer_sk#26959, wr_returning_addr_sk#26962, wr_return_amt#26967]
         :     :                                   :  +- BroadcastHashJoin [wr_returned_date_sk#26952], [d_date_sk#26976], Inner, BuildRight, false
         :     :                                   :     :- Filter (isnotnull(wr_returned_date_sk#26952) AND isnotnull(wr_returning_addr_sk#26962))
         :     :                                   :     :  +- FileScan parquet spark_catalog.m.web_returns[wr_returned_date_sk#26952,wr_returning_customer_sk#26959,wr_returning_addr_sk#26962,wr_return_amt#26967] Batched: true, DataFilters: [isnotnull(wr_returned_date_sk#26952), isnotnull(wr_returning_addr_sk#26962)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/web_returns], PartitionFilters: [], PushedFilters: [IsNotNull(wr_returned_date_sk), IsNotNull(wr_returning_addr_sk)], ReadSchema: struct<wr_returned_date_sk:int,wr_returning_customer_sk:int,wr_returning_addr_sk:int,wr_return_am...
         :     :                                   :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=75970]
         :     :                                   :        +- Project [d_date_sk#26976]
         :     :                                   :           +- Filter ((isnotnull(d_year#26982) AND (d_year#26982 = 2001)) AND isnotnull(d_date_sk#26976))
         :     :                                   :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#26976,d_year#26982] Batched: true, DataFilters: [isnotnull(d_year#26982), (d_year#26982 = 2001), isnotnull(d_date_sk#26976)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_year), EqualTo(d_year,2001), IsNotNull(d_date_sk)], ReadSchema: struct<d_date_sk:int,d_year:int>
         :     :                                   +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=75974]
         :     :                                      +- Filter (isnotnull(ca_address_sk#27004) AND isnotnull(ca_state#27012))
         :     :                                         +- FileScan parquet spark_catalog.m.customer_address[ca_address_sk#27004,ca_state#27012] Batched: true, DataFilters: [isnotnull(ca_address_sk#27004), isnotnull(ca_state#27012)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk), IsNotNull(ca_state)], ReadSchema: struct<ca_address_sk:int,ca_state:string>
         :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=75994]
         :        +- Filter (isnotnull(c_customer_sk#81) AND isnotnull(c_current_addr_sk#85))
         :           +- FileScan parquet spark_catalog.m.customer[c_customer_sk#81,c_customer_id#82,c_current_addr_sk#85,c_salutation#88,c_first_name#89,c_last_name#90,c_preferred_cust_flag#91,c_birth_day#92,c_birth_month#93,c_birth_year#94,c_birth_country#95,c_login#96,c_email_address#97] Batched: true, DataFilters: [isnotnull(c_customer_sk#81), isnotnull(c_current_addr_sk#85)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk), IsNotNull(c_current_addr_sk)], ReadSchema: struct<c_customer_sk:int,c_customer_id:string,c_current_addr_sk:int,c_salutation:string,c_first_n...
         +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=75998]
            +- Project [ca_address_sk#26567]
               +- Filter ((isnotnull(ca_state#26575) AND (ca_state#26575 = GA)) AND isnotnull(ca_address_sk#26567))
                  +- FileScan parquet spark_catalog.m.customer_address[ca_address_sk#26567,ca_state#26575] Batched: true, DataFilters: [isnotnull(ca_state#26575), (ca_state#26575 = GA), isnotnull(ca_address_sk#26567)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_state), EqualTo(ca_state,GA), IsNotNull(ca_address_sk)], ReadSchema: struct<ca_address_sk:int,ca_state:string>
