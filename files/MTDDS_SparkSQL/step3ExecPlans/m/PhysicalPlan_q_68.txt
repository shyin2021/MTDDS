AdaptiveSparkPlan isFinalPlan=false
+- TakeOrderedAndProject(limit=100, orderBy=[c_last_name#90 ASC NULLS FIRST,ss_ticket_number#1257 ASC NULLS FIRST], output=[c_last_name#90,c_first_name#89,ca_city#40724,bought_city#40714,ss_ticket_number#1257,extended_price#40715,extended_tax#40717,list_price#40716])
   +- Project [c_last_name#90, c_first_name#89, ca_city#40724, bought_city#40714, ss_ticket_number#1257, extended_price#40715, extended_tax#40717, list_price#40716]
      +- BroadcastHashJoin [c_current_addr_sk#85], [ca_address_sk#40718], Inner, BuildRight, NOT (ca_city#40724 = bought_city#40714), false
         :- Project [ss_ticket_number#1257, bought_city#40714, extended_price#40715, list_price#40716, extended_tax#40717, c_current_addr_sk#85, c_first_name#89, c_last_name#90]
         :  +- BroadcastHashJoin [ss_customer_sk#1251], [c_customer_sk#81], Inner, BuildRight, false
         :     :- HashAggregate(keys=[ss_ticket_number#1257, ss_customer_sk#1251, ss_addr_sk#1254, ca_city#8177], functions=[sum(ss_ext_sales_price#1263), sum(ss_ext_list_price#1265), sum(ss_ext_tax#1266)], output=[ss_ticket_number#1257, ss_customer_sk#1251, bought_city#40714, extended_price#40715, list_price#40716, extended_tax#40717])
         :     :  +- Exchange hashpartitioning(ss_ticket_number#1257, ss_customer_sk#1251, ss_addr_sk#1254, ca_city#8177, 200), ENSURE_REQUIREMENTS, [plan_id=135250]
         :     :     +- HashAggregate(keys=[ss_ticket_number#1257, ss_customer_sk#1251, ss_addr_sk#1254, ca_city#8177], functions=[partial_sum(ss_ext_sales_price#1263), partial_sum(ss_ext_list_price#1265), partial_sum(ss_ext_tax#1266)], output=[ss_ticket_number#1257, ss_customer_sk#1251, ss_addr_sk#1254, ca_city#8177, sum#40770, sum#40771, sum#40772])
         :     :        +- Project [ss_customer_sk#1251, ss_addr_sk#1254, ss_ticket_number#1257, ss_ext_sales_price#1263, ss_ext_list_price#1265, ss_ext_tax#1266, ca_city#8177]
         :     :           +- BroadcastHashJoin [ss_addr_sk#1254], [ca_address_sk#8171], Inner, BuildRight, false
         :     :              :- Project [ss_customer_sk#1251, ss_addr_sk#1254, ss_ticket_number#1257, ss_ext_sales_price#1263, ss_ext_list_price#1265, ss_ext_tax#1266]
         :     :              :  +- BroadcastHashJoin [ss_hdemo_sk#1253], [hd_demo_sk#12110], Inner, BuildRight, false
         :     :              :     :- Project [ss_customer_sk#1251, ss_hdemo_sk#1253, ss_addr_sk#1254, ss_ticket_number#1257, ss_ext_sales_price#1263, ss_ext_list_price#1265, ss_ext_tax#1266]
         :     :              :     :  +- BroadcastHashJoin [ss_store_sk#1255], [s_store_sk#52], Inner, BuildRight, false
         :     :              :     :     :- Project [ss_customer_sk#1251, ss_hdemo_sk#1253, ss_addr_sk#1254, ss_store_sk#1255, ss_ticket_number#1257, ss_ext_sales_price#1263, ss_ext_list_price#1265, ss_ext_tax#1266]
         :     :              :     :     :  +- BroadcastHashJoin [ss_sold_date_sk#1248], [d_date_sk#24], Inner, BuildRight, false
         :     :              :     :     :     :- Filter ((((isnotnull(ss_sold_date_sk#1248) AND isnotnull(ss_store_sk#1255)) AND isnotnull(ss_hdemo_sk#1253)) AND isnotnull(ss_addr_sk#1254)) AND isnotnull(ss_customer_sk#1251))
         :     :              :     :     :     :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#1248,ss_customer_sk#1251,ss_hdemo_sk#1253,ss_addr_sk#1254,ss_store_sk#1255,ss_ticket_number#1257,ss_ext_sales_price#1263,ss_ext_list_price#1265,ss_ext_tax#1266] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#1248), isnotnull(ss_store_sk#1255), isnotnull(ss_hdemo_sk#1253), isnot..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_store_sk), IsNotNull(ss_hdemo_sk), IsNotNull(ss_addr_sk..., ReadSchema: struct<ss_sold_date_sk:int,ss_customer_sk:int,ss_hdemo_sk:int,ss_addr_sk:int,ss_store_sk:int,ss_t...
         :     :              :     :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=135233]
         :     :              :     :     :        +- Project [d_date_sk#24]
         :     :              :     :     :           +- Filter ((((isnotnull(d_dom#33) AND (d_dom#33 >= 1)) AND (d_dom#33 <= 2)) AND d_year#30 IN (1998,1999,2000)) AND isnotnull(d_date_sk#24))
         :     :              :     :     :              +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#24,d_year#30,d_dom#33] Batched: true, DataFilters: [isnotnull(d_dom#33), (d_dom#33 >= 1), (d_dom#33 <= 2), d_year#30 IN (1998,1999,2000), isnotnull(..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_dom), GreaterThanOrEqual(d_dom,1), LessThanOrEqual(d_dom,2), In(d_year, [1998,1999,2..., ReadSchema: struct<d_date_sk:int,d_year:int,d_dom:int>
         :     :              :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=135237]
         :     :              :     :        +- Project [s_store_sk#52]
         :     :              :     :           +- Filter (s_city#74 IN (Oak Grove,Fairview) AND isnotnull(s_store_sk#52))
         :     :              :     :              +- FileScan parquet spark_catalog.m.store[s_store_sk#52,s_city#74] Batched: true, DataFilters: [s_city#74 IN (Oak Grove,Fairview), isnotnull(s_store_sk#52)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store], PartitionFilters: [], PushedFilters: [In(s_city, [Fairview,Oak Grove]), IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_city:string>
         :     :              :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=135241]
         :     :              :        +- Project [hd_demo_sk#12110]
         :     :              :           +- Filter (((hd_dep_count#12113 = 5) OR (hd_vehicle_count#12114 = 1)) AND isnotnull(hd_demo_sk#12110))
         :     :              :              +- FileScan parquet spark_catalog.m.household_demographics[hd_demo_sk#12110,hd_dep_count#12113,hd_vehicle_count#12114] Batched: true, DataFilters: [((hd_dep_count#12113 = 5) OR (hd_vehicle_count#12114 = 1)), isnotnull(hd_demo_sk#12110)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/household_demograp..., PartitionFilters: [], PushedFilters: [Or(EqualTo(hd_dep_count,5),EqualTo(hd_vehicle_count,1)), IsNotNull(hd_demo_sk)], ReadSchema: struct<hd_demo_sk:int,hd_dep_count:int,hd_vehicle_count:int>
         :     :              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=135245]
         :     :                 +- Filter (isnotnull(ca_address_sk#8171) AND isnotnull(ca_city#8177))
         :     :                    +- FileScan parquet spark_catalog.m.customer_address[ca_address_sk#8171,ca_city#8177] Batched: true, DataFilters: [isnotnull(ca_address_sk#8171), isnotnull(ca_city#8177)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk), IsNotNull(ca_city)], ReadSchema: struct<ca_address_sk:int,ca_city:string>
         :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=135253]
         :        +- Filter (isnotnull(c_customer_sk#81) AND isnotnull(c_current_addr_sk#85))
         :           +- FileScan parquet spark_catalog.m.customer[c_customer_sk#81,c_current_addr_sk#85,c_first_name#89,c_last_name#90] Batched: true, DataFilters: [isnotnull(c_customer_sk#81), isnotnull(c_current_addr_sk#85)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer], PartitionFilters: [], PushedFilters: [IsNotNull(c_customer_sk), IsNotNull(c_current_addr_sk)], ReadSchema: struct<c_customer_sk:int,c_current_addr_sk:int,c_first_name:string,c_last_name:string>
         +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=135257]
            +- Filter (isnotnull(ca_address_sk#40718) AND isnotnull(ca_city#40724))
               +- FileScan parquet spark_catalog.m.customer_address[ca_address_sk#40718,ca_city#40724] Batched: true, DataFilters: [isnotnull(ca_address_sk#40718), isnotnull(ca_city#40724)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/customer_address], PartitionFilters: [], PushedFilters: [IsNotNull(ca_address_sk), IsNotNull(ca_city)], ReadSchema: struct<ca_address_sk:int,ca_city:string>
