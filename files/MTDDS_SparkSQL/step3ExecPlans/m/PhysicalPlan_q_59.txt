AdaptiveSparkPlan isFinalPlan=false
+- TakeOrderedAndProject(limit=100, orderBy=[s_store_name1#36082 ASC NULLS FIRST,s_store_id1#36084 ASC NULLS FIRST,d_week_seq1#36083 ASC NULLS FIRST], output=[s_store_name1#36082,s_store_id1#36084,d_week_seq1#36083,(sun_sales1 / sun_sales2)#36210,(mon_sales1 / mon_sales2)#36211,(tue_sales1 / tue_sales2)#36212,(wed_sales1 / wed_sales2)#36213,(thu_sales1 / thu_sales2)#36214,(fri_sales1 / fri_sales2)#36215,(sat_sales1 / sat_sales2)#36216])
   +- Project [s_store_name1#36082, s_store_id1#36084, d_week_seq1#36083, (sun_sales1#36085 / sun_sales2#36095) AS (sun_sales1 / sun_sales2)#36210, (mon_sales1#36086 / mon_sales2#36096) AS (mon_sales1 / mon_sales2)#36211, (tue_sales1#36087 / tue_sales2#36097) AS (tue_sales1 / tue_sales2)#36212, (wed_sales1#36088 / wed_sales2#36098) AS (wed_sales1 / wed_sales2)#36213, (thu_sales1#36089 / thu_sales2#36099) AS (thu_sales1 / thu_sales2)#36214, (fri_sales1#36090 / fri_sales2#36100) AS (fri_sales1 / fri_sales2)#36215, (sat_sales1#36091 / sat_sales2#36101) AS (sat_sales1 / sat_sales2)#36216]
      +- SortMergeJoin [s_store_id1#36084, d_week_seq1#36083], [s_store_id2#36094, (d_week_seq2#36093 - 52)], Inner
         :- Sort [s_store_id1#36084 ASC NULLS FIRST, d_week_seq1#36083 ASC NULLS FIRST], false, 0
         :  +- Exchange hashpartitioning(s_store_id1#36084, d_week_seq1#36083, 200), ENSURE_REQUIREMENTS, [plan_id=114405]
         :     +- Project [s_store_name#57 AS s_store_name1#36082, d_week_seq#28 AS d_week_seq1#36083, s_store_id#53 AS s_store_id1#36084, sun_sales#36102 AS sun_sales1#36085, mon_sales#36103 AS mon_sales1#36086, tue_sales#36104 AS tue_sales1#36087, wed_sales#36105 AS wed_sales1#36088, thu_sales#36106 AS thu_sales1#36089, fri_sales#36107 AS fri_sales1#36090, sat_sales#36108 AS sat_sales1#36091]
         :        +- BroadcastHashJoin [d_week_seq#28], [d_week_seq#36113], Inner, BuildRight, false
         :           :- Project [d_week_seq#28, sun_sales#36102, mon_sales#36103, tue_sales#36104, wed_sales#36105, thu_sales#36106, fri_sales#36107, sat_sales#36108, s_store_id#53, s_store_name#57]
         :           :  +- BroadcastHashJoin [ss_store_sk#1255], [s_store_sk#52], Inner, BuildRight, false
         :           :     :- HashAggregate(keys=[d_week_seq#28, ss_store_sk#1255], functions=[sum(CASE WHEN (d_day_name#38 = Sunday) THEN ss_sales_price#1261 END), sum(CASE WHEN (d_day_name#38 = Monday) THEN ss_sales_price#1261 END), sum(CASE WHEN (d_day_name#38 = Tuesday) THEN ss_sales_price#1261 END), sum(CASE WHEN (d_day_name#38 = Wednesday) THEN ss_sales_price#1261 END), sum(CASE WHEN (d_day_name#38 = Thursday) THEN ss_sales_price#1261 END), sum(CASE WHEN (d_day_name#38 = Friday) THEN ss_sales_price#1261 END), sum(CASE WHEN (d_day_name#38 = Saturday) THEN ss_sales_price#1261 END)], output=[d_week_seq#28, ss_store_sk#1255, sun_sales#36102, mon_sales#36103, tue_sales#36104, wed_sales#36105, thu_sales#36106, fri_sales#36107, sat_sales#36108])
         :           :     :  +- Exchange hashpartitioning(d_week_seq#28, ss_store_sk#1255, 200), ENSURE_REQUIREMENTS, [plan_id=114378]
         :           :     :     +- HashAggregate(keys=[d_week_seq#28, ss_store_sk#1255], functions=[partial_sum(CASE WHEN (d_day_name#38 = Sunday) THEN ss_sales_price#1261 END), partial_sum(CASE WHEN (d_day_name#38 = Monday) THEN ss_sales_price#1261 END), partial_sum(CASE WHEN (d_day_name#38 = Tuesday) THEN ss_sales_price#1261 END), partial_sum(CASE WHEN (d_day_name#38 = Wednesday) THEN ss_sales_price#1261 END), partial_sum(CASE WHEN (d_day_name#38 = Thursday) THEN ss_sales_price#1261 END), partial_sum(CASE WHEN (d_day_name#38 = Friday) THEN ss_sales_price#1261 END), partial_sum(CASE WHEN (d_day_name#38 = Saturday) THEN ss_sales_price#1261 END)], output=[d_week_seq#28, ss_store_sk#1255, sum#36666, sum#36667, sum#36668, sum#36669, sum#36670, sum#36671, sum#36672])
         :           :     :        +- Project [ss_store_sk#1255, ss_sales_price#1261, d_week_seq#28, d_day_name#38]
         :           :     :           +- BroadcastHashJoin [ss_sold_date_sk#1248], [d_date_sk#24], Inner, BuildRight, false
         :           :     :              :- Filter (isnotnull(ss_sold_date_sk#1248) AND isnotnull(ss_store_sk#1255))
         :           :     :              :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#1248,ss_store_sk#1255,ss_sales_price#1261] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#1248), isnotnull(ss_store_sk#1255)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_store_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_store_sk:int,ss_sales_price:double>
         :           :     :              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=114373]
         :           :     :                 +- Filter (isnotnull(d_date_sk#24) AND isnotnull(d_week_seq#28))
         :           :     :                    +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#24,d_week_seq#28,d_day_name#38] Batched: true, DataFilters: [isnotnull(d_date_sk#24), isnotnull(d_week_seq#28)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)], ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>
         :           :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=114381]
         :           :        +- Filter (isnotnull(s_store_sk#52) AND isnotnull(s_store_id#53))
         :           :           +- FileScan parquet spark_catalog.m.store[s_store_sk#52,s_store_id#53,s_store_name#57] Batched: true, DataFilters: [isnotnull(s_store_sk#52), isnotnull(s_store_id#53)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)], ReadSchema: struct<s_store_sk:int,s_store_id:string,s_store_name:string>
         :           +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=114385]
         :              +- Project [d_week_seq#36113]
         :                 +- Filter (((isnotnull(d_month_seq#36112) AND (d_month_seq#36112 >= 1205)) AND (d_month_seq#36112 <= 1216)) AND isnotnull(d_week_seq#36113))
         :                    +- FileScan parquet spark_catalog.m.date_dim[d_month_seq#36112,d_week_seq#36113] Batched: true, DataFilters: [isnotnull(d_month_seq#36112), (d_month_seq#36112 >= 1205), (d_month_seq#36112 <= 1216), isnotnul..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1205), LessThanOrEqual(d_month_seq,1216),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>
         +- Sort [s_store_id2#36094 ASC NULLS FIRST, (d_week_seq2#36093 - 52) ASC NULLS FIRST], false, 0
            +- Exchange hashpartitioning(s_store_id2#36094, (d_week_seq2#36093 - 52), 200), ENSURE_REQUIREMENTS, [plan_id=114406]
               +- Project [d_week_seq#36628 AS d_week_seq2#36093, s_store_id#36138 AS s_store_id2#36094, sun_sales#36203 AS sun_sales2#36095, mon_sales#36204 AS mon_sales2#36096, tue_sales#36205 AS tue_sales2#36097, wed_sales#36206 AS wed_sales2#36098, thu_sales#36207 AS thu_sales2#36099, fri_sales#36208 AS fri_sales2#36100, sat_sales#36209 AS sat_sales2#36101]
                  +- BroadcastHashJoin [d_week_seq#36628], [d_week_seq#36170], Inner, BuildRight, false
                     :- Project [d_week_seq#36628, sun_sales#36203, mon_sales#36204, tue_sales#36205, wed_sales#36206, thu_sales#36207, fri_sales#36208, sat_sales#36209, s_store_id#36138]
                     :  +- BroadcastHashJoin [ss_store_sk#36608], [s_store_sk#36137], Inner, BuildRight, false
                     :     :- HashAggregate(keys=[d_week_seq#36628, ss_store_sk#36608], functions=[sum(CASE WHEN (d_day_name#36638 = Sunday) THEN ss_sales_price#36614 END), sum(CASE WHEN (d_day_name#36638 = Monday) THEN ss_sales_price#36614 END), sum(CASE WHEN (d_day_name#36638 = Tuesday) THEN ss_sales_price#36614 END), sum(CASE WHEN (d_day_name#36638 = Wednesday) THEN ss_sales_price#36614 END), sum(CASE WHEN (d_day_name#36638 = Thursday) THEN ss_sales_price#36614 END), sum(CASE WHEN (d_day_name#36638 = Friday) THEN ss_sales_price#36614 END), sum(CASE WHEN (d_day_name#36638 = Saturday) THEN ss_sales_price#36614 END)], output=[d_week_seq#36628, ss_store_sk#36608, sun_sales#36203, mon_sales#36204, tue_sales#36205, wed_sales#36206, thu_sales#36207, fri_sales#36208, sat_sales#36209])
                     :     :  +- Exchange hashpartitioning(d_week_seq#36628, ss_store_sk#36608, 200), ENSURE_REQUIREMENTS, [plan_id=114393]
                     :     :     +- HashAggregate(keys=[d_week_seq#36628, ss_store_sk#36608], functions=[partial_sum(CASE WHEN (d_day_name#36638 = Sunday) THEN ss_sales_price#36614 END), partial_sum(CASE WHEN (d_day_name#36638 = Monday) THEN ss_sales_price#36614 END), partial_sum(CASE WHEN (d_day_name#36638 = Tuesday) THEN ss_sales_price#36614 END), partial_sum(CASE WHEN (d_day_name#36638 = Wednesday) THEN ss_sales_price#36614 END), partial_sum(CASE WHEN (d_day_name#36638 = Thursday) THEN ss_sales_price#36614 END), partial_sum(CASE WHEN (d_day_name#36638 = Friday) THEN ss_sales_price#36614 END), partial_sum(CASE WHEN (d_day_name#36638 = Saturday) THEN ss_sales_price#36614 END)], output=[d_week_seq#36628, ss_store_sk#36608, sum#36680, sum#36681, sum#36682, sum#36683, sum#36684, sum#36685, sum#36686])
                     :     :        +- Project [ss_store_sk#36608, ss_sales_price#36614, d_week_seq#36628, d_day_name#36638]
                     :     :           +- BroadcastHashJoin [ss_sold_date_sk#36601], [d_date_sk#36624], Inner, BuildRight, false
                     :     :              :- Filter (isnotnull(ss_sold_date_sk#36601) AND isnotnull(ss_store_sk#36608))
                     :     :              :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#36601,ss_store_sk#36608,ss_sales_price#36614] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#36601), isnotnull(ss_store_sk#36608)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), IsNotNull(ss_store_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_store_sk:int,ss_sales_price:double>
                     :     :              +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=114388]
                     :     :                 +- Filter (isnotnull(d_date_sk#36624) AND isnotnull(d_week_seq#36628))
                     :     :                    +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#36624,d_week_seq#36628,d_day_name#36638] Batched: true, DataFilters: [isnotnull(d_date_sk#36624), isnotnull(d_week_seq#36628)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_date_sk), IsNotNull(d_week_seq)], ReadSchema: struct<d_date_sk:int,d_week_seq:int,d_day_name:string>
                     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=114396]
                     :        +- Filter (isnotnull(s_store_sk#36137) AND isnotnull(s_store_id#36138))
                     :           +- FileScan parquet spark_catalog.m.store[s_store_sk#36137,s_store_id#36138] Batched: true, DataFilters: [isnotnull(s_store_sk#36137), isnotnull(s_store_id#36138)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_sk), IsNotNull(s_store_id)], ReadSchema: struct<s_store_sk:int,s_store_id:string>
                     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=114400]
                        +- Project [d_week_seq#36170]
                           +- Filter (((isnotnull(d_month_seq#36169) AND (d_month_seq#36169 >= 1217)) AND (d_month_seq#36169 <= 1228)) AND isnotnull(d_week_seq#36170))
                              +- FileScan parquet spark_catalog.m.date_dim[d_month_seq#36169,d_week_seq#36170] Batched: true, DataFilters: [isnotnull(d_month_seq#36169), (d_month_seq#36169 >= 1217), (d_month_seq#36169 <= 1228), isnotnul..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1217), LessThanOrEqual(d_month_seq,1228),..., ReadSchema: struct<d_month_seq:int,d_week_seq:int>
