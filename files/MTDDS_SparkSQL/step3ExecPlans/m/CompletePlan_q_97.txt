== Parsed Logical Plan ==
CTE [ssci, csci]
:  :- 'SubqueryAlias ssci
:  :  +- 'Aggregate ['ss_customer_sk, 'ss_item_sk], ['ss_customer_sk AS customer_sk#49351, 'ss_item_sk AS item_sk#49352]
:  :     +- 'Filter (('ss_sold_date_sk = 'd_date_sk) AND (('d_month_seq >= 1211) AND ('d_month_seq <= (1211 + 11))))
:  :        +- 'Join Inner
:  :           :- 'UnresolvedRelation [store_sales], [], false
:  :           +- 'UnresolvedRelation [date_dim], [], false
:  +- 'SubqueryAlias csci
:     +- 'Aggregate ['cs_bill_customer_sk, 'cs_item_sk], ['cs_bill_customer_sk AS customer_sk#49353, 'cs_item_sk AS item_sk#49354]
:        +- 'Filter (('cs_sold_date_sk = 'd_date_sk) AND (('d_month_seq >= 1211) AND ('d_month_seq <= (1211 + 11))))
:           +- 'Join Inner
:              :- 'UnresolvedRelation [catalog_sales], [], false
:              +- 'UnresolvedRelation [date_dim], [], false
+- 'GlobalLimit 100
   +- 'LocalLimit 100
      +- 'Project ['sum(CASE WHEN (isnotnull('ssci.customer_sk) AND isnull('csci.customer_sk)) THEN 1 ELSE 0 END) AS store_only#49348, 'sum(CASE WHEN (isnull('ssci.customer_sk) AND isnotnull('csci.customer_sk)) THEN 1 ELSE 0 END) AS catalog_only#49349, 'sum(CASE WHEN (isnotnull('ssci.customer_sk) AND isnotnull('csci.customer_sk)) THEN 1 ELSE 0 END) AS store_and_catalog#49350]
         +- 'Join FullOuter, (('ssci.customer_sk = 'csci.customer_sk) AND ('ssci.item_sk = 'csci.item_sk))
            :- 'UnresolvedRelation [ssci], [], false
            +- 'UnresolvedRelation [csci], [], false

== Analyzed Logical Plan ==
store_only: bigint, catalog_only: bigint, store_and_catalog: bigint
WithCTE
:- CTERelationDef 78, false
:  +- SubqueryAlias ssci
:     +- Aggregate [ss_customer_sk#1251, ss_item_sk#1250], [ss_customer_sk#1251 AS customer_sk#49351, ss_item_sk#1250 AS item_sk#49352]
:        +- Filter ((ss_sold_date_sk#1248 = d_date_sk#24) AND ((d_month_seq#27 >= 1211) AND (d_month_seq#27 <= (1211 + 11))))
:           +- Join Inner
:              :- SubqueryAlias spark_catalog.m.store_sales
:              :  +- Relation spark_catalog.m.store_sales[ss_sold_date_sk#1248,ss_sold_time_sk#1249,ss_item_sk#1250,ss_customer_sk#1251,ss_cdemo_sk#1252,ss_hdemo_sk#1253,ss_addr_sk#1254,ss_store_sk#1255,ss_promo_sk#1256,ss_ticket_number#1257,ss_quantity#1258,ss_wholesale_cost#1259,ss_list_price#1260,ss_sales_price#1261,ss_ext_discount_amt#1262,ss_ext_sales_price#1263,ss_ext_wholesale_cost#1264,ss_ext_list_price#1265,ss_ext_tax#1266,ss_coupon_amt#1267,ss_net_paid#1268,ss_net_paid_inc_tax#1269,ss_net_profit#1270] parquet
:              +- SubqueryAlias spark_catalog.m.date_dim
:                 +- Relation spark_catalog.m.date_dim[d_date_sk#24,d_date_id#25,d_date#26,d_month_seq#27,d_week_seq#28,d_quarter_seq#29,d_year#30,d_dow#31,d_moy#32,d_dom#33,d_qoy#34,d_fy_year#35,d_fy_quarter_seq#36,d_fy_week_seq#37,d_day_name#38,d_quarter_name#39,d_holiday#40,d_weekend#41,d_following_holiday#42,d_first_dom#43,d_last_dom#44,d_same_day_ly#45,d_same_day_lq#46,d_current_day#47,... 4 more fields] parquet
:- CTERelationDef 79, false
:  +- SubqueryAlias csci
:     +- Aggregate [cs_bill_customer_sk#464, cs_item_sk#476], [cs_bill_customer_sk#464 AS customer_sk#49353, cs_item_sk#476 AS item_sk#49354]
:        +- Filter ((cs_sold_date_sk#461 = d_date_sk#49355) AND ((d_month_seq#49358 >= 1211) AND (d_month_seq#49358 <= (1211 + 11))))
:           +- Join Inner
:              :- SubqueryAlias spark_catalog.m.catalog_sales
:              :  +- Relation spark_catalog.m.catalog_sales[cs_sold_date_sk#461,cs_sold_time_sk#462,cs_ship_date_sk#463,cs_bill_customer_sk#464,cs_bill_cdemo_sk#465,cs_bill_hdemo_sk#466,cs_bill_addr_sk#467,cs_ship_customer_sk#468,cs_ship_cdemo_sk#469,cs_ship_hdemo_sk#470,cs_ship_addr_sk#471,cs_call_center_sk#472,cs_catalog_page_sk#473,cs_ship_mode_sk#474,cs_warehouse_sk#475,cs_item_sk#476,cs_promo_sk#477,cs_order_number#478,cs_quantity#479,cs_wholesale_cost#480,cs_list_price#481,cs_sales_price#482,cs_ext_discount_amt#483,cs_ext_sales_price#484,... 10 more fields] parquet
:              +- SubqueryAlias spark_catalog.m.date_dim
:                 +- Relation spark_catalog.m.date_dim[d_date_sk#49355,d_date_id#49356,d_date#49357,d_month_seq#49358,d_week_seq#49359,d_quarter_seq#49360,d_year#49361,d_dow#49362,d_moy#49363,d_dom#49364,d_qoy#49365,d_fy_year#49366,d_fy_quarter_seq#49367,d_fy_week_seq#49368,d_day_name#49369,d_quarter_name#49370,d_holiday#49371,d_weekend#49372,d_following_holiday#49373,d_first_dom#49374,d_last_dom#49375,d_same_day_ly#49376,d_same_day_lq#49377,d_current_day#49378,... 4 more fields] parquet
+- GlobalLimit 100
   +- LocalLimit 100
      +- Aggregate [sum(CASE WHEN (isnotnull(customer_sk#49351) AND isnull(customer_sk#49353)) THEN 1 ELSE 0 END) AS store_only#49348L, sum(CASE WHEN (isnull(customer_sk#49351) AND isnotnull(customer_sk#49353)) THEN 1 ELSE 0 END) AS catalog_only#49349L, sum(CASE WHEN (isnotnull(customer_sk#49351) AND isnotnull(customer_sk#49353)) THEN 1 ELSE 0 END) AS store_and_catalog#49350L]
         +- Join FullOuter, ((customer_sk#49351 = customer_sk#49353) AND (item_sk#49352 = item_sk#49354))
            :- SubqueryAlias ssci
            :  +- CTERelationRef 78, true, [customer_sk#49351, item_sk#49352], false
            +- SubqueryAlias csci
               +- CTERelationRef 79, true, [customer_sk#49353, item_sk#49354], false

== Optimized Logical Plan ==
Aggregate [sum(CASE WHEN (isnotnull(customer_sk#49351) AND isnull(customer_sk#49353)) THEN 1 ELSE 0 END) AS store_only#49348L, sum(CASE WHEN (isnull(customer_sk#49351) AND isnotnull(customer_sk#49353)) THEN 1 ELSE 0 END) AS catalog_only#49349L, sum(CASE WHEN (isnotnull(customer_sk#49351) AND isnotnull(customer_sk#49353)) THEN 1 ELSE 0 END) AS store_and_catalog#49350L]
+- Project [customer_sk#49351, customer_sk#49353]
   +- Join FullOuter, ((customer_sk#49351 = customer_sk#49353) AND (item_sk#49352 = item_sk#49354))
      :- Aggregate [ss_customer_sk#1251, ss_item_sk#1250], [ss_customer_sk#1251 AS customer_sk#49351, ss_item_sk#1250 AS item_sk#49352]
      :  +- Project [ss_item_sk#1250, ss_customer_sk#1251]
      :     +- Join Inner, (ss_sold_date_sk#1248 = d_date_sk#24)
      :        :- Project [ss_sold_date_sk#1248, ss_item_sk#1250, ss_customer_sk#1251]
      :        :  +- Filter isnotnull(ss_sold_date_sk#1248)
      :        :     +- Relation spark_catalog.m.store_sales[ss_sold_date_sk#1248,ss_sold_time_sk#1249,ss_item_sk#1250,ss_customer_sk#1251,ss_cdemo_sk#1252,ss_hdemo_sk#1253,ss_addr_sk#1254,ss_store_sk#1255,ss_promo_sk#1256,ss_ticket_number#1257,ss_quantity#1258,ss_wholesale_cost#1259,ss_list_price#1260,ss_sales_price#1261,ss_ext_discount_amt#1262,ss_ext_sales_price#1263,ss_ext_wholesale_cost#1264,ss_ext_list_price#1265,ss_ext_tax#1266,ss_coupon_amt#1267,ss_net_paid#1268,ss_net_paid_inc_tax#1269,ss_net_profit#1270] parquet
      :        +- Project [d_date_sk#24]
      :           +- Filter ((isnotnull(d_month_seq#27) AND ((d_month_seq#27 >= 1211) AND (d_month_seq#27 <= 1222))) AND isnotnull(d_date_sk#24))
      :              +- Relation spark_catalog.m.date_dim[d_date_sk#24,d_date_id#25,d_date#26,d_month_seq#27,d_week_seq#28,d_quarter_seq#29,d_year#30,d_dow#31,d_moy#32,d_dom#33,d_qoy#34,d_fy_year#35,d_fy_quarter_seq#36,d_fy_week_seq#37,d_day_name#38,d_quarter_name#39,d_holiday#40,d_weekend#41,d_following_holiday#42,d_first_dom#43,d_last_dom#44,d_same_day_ly#45,d_same_day_lq#46,d_current_day#47,... 4 more fields] parquet
      +- Aggregate [cs_bill_customer_sk#464, cs_item_sk#476], [cs_bill_customer_sk#464 AS customer_sk#49353, cs_item_sk#476 AS item_sk#49354]
         +- Project [cs_bill_customer_sk#464, cs_item_sk#476]
            +- Join Inner, (cs_sold_date_sk#461 = d_date_sk#49355)
               :- Project [cs_sold_date_sk#461, cs_bill_customer_sk#464, cs_item_sk#476]
               :  +- Filter isnotnull(cs_sold_date_sk#461)
               :     +- Relation spark_catalog.m.catalog_sales[cs_sold_date_sk#461,cs_sold_time_sk#462,cs_ship_date_sk#463,cs_bill_customer_sk#464,cs_bill_cdemo_sk#465,cs_bill_hdemo_sk#466,cs_bill_addr_sk#467,cs_ship_customer_sk#468,cs_ship_cdemo_sk#469,cs_ship_hdemo_sk#470,cs_ship_addr_sk#471,cs_call_center_sk#472,cs_catalog_page_sk#473,cs_ship_mode_sk#474,cs_warehouse_sk#475,cs_item_sk#476,cs_promo_sk#477,cs_order_number#478,cs_quantity#479,cs_wholesale_cost#480,cs_list_price#481,cs_sales_price#482,cs_ext_discount_amt#483,cs_ext_sales_price#484,... 10 more fields] parquet
               +- Project [d_date_sk#49355]
                  +- Filter ((isnotnull(d_month_seq#49358) AND ((d_month_seq#49358 >= 1211) AND (d_month_seq#49358 <= 1222))) AND isnotnull(d_date_sk#49355))
                     +- Relation spark_catalog.m.date_dim[d_date_sk#49355,d_date_id#49356,d_date#49357,d_month_seq#49358,d_week_seq#49359,d_quarter_seq#49360,d_year#49361,d_dow#49362,d_moy#49363,d_dom#49364,d_qoy#49365,d_fy_year#49366,d_fy_quarter_seq#49367,d_fy_week_seq#49368,d_day_name#49369,d_quarter_name#49370,d_holiday#49371,d_weekend#49372,d_following_holiday#49373,d_first_dom#49374,d_last_dom#49375,d_same_day_ly#49376,d_same_day_lq#49377,d_current_day#49378,... 4 more fields] parquet

== Physical Plan ==
AdaptiveSparkPlan isFinalPlan=false
+- HashAggregate(keys=[], functions=[sum(CASE WHEN (isnotnull(customer_sk#49351) AND isnull(customer_sk#49353)) THEN 1 ELSE 0 END), sum(CASE WHEN (isnull(customer_sk#49351) AND isnotnull(customer_sk#49353)) THEN 1 ELSE 0 END), sum(CASE WHEN (isnotnull(customer_sk#49351) AND isnotnull(customer_sk#49353)) THEN 1 ELSE 0 END)], output=[store_only#49348L, catalog_only#49349L, store_and_catalog#49350L])
   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=177708]
      +- HashAggregate(keys=[], functions=[partial_sum(CASE WHEN (isnotnull(customer_sk#49351) AND isnull(customer_sk#49353)) THEN 1 ELSE 0 END), partial_sum(CASE WHEN (isnull(customer_sk#49351) AND isnotnull(customer_sk#49353)) THEN 1 ELSE 0 END), partial_sum(CASE WHEN (isnotnull(customer_sk#49351) AND isnotnull(customer_sk#49353)) THEN 1 ELSE 0 END)], output=[sum#49402L, sum#49403L, sum#49404L])
         +- Project [customer_sk#49351, customer_sk#49353]
            +- SortMergeJoin [customer_sk#49351, item_sk#49352], [customer_sk#49353, item_sk#49354], FullOuter
               :- Sort [customer_sk#49351 ASC NULLS FIRST, item_sk#49352 ASC NULLS FIRST], false, 0
               :  +- HashAggregate(keys=[ss_customer_sk#1251, ss_item_sk#1250], functions=[], output=[customer_sk#49351, item_sk#49352])
               :     +- Exchange hashpartitioning(ss_customer_sk#1251, ss_item_sk#1250, 200), ENSURE_REQUIREMENTS, [plan_id=177691]
               :        +- HashAggregate(keys=[ss_customer_sk#1251, ss_item_sk#1250], functions=[], output=[ss_customer_sk#1251, ss_item_sk#1250])
               :           +- Project [ss_item_sk#1250, ss_customer_sk#1251]
               :              +- BroadcastHashJoin [ss_sold_date_sk#1248], [d_date_sk#24], Inner, BuildRight, false
               :                 :- Filter isnotnull(ss_sold_date_sk#1248)
               :                 :  +- FileScan parquet spark_catalog.m.store_sales[ss_sold_date_sk#1248,ss_item_sk#1250,ss_customer_sk#1251] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#1248)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/store_sales], PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk)], ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_customer_sk:int>
               :                 +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=177686]
               :                    +- Project [d_date_sk#24]
               :                       +- Filter (((isnotnull(d_month_seq#27) AND (d_month_seq#27 >= 1211)) AND (d_month_seq#27 <= 1222)) AND isnotnull(d_date_sk#24))
               :                          +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#24,d_month_seq#27] Batched: true, DataFilters: [isnotnull(d_month_seq#27), (d_month_seq#27 >= 1211), (d_month_seq#27 <= 1222), isnotnull(d_date_..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1211), LessThanOrEqual(d_month_seq,1222),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>
               +- Sort [customer_sk#49353 ASC NULLS FIRST, item_sk#49354 ASC NULLS FIRST], false, 0
                  +- HashAggregate(keys=[cs_bill_customer_sk#464, cs_item_sk#476], functions=[], output=[customer_sk#49353, item_sk#49354])
                     +- Exchange hashpartitioning(cs_bill_customer_sk#464, cs_item_sk#476, 200), ENSURE_REQUIREMENTS, [plan_id=177698]
                        +- HashAggregate(keys=[cs_bill_customer_sk#464, cs_item_sk#476], functions=[], output=[cs_bill_customer_sk#464, cs_item_sk#476])
                           +- Project [cs_bill_customer_sk#464, cs_item_sk#476]
                              +- BroadcastHashJoin [cs_sold_date_sk#461], [d_date_sk#49355], Inner, BuildRight, false
                                 :- Filter isnotnull(cs_sold_date_sk#461)
                                 :  +- FileScan parquet spark_catalog.m.catalog_sales[cs_sold_date_sk#461,cs_bill_customer_sk#464,cs_item_sk#476] Batched: true, DataFilters: [isnotnull(cs_sold_date_sk#461)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/catalog_sales], PartitionFilters: [], PushedFilters: [IsNotNull(cs_sold_date_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_bill_customer_sk:int,cs_item_sk:int>
                                 +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=177693]
                                    +- Project [d_date_sk#49355]
                                       +- Filter (((isnotnull(d_month_seq#49358) AND (d_month_seq#49358 >= 1211)) AND (d_month_seq#49358 <= 1222)) AND isnotnull(d_date_sk#49355))
                                          +- FileScan parquet spark_catalog.m.date_dim[d_date_sk#49355,d_month_seq#49358] Batched: true, DataFilters: [isnotnull(d_month_seq#49358), (d_month_seq#49358 >= 1211), (d_month_seq#49358 <= 1222), isnotnul..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://gros-121:9000/usr/spark/spark-warehouse/m.db/date_dim], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1211), LessThanOrEqual(d_month_seq,1222),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>
