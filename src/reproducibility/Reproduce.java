package reproducibility;

import java.io.IOException;
import java.sql.SQLException;

public class Reproduce {

	public static void main(String args[]) throws ClassNotFoundException, SQLException, IOException {
		
		// Generate 20 tenants to reproduce Figures 2-4 in the paper
		// Input: number of tenants to generate
		// Output: a csv file containing the tenants' information
		core.TenantsGenerator.generateTenants(20, "files\\20tenants.csv");
		System.out.println("[REPRODUCE] 20 tenants are generated.");
		
		// Generate queries for the 20 tenants
		// Input: a csv file containing the tenants' information
		// Output: a csv file containing all queries in the folder 20tenantsQueries
		core.TenantQueriesGenerator.generateAllQueries_OneFile("files\\20tenants.csv", "files\\20tenantsQueries");
		System.out.println("[REPRODUCE] Queries for the 20 tenants are generated.");
		
		// the file 20tenantsQueries.csv was then imported into the Excel file QueryArrivals.xlsx for plotting the figures (see the folder excelFilesforFigures).
		
		/*** The benchmarking steps used by the experiments in Section 4 are below. ***/
		/*** Step 1 - Data and queries generation ***/
		System.out.println("\n====== Step 1 - Data and queries generation ======");
				
		/* We generated 3 data sets (scale factor 1, 2 and 3) and the 99 queries for each scale factor by using the TPC-DS tool kit. */
		System.out.println("### We generated 3 data sets (scale factor 1, 2 and 3) and the 99 queries for each scale factor by using the TPC-DS tool kit.");
		
		// With the addExplain_( ) method in the example.AddExplain class, we then add EXPLAIN ANALYZE to each query, in order that the execution plans will be printed during the Power Test. 
		// Input: a file in the folder step1Queries_TPCDS with the queries generated by TPC-DS tool kit
		// Output: a file in the folder step1QueriesWithExplain with the queries preceded by EXPLAIN ANALYZE
		example.AddExplain.addExplain_("files\\step1Queries_TPCDS\\l\\query_0.sql", "files\\step1QueriesWithExplain\\l", "query_0_l", "/home/postgres/mtdds/queries/l");
		example.AddExplain.addExplain_("files\\step1Queries_TPCDS\\m\\query_0.sql", "files\\step1QueriesWithExplain\\m", "query_0_m", "/home/postgres/mtdds/queries/m");
		example.AddExplain.addExplain_("files\\step1Queries_TPCDS\\s\\query_0.sql", "files\\step1QueriesWithExplain\\s", "query_0_s", "/home/postgres/mtdds/queries/s");		
		System.out.println("[REPRODUCE] EXPLAIN ANALYZE is added.");
		
		/*** Step2 - Databases Load ***/
		System.out.println("\n====== Step 2 - Databases Load ======");
		
		/* We loaded the three databases by using the scripts in the folder step2Scripts_PostgresXL. */
		System.out.println("### We loaded the three databases by using the scripts in the folder step2Scripts_PostgresXL.");
		
		/*** Step 3 - Power Tests ***/
		System.out.println("\n====== Step 3 - Power Tests ======");
		
		// In our experiments, during the Power Tests, we register the execution plan and execution time of each query for each scale factor in separated files.
		System.out.println("### We registered the execution plan and execution time of each query for each scale factor in separated files (folder step3ExecPlans).");
		// These files (in the folder step3ExecPlans) are then read by the ExecTimeExtractor to extract the execution times.
		// Input: a folder with files containing the execution plan and execution time of each query
		// Output: a single csv file with execution time of each query 
		example.ExecTimeExtractor.extractExecTime("files\\step3ExecPlans\\l", "files\\step3ExecTimes\\ExecTime_3.csv");
		example.ExecTimeExtractor.extractExecTime("files\\step3ExecPlans\\m", "files\\step3ExecTimes\\ExecTime_2.csv");
		example.ExecTimeExtractor.extractExecTime("files\\step3ExecPlans\\s", "files\\step3ExecTimes\\ExecTime_1.csv");
		System.out.println("[REPRODUCE] Execution times extracted.");
		
		/*** Step 4 - Performance SLO generation ***/
		System.out.println("\n====== Step 4 - Performance SLO generation ======");
		
		// Input 1: directory(execTimeDir) with execTime_*.csv (queryId, execTime) for the three scale factors, for example, execTime_2.csv for scale factor 2 
		// Input 2: query_types.csv (queryId, type)
		// Output: perfSLOs.csv (queryId, scaleFactor, expectedQCT, perfSLO_premium, perfSLO_standard, perfSLO_basic)
		core.PerfSLOGenerator.generatePerfSLO("files\\step3ExecTimes", "files\\benchmarkInputFiles\\query_types.csv", "files\\benchmarkInputFiles\\PriorityTRT.csv", "files\\step4PerfSLOs\\perfSLOs.csv");
		System.out.println("[REPRODUCE] Performance SLOs generated.");
		
		/*** Step 5 - Multi-tenant query workload generation ***/
		System.out.println("\n====== Step 5 - Multi-tenant query workload generation ======");
		
		// Generate 6 tenants
		// Input: number of tenants to generate
		// Output: a csv file containing the tenants' information
		core.TenantsGenerator.generateTenants(6, "files\\6tenants.csv");
		System.out.println("[REPRODUCE] 6 tenants are generated.");
				
		// Generate queries for the 20 tenants
		// Input: a csv file containing the tenants' information
		// Output: a folder with csv files each containing the queries of a tenant
		core.TenantQueriesGenerator.generateAllQueries("files\\6tenants.csv", "files\\6tenantsQueries");
		System.out.println("[REPRODUCE] Queries for the 6 tenants are generated.");
		
		// Split the query_0.sql file for each DBSize into separate sql files (one file for each query), such that in Step 6, each query could be launched at a precise moment
		// Input: a file in the folder step1Queries_TPCDS with the queries generated by TPC-DS tool kit
		// Output: 99 files each containing a single query
		example.splitQueries.splitQ("files\\step1Queries_TPCDS\\l\\query_0.sql", "files\\step5IndividualQueries\\l");
		example.splitQueries.splitQ("files\\step1Queries_TPCDS\\m\\query_0.sql", "files\\step5IndividualQueries\\m");
		example.splitQueries.splitQ("files\\step1Queries_TPCDS\\s\\query_0.sql", "files\\step5IndividualQueries\\s");
		System.out.println("[REPRODUCE] Individual queries are extracted into separate files.");
		
		/*** Step 6 - Multi-tenant query workload tests ***/
		System.out.println("\n====== Step 6 - Multi-tenant query workload tests ======");
		
		// Use templates to generate scripts for creating the 6 tenants, their databases and loading the data
		// Input: a folder (step6SourceScript) containing the initial CREATE TABLE commands provided by the TPC-DS tool kit 
		// Output: a folder with necessary scripts to create tenants, databases and to load the data (step6Scripts)
		// The scripts tpcds_ri.sql, alter_table_rep.sql and create_index_catalog.sql are included in the folder step6Scripts and they can be used by all tenants.
		example.MTTestsScriptWriter.generateScripts(1, "files\\6tenants.csv", "files\\step6SourceScript", "files\\step6Scripts_PostgresXL");
		System.out.println("[REPRODUCE] Multi-tenant databases creation and data load scripts are generated.");
		
		// In our experiments, during theMulti-tenant query workload Tests, we run the driver programs which send queries to the SUTs.
		System.out.println("### We ran the driver program (in the folder step6Drivers_PostgresXL) on each SUT.");
		
		/*** Step 7 - PO_Metric 1 and PO_Metric 2 measurement ***/
		System.out.println("\n====== Step 7 - PO_Metric 1 and PO_Metric 2 measurement ======");
		System.out.println("### In the benchmark we can choose to run Step 7 or Step 8, or both. In our experiment, we ran only Step 8.");
		
		/*** Step 8 - PO_Metric 1 Bis and PO_Metric 2 Bis measurement ***/
		System.out.println("\n====== Step 8 - PO_Metric 1 Bis and PO_Metric 2 Bis measurement ======");
		System.out.println("### We ran the driver program for each Arrival Rate Factor (ARF) and copied the execution traces into the folder step6ExecTraces.");
		
		// In order to compute the metrics' values easily, we use a SQLite database (mtdds.db) to store the parameter values, execution traces and intermediate results.
		
		// Initialize the SQLite database (mtdds.db).
		System.out.println("[REPRODUCE] Creating and initializing a SQLite database mtdds.db to compute the metric's values...");
		tools.DBInitialization.initDB();
		System.out.println("[REPRODUCE] SQLite database mtdds.db initialized.");
		
		// Transform the execution traces from Format1 to Format2, and load them into mtdds.db
		// Input: Execution traces with Format1 (TenantName, QueryNumber, ThreadName, Event, TimeStamp)
		// Output: Execution traces with Format2 (SUTNumber, clusterSize, arrivalRateFactor, TenantName, QueryNumber, ThreadName, LaunchTime, StartTime, FinishTime);
		System.out.println("[REPRODUCE] Transform the execution traces from Format1 to Format2...");
		tools.ExecutionTraceTransformer.transformAllTraces(1, "files\\step8ExecTraces\\SUT1", 15, "files\\step8FormatedTraces\\SUT1");
		tools.ExecutionTraceTransformer.transformAllTraces(2, "files\\step8ExecTraces\\SUT2", 15, "files\\step8FormatedTraces\\SUT2");
		System.out.println("[REPRODUCE] Execution Traces transformed.");
		
		/*** Step 9 - Final scores computation ***/
		System.out.println("\n====== Step 9 - Final scores computation ======");
		
		// Load the benchmark input files with the prices of the resources, scales factors of various DBSizes and tolerance rate thresholds of tenants with different priorities
		// Input: files in the Folder benchmarkInputFiles
		// Output: updated SQLite database (mtdds.db)
		tools.InputFilesLoader.loadRSPrices("files\\benchmarkInputFiles\\RSPrices.csv");
		tools.InputFilesLoader.loadDBSizesSF("files\\benchmarkInputFiles\\DBSizesSF.csv");
		tools.InputFilesLoader.loadPriorityTTR("files\\benchmarkInputFiles\\PriorityTRT.csv");
		System.out.println("[REPRODUCE] Benchmark input files loaded into mtdds.db.");
		
		// Load the tenants file generated in Step 5
		tools.TenantsLoader.loadTenants("files\\6tenants.csv");
		System.out.println("[REPRODUCE] Generated tenants loaded into mtdds.db.");
		
		// Load the generic performance SLOs generated in Step 4 and compute the performance SLOs for each tenant 
		tools.PerfSLOsPerTenant.LoadPerfSLOs("files\\step4PerfSLOs\\perfSLOs.csv");
		tools.PerfSLOsPerTenant.computePerfSLOs_per_tenant("files\\6tenants.csv");
		System.out.println("[REPRODUCE] Performance SLOs are computed for all tenants.");
		
		// Compute intermediate metrics for SUT1 and SUT2 using the pricing model RCB
		core.PricingModelRCB.computeIntermediateMetrics(1, 5, 15);
		core.PricingModelRCB.computeIntermediateMetrics(2, 5, 15);
		System.out.println("[REPRODUCE] Intermediate metrics computed for the pricing model RCB.");
		
		
		// Compute intermediate metrics for SUT1 and SUT2 using the pricing model QLSA
		core.PricingModelQLSA.computeIntermediateMetrics(1, 5, 15);
		core.PricingModelQLSA.computeIntermediateMetrics(2, 5, 15);
		System.out.println("[REPRODUCE] Intermediate metrics computed for the pricing model QLSA.");
		
		// Compute the final scores of SUT1 and SUT2 using the pricing model RCB under the clusterSize 5 with SSR_MIN = 0.7
		System.out.println("[REPRODUCE] Computing final scores for the pricing model RCB...");
		System.out.println("== SUT1: HARF related results ==");
		core.Metrics.showAllforHARF(1, "RCB", 5, 0.7);
		System.out.println("== SUT1: OARF related results ==");
		core.Metrics.showAllforOARF(1, "RCB", 5, 0.7);
		System.out.println("== SUT2: HARF related results ==");
		core.Metrics.showAllforHARF(2, "RCB", 5, 0.7);
		System.out.println("== SUT2: OARF related results ==");
		core.Metrics.showAllforOARF(2, "RCB", 5, 0.7);
		System.out.println("[REPRODUCE] Final scores computed for the pricing model RCB.");
		
		// Compute the final scores of SUT1 and SUT2 using the pricing model QLSA under the clusterSize 5 with SSR_MIN = 0.7
		System.out.println("[REPRODUCE] Computing final scores for the pricing model QLSA...");
		System.out.println("== SUT1: HARF related resqults ==");
		core.Metrics.showAllforHARF(1, "QLSA", 5, 0.7);
		System.out.println("== SUT1: OARF related results ==");
		core.Metrics.showAllforOARF(1, "QLSA", 5, 0.7);
		System.out.println("== SUT2: HARF related results ==");
		core.Metrics.showAllforHARF(2, "QLSA", 5, 0.7);
		System.out.println("== SUT2: OARF related results ==");
		core.Metrics.showAllforOARF(2, "QLSA", 5, 0.7);
		System.out.println("[REPRODUCE] Final scores computed for the pricing model QLSA.");
		
		/*** Export of data files for reproducing the Figures in the paper ***/
		System.out.println("\n====== Exporting data files for reproducing the Figures in the paper ======");
		example.DataForFigures.exportDataForAllFigure("files");
	}
}
